<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://debezium.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://debezium.io/" rel="alternate" type="text/html"/><updated>2023-05-01T14:13:22+00:00</updated><id>https://debezium.io/feed.xml</id><title type="html">Debezium</title><subtitle>Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.</subtitle><entry><title type="html">New Debezium images will be available only Quay.io in the future</title><link href="https://debezium.io/blog/2023/04/25/container-images-quayio/" rel="alternate" type="text/html" title="New Debezium images will be available only Quay.io in the future"/><published>2023-04-25T10:11:11+00:00</published><updated>2023-04-25T10:11:11+00:00</updated><id>https://debezium.io/blog/2023/04/25/container-images-quayio</id><content type="html" xml:base="https://debezium.io/blog/2023/04/25/container-images-quayio/"><![CDATA[<div class="paragraph"> <p>As you may have noticed, the Docker company recently announced a reduction of the free organization accounts offering. The Docker company wanted to provide for free organization accounts only for <a href="https://www.docker.com/community/open-source/application/">Docker-Sponsored Open Source (DSOS) projects</a>. Debezium project doesn&#8217;t meet their definition of open source project as we have a pathway to commercialization. As the accounts ought to be terminated in 30 days, we immediately started to work on moving out the Debezium project from Docker Hub.</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>Based on the feedback from the community, the Docker company later on <a href="https://www.docker.com/blog/no-longer-sunsetting-the-free-team-plan/">re-evaluated their decision</a> and Free Team plan is still available as before. However, the whole story, and especially the initial intention to give projects which don&#8217;t meet DSOS conditions only 30 days for migration, undermined our trust in the Docker company and raised a question of what will come in the future. As a result we decided <strong>not to publish Debezium images on Docker Hub</strong> in the future.</p> </div> <div class="paragraph"> <p>For quite some time we already publish all Debezium images into two container image registries:</p> </div> <div class="ulist"> <ul> <li> <p>on the <a href="https://hub.docker.com/u/debezium">Docker Hub</a></p> </li> <li> <p>on the <a href="https://quay.io/organization/debezium/">Quay.io</a></p> </li> </ul> </div> <div class="paragraph"> <p>Upcomming 2.2 release and previews of 2.3 (including CR releases), will be still available on the Docker Hub, but starting 2.3.0.Final release, we will stop publishing images there. Images of Debezium 2.3.0.Final and subsequent releases will be available only on the <a href="https://quay.io/organization/debezium/">Quay.io</a>. Older, already published, images will be of course still available through Docker Hub (unless Docker company changes the conditions which would prevent it in the future). Older Debezium images can be found also on <a href="https://quay.io/organization/debezium/">Quay.io</a>.</p> </div> <div class="paragraph"> <p><a href="https://quay.io">Quay.io</a> is a mature container registry service, which provides additional features like e.g. vulnerability scans. As the <a href="https://quay.io">Quay.io</a> is run and sponsored by Red Hat, and we already publish the image there, it was a natural choice for us to move to this container registry.</p> </div> <div class="paragraph"> <p>How to migrate to <a href="https://quay.io/organization/debezium/">Quay.io</a>? It&#8217;s very simple - just add <code>quay.io/</code> prefix to the container image name, e.g. instead of running</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>docker pull debezium/connect:latest</code></pre> </div> </div> <div class="paragraph"> <p>you run</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>docker pull quay.io/debezium/connect:latest</code></pre> </div> </div> <div class="paragraph"> <p>and similar for any other images or commands.</p> </div> <div class="paragraph"> <p>If you have any questions or issues with using <a href="https://quay.io">Quay.io</a> images, don&#8217;t hesitate to reach to us and raise your questions or concerns in our <a href="https://debezium.zulipchat.com/#narrow/stream/302529-users">user chat room</a>.</p> </div>]]></content><author><name>Vojtěch Juránek</name></author><category term="news"/><category term="docker"/><category term="containers"/><summary type="html"><![CDATA[As you may have noticed, the Docker company recently announced a reduction of the free organization accounts offering. The Docker company wanted to provide for free organization accounts only for Docker-Sponsored Open Source (DSOS) projects. Debezium project doesn&#8217;t meet their definition of open source project as we have a pathway to commercialization. As the accounts ought to be terminated in 30 days, we immediately started to work on moving out the Debezium project from Docker Hub.]]></summary></entry><entry><title type="html">Debezium 2.2.0.Final Released</title><link href="https://debezium.io/blog/2023/04/20/debezium-2-2-final-released/" rel="alternate" type="text/html" title="Debezium 2.2.0.Final Released"/><published>2023-04-20T00:00:00+00:00</published><updated>2023-04-20T00:00:00+00:00</updated><id>https://debezium.io/blog/2023/04/20/debezium-2-2-final-released</id><content type="html" xml:base="https://debezium.io/blog/2023/04/20/debezium-2-2-final-released/"><![CDATA[<div class="paragraph"> <p>Today, it&#8217;s with great joy that we can announce the availability of Debezium <strong>2.2.0.Final</strong>!</p> </div> <div class="paragraph"> <p>Many of you may have noticed, this release cadence took a bit longer than our traditional three-months. While we normally prefer to keep to our usual cadence, this shift gives us a unique opportunity to ship Debezium 2.2 with tons of new features and bug fixes, but also major upgrades to several core components.</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>Table of Contents:</p> </div> <div class="ulist"> <ul> <li> <p><a href="#debezium-2-2-breaking-changes">Breaking changes</a></p> </li> <li> <p><a href="#debezium-2-2-whats-new">What&#8217;s new?</a></p> </li> <li> <p><a href="#other-fixes-improvements">Other fixes &amp; improvements</a></p> </li> <li> <p><a href="#whats-next">What&#8217;s Next?</a></p> </li> </ul> </div> <div class="sect1"> <h2 id="debezium-2-2-breaking-changes">Breaking changes</h2> <div class="sectionbody"> <div class="paragraph"> <p>Before we dive into what&#8217;s new and changed, lets take a moment and discuss several breaking changes that took place in the Debezium 2.2 release:</p> </div> <div class="ulist"> <ul> <li> <p><a href="#breaking-change-zonedtimestamp-truncation">ZonedTimestamp truncation</a></p> </li> <li> <p><a href="#breaking-change-topic-and-schema-naming-changes">Topic and Schema naming changes</a></p> </li> <li> <p><a href="#breaking-change-oracle-source-info-block-changes">Oracle source-information block changes</a></p> </li> <li> <p><a href="#breaking-change-debezium-server-repository">Debezium Server moved to new repository</a></p> </li> <li> <p><a href="#breaking-change-sunset-dockerio">Sunset container image publication to docker.io</a></p> </li> </ul> </div> <div class="sect2"> <h3 id="breaking-change-zonedtimestamp-truncation">ZonedTimestamp truncation</h3> <div class="paragraph"> <p>An edge case was reported in <a href="https://issues.redhat.com/browse/issues/DBZ-5996">DBZ-5996</a> where if a temporal column used <code>ZonedTimestamp</code> and if the column&#8217;s value had <code>0</code> micro or nanoseconds, rather than emitting the value as <code>2023-01-19T12:30:00.123000Z</code>, the value would be emitted in a truncated way as <code>2023-01-19T12:30:00.123Z</code>. This could lead to other issues with converters used in the event pipeline when the output from that column could be formatted inconsistently.</p> </div> <div class="paragraph"> <p>In order to remedy the edge case, the <code>ZonedTimestamp</code> implementation will now pad the fraction-based seconds value of the column&#8217;s value to the length/scale of the source database column. Using the example above of a <code>TIMESTAMP(6)</code> MySQL column type, the emitted value will now properly reflect a value of <code>2023-01-19T12:30:00.123000Z</code>.</p> </div> <div class="paragraph"> <p>While this change in behavior is likely to have minimal impact to most users, we wanted to bring attention to it in the event that you&#8217;ve perhaps used other means to handle this edge case in your pipelines. If you have, you should be able to rely on Debezium to emit the value consistently, even when the fraction-based seconds is <code>0</code>.</p> </div> </div> <div class="sect2"> <h3 id="breaking-change-topic-and-schema-naming-changes">Topic and Schema naming changes</h3> <div class="paragraph"> <p>Debezium previously sanitized topic and schema names by using an underscore (<code>_</code>) to replace non-ASCII characters that would lead to unsupported topic or schema names when using schema registries. However, if this non-ASCII character was the only difference between two similar topics or schema names that otherwise only varied by case, this would lead to other problems.</p> </div> <div class="paragraph"> <p>In order to address this in the most compatible way, Debezium now uses a strategy-based approach to map characters uniquely. As a side effect of this change, the <code>sanitize.field.names</code> configuration property has been retired and replaced by this new strategy-based approach.</p> </div> <div class="paragraph"> <p>Each connector supports two configuration properties to control this behavior:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>schema.name.adjustment.mode</code></dt> <dd> <p>Specifies how schema names should be adjusted for compatibility with the message converter.</p> </dd> <dt class="hdlist1"><code>field.name.adjustment.mode</code></dt> <dd> <p>Specifies how field names should be adjusted for compatibility with the message converter.</p> </dd> </dl> </div> <div class="paragraph"> <p>These two connector configuration properties support three modes:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>none</code></dt> <dd> <p>No adjustment is made to the schema or field names, passed as-is.</p> </dd> <dt class="hdlist1"><code>avro</code></dt> <dd> <p>Replaces characters that cannot be used in Avro with an underscore (<code>_</code>).</p> </dd> <dt class="hdlist1"><code>avro_unicode</code></dt> <dd> <p>Replaces underscores (<code>_</code>) and characters that cannot be used in Avro with unicode-based characters.</p> </dd> </dl> </div> <div class="paragraph"> <p>This now allows you to pick the most appropriate strategy based on your table or collection naming convention.</p> </div> </div> <div class="sect2"> <h3 id="breaking-change-oracle-source-info-block-changes">Oracle source-information block changes</h3> <div class="paragraph"> <p>All Debezium change events related to inserts, updates, and deletes contain a <code>source</code> info block in the event&#8217;s payload. For the Oracle connector, this block contains a special field called <code>ssn</code> that represents the SQL sequence number for this change.</p> </div> <div class="paragraph"> <p>It has been identified that there were corner cases where the value sourced from the database for this field could exceed the maximum value of <code>2,147,483,647</code>, or the maximum value of an <code>INT32</code> data type. To fix this corner case, we&#8217;ve changed the data type from <code>INT32</code> to <code>INT64</code>, which allows up to a maximum value of <code>9,223,372,036,854,775,807</code>.</p> </div> <div class="paragraph"> <p>This change should be entirely non-invasive, but we wanted to bring attention to this should you have pipelines that could be storing this value in a sink system or if you are using a schema registry.</p> </div> </div> <div class="sect2"> <h3 id="breaking-change-debezium-server-repository">Debezium Server moved to new repository</h3> <div class="paragraph"> <p>Debezium Server is a standalone Quarkus-based runtime for Debezium source connectors enabling the integration with various platforms like EventHubs, PubSub, Pulsar, Redis, and Kafka, to name a few. With this release, we have moved the code related to Debezium Server to its own <a href="https://www.github.com/debezium/debezium-server">GitHub repository</a>.</p> </div> <div class="paragraph"> <p>This change was required in order to support building Debezium Server to include connectors that are not part of the main Debezium repository, connectors such as Db2, Google Spanner, Cassandra 4, and Vitess. Therefore, this means that starting with this release, Debezium Server now ships with all connectors (excluding Cassandra 3) by default.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>Cassandra 3 is excluded due to some technical limitations with class loading that creates conflicts with Cassandra 4. We are aware of this and plan to deliver a solution to include Cassandra 3 in the future.</p> </div> </td> </tr> </table> </div> </div> <div class="sect2"> <h3 id="breaking-change-sunset-dockerio">Sunset container image publication to docker.io</h3> <div class="paragraph"> <p>Debezium intends to sunset publishing container images to <code>docker.io</code> in June 2023. Some may be aware of recent policy changes at Docker around the reduction of their free organization plans, a plan that is used by a number of open-source projects including Debezium.</p> </div> <div class="paragraph"> <p>While Docker walked back their decision, this does raise a question about whether this could happen in the future. Debezium has been dual publishing container artifacts to <code>docker.io</code> and <code>quay.io</code> for quite some time, and we plan to continue doing so throughout this upcoming quarter with the <strong>preview</strong> releases of Debezium 2.3.</p> </div> <div class="paragraph"> <p>However, effective with the release of <strong>Debezium 2.3.0.Final</strong> at the end of June 2023, Debezium will cease publishing container artifacts to <code>docker.io</code> and will only be publishing container images moving forward to <code>quay.io</code>.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="debezium-2-2-whats-new">What&#8217;s new?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium 2.2 is packed with a plethora of new features, most notable are:</p> </div> <div class="ulist"> <ul> <li> <p>Containers</p> <div class="ulist"> <ul> <li> <p><a href="#new-jolokia">Jolokia support</a></p> </li> </ul> </div> </li> <li> <p>Core</p> <div class="ulist"> <ul> <li> <p><a href="#new-database-connection-retries-startup">Database connections retried on connector start-up</a></p> </li> <li> <p><a href="#new-extract-changed-record-state-smt">ExtractNewRecordState single message transformation</a></p> </li> <li> <p><a href="#new-drop-fields-extract-new-record-state-smt">Drop fields using ExtractNewRecordState single message transformation</a></p> </li> <li> <p><a href="#new-parallel-snapshots">Parallel Snapshots</a></p> </li> <li> <p><a href="#new-incremental-snapshots-surrogate-key">Incremental snapshots using surrogate key</a></p> </li> <li> <p><a href="#new-quarkus-3">Quarkus 3 support</a></p> </li> </ul> </div> </li> <li> <p>Connectors</p> <div class="ulist"> <ul> <li> <p>JDBC</p> <div class="ulist"> <ul> <li> <p><a href="#new-jdbc-sink">JDBC Sink connector</a></p> </li> </ul> </div> </li> <li> <p>Oracle</p> <div class="ulist"> <ul> <li> <p><a href="#new-oracle-logical-standby">Ingest changes from Oracle Logical standby instances</a></p> </li> </ul> </div> </li> <li> <p>Spanner</p> <div class="ulist"> <ul> <li> <p><a href="#new-spanner-postgresql-dialect">Google Spanner PostgreSQL dialect support</a></p> </li> </ul> </div> </li> </ul> </div> </li> <li> <p>Debezium Server</p> <div class="ulist"> <ul> <li> <p><a href="#new-infinispan-sink">Infinispan sink adapter</a></p> </li> <li> <p><a href="#new-rabbitmq-sink">RabbitMQ sink adapter</a></p> </li> <li> <p><a href="#new-rocketmq-sink">RocketMQ sink adapter</a></p> </li> <li> <p><a href="#new-pulsar-async-delivery">Pulsar asynchronous event delivery</a></p> </li> </ul> </div> </li> <li> <p>Outbox Quarkus Extension</p> <div class="ulist"> <ul> <li> <p><a href="#new-outbox-reactive-extension">Reactive Quarkus Outbox extension</a></p> </li> </ul> </div> </li> <li> <p>Storage API</p> <div class="ulist"> <ul> <li> <p><a href="#new-storage-amazon-s3-bucket">Amazon S3 bucket storage support</a></p> </li> <li> <p><a href="#new-storage-rocketmq">RocketMQ storage support</a></p> </li> </ul> </div> </li> </ul> </div> <div class="sect2"> <h3 id="new-jolokia">Jolokia support</h3> <div class="paragraph"> <p>Jolokia is a JMX-HTTP bridge that provides an alternative to using JSR-160 to gather metrics. It is an agent based approach that improves traditional JMX by introducing unique features like bulk requests and fine-grained security policies.</p> </div> <div class="paragraph"> <p>With Debezium 2.2, the <code>debezium/connect</code> image now ships with Jolokia, but this agent isn&#8217;t enabled by default. In order to enable Jolokia support, the container must be started with <code>ENABLE_JOLOKIA</code> set to <code>true</code>. By default, Jolokia will bind to port 8778 when enabled.</p> </div> <div class="paragraph"> <p>In the event that a different port is required, Jolokia will need to be enabled differently. For example, in order to enable Jolokia using port 9779, do not set the <code>ENABLE_JOLOKIA</code> but instead configure the <code>KAFKA_OPTS</code> environment variable as follows:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="propreties">-e KAFKA_OPTS=&quot;-javaagent:$(ls &quot;$KAFKA_HOME&quot;/libs/jolokia-jvm-*.jar)=port=9779,host=*&quot;</code></pre> </div> </div> <div class="paragraph"> <p>By specifying the above environment variable, Jolokia&#8217;s JMX-HTTP bridge will be available on port 9779 of the container.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>Do not forget to add the Jolokia port to the container&#8217;s list of exposed ports when starting.</p> </div> </td> </tr> </table> </div> </div> <div class="sect2"> <h3 id="new-database-connection-retries-startup">Database connections retried on connector start-up</h3> <div class="paragraph"> <p>In previous releases of Debezium, the connector start-up phase used a fail-fast strategy. Simply put, this meant that if we couldn&#8217;t connect, authenticate, or performs any of the start-up phase steps required by the connector, the connector would enter a <code>FAILED</code> state.</p> </div> <div class="paragraph"> <p>One specific problem area for users is if the connector gracefully starts, runs for a period of time, and then eventually encounters some fatal error. If the error is related to a resource that wasn&#8217;t accessed during the connector&#8217;s start-up lifecycle, the connector would typically gracefully restart just fine. However, the situation is different if the problem was related to the database&#8217;s availability and the database was still unavailable during the connector&#8217;s start-up phase. In this situation, the connector would fail-fast, and would enter a <code>FAILED</code> state, requiring manual intervention.</p> </div> <div class="paragraph"> <p>The fail-fast approach served Debezium well over the years, but in a world where a resource can come and go without warning, it became clear that changes were needed to improve Debezium&#8217;s reliability and resiliency. While the Kafka Connect&#8217;s retry/back-off framework has helped in this regard, that doesn&#8217;t address the concerns with start-up resources being unavailable with how the code is currently written.</p> </div> <div class="paragraph"> <p>Debezium 2.2 changes this landscape, shifting how we integrate with Kafka Connect&#8217;s source connector API slightly. Instead of accessing potentially unavailable resources during the start-up lifecycle, we moved that access to a later phase in the connector&#8217;s lifecycle. In effect, the Debezium start-up code is executed lazily that accesses potentially unavailable resources, which allows us to take advantage of the Kafka Connect retry/back-off framework even during our start-up code. In short, if the database is still unavailable during the connector&#8217;s start-up, the connector will continue to retry/back-off if Kafka Connect retries are enabled. Only once the maximum number of retry attempts has been reached or a non-retriable error occurs will the connector task enter a <code>FAILED</code> state.</p> </div> <div class="paragraph"> <p>We hope this brings more reliability and resiliency for the Debezium experience, improving how errors are handled in an ever-changing landscape, and provides a solid foundation to manage connector lifecycles.</p> </div> </div> <div class="sect2"> <h3 id="new-extract-changed-record-state-smt">ExtractNewRecordState single message transformation</h3> <div class="paragraph"> <p>We have heard from the community on several occasions that it would great to have an out-of-the-box way to determine what values have changed in a Debezium change event. The new single message transform (SMT) <code>ExtractChangedRecordState</code> aims to deliver on this request by adding metadata to the event identifying which fields changed or were unchanged.</p> </div> <div class="paragraph"> <p>In order to get started with this new transformation, configure it as part of your connector configuration:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">transforms=changes
transforms.changes.type=io.debezium.transforms.ExtractChangedRecordState
transforms.changes.header.changed=ChangedFields
transforms.changes.header.unchanged=UnchangedFields</code></pre> </div> </div> <div class="paragraph"> <p>This transformation can be configured to disclose either what fields changed by setting <code>header.changed</code>, what fields are unchanged by setting <code>header.unchanged</code>, or both by setting both properties as shown above. The transformation will add a new header with the specified name, and it&#8217;s value will include a collection of field names based on whether you&#8217;ve configured changes, non-changes, or both.</p> </div> </div> <div class="sect2"> <h3 id="new-drop-fields-extract-new-record-state-smt">Drop fields using ExtractNewRecordState single message transformation</h3> <div class="paragraph"> <p>The <code>ExtractNewRecordState</code> single message transformation is extremely useful in situations where you need to consume the Debezium change event in a <em>flattened</em> format. This SMT has been changed in this release to add the ability to drop fields from the payload and the message key of the event.</p> </div> <div class="paragraph"> <p>This new feature introduces three new configuration properties for the transformation:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>drop.fields.header.name</code></dt> <dd> <p>The Kafka message header name to use for listing field names in the source message that are to be dropped.</p> </dd> <dt class="hdlist1"><code>drop.fields.from.key</code></dt> <dd> <p>Specifies whether to remove fields also from the key, defaults to <code>false</code>.</p> </dd> <dt class="hdlist1"><code>drop.fields.keep.schema.compatible</code></dt> <dd> <p>Specifies whether to remove fields that are only optional, defaults to <code>true</code>.</p> </dd> </dl> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>When using Avro, schema compatibility is extremely important. This is why we opted to enforce schema compatibility by default. If a field is configured to be dropped but it is non-optional, the field will not be removed from the key nor the payload unless schema compatibility is disabled.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>These new configuration options allow for some exciting ways to manipulate change events. For example, to emit events with only changed fields, pairing the <code>ExtractNewRecordState</code> with the new <code>ExtractChangedRecordState</code> transformation makes this extremely simple and straightforward. An example configuration to only emit changed columns would look like the following:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">transforms=changes,extract
transforms.changes.type=io.debezium.transforms.ExtractChangedRecordState
transforms.changes.header.unchanged=UnchangedFields
transforms.extract.type=io.debezium.transforms.ExtractNewRecordState
transforms.extract.drop.fields.header.name=UnchangedFields</code></pre> </div> </div> <div class="paragraph"> <p>The above configuration will explicitly not include unchanged fields from the event&#8217;s payload value. If a field in the key did not change, it will be unaffected because <code>drop.fields.from.key</code> was left as its default of <code>false</code>. And finally, if a field in the event&#8217;s payload is to be dropped because it did not change, but it&#8217;s not optional, it will continue to be included in the transformation&#8217;s output event to comply with schema compatibility.</p> </div> </div> <div class="sect2"> <h3 id="new-parallel-snapshots">Parallel Snapshots</h3> <div class="paragraph"> <p>Debezium&#8217;s relational database initial snapshot process has always been single-threaded. This limitation primarily stems from the complexities of ensuring data consistency across multiple transactions.</p> </div> <div class="paragraph"> <p>Starting in Debezium 2.2, we&#8217;re adding a new and initially optional way to utilize multiple threads to perform consistent database snapshot for a connector. This implementation uses these multiple threads to execute table-level snapshots in parallel.</p> </div> <div class="paragraph"> <p>In order to take advantage of this new feature, specify <code>snapshot.max.threads</code> in your connector&#8217;s configuration and when this property has a value greater than <code>1</code>, parallel snapshots will be used.</p> </div> <div class="listingblock"> <div class="title">Example configuration using parallel snapshots</div> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">snapshot.max.threads=4</code></pre> </div> </div> <div class="paragraph"> <p>In the example above, if the connector needs to snapshot more than 4 tables, there will be at most 4 tables being snapshot in parallel. When one thread finishes processing a table, it will get a new table to snapshot from the queue and the process continues until all tables have been snapshot.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>This feature is considered <em>incubating</em>, but we strongly suggest that new connector deployments give this feature a try. We would welcome any and all feedback on how to improve this going forward.</p> </div> </td> </tr> </table> </div> </div> <div class="sect2"> <h3 id="new-incremental-snapshots-surrogate-key">Incremental snapshots using surrogate key</h3> <div class="paragraph"> <p>Debezium&#8217;s incremental snapshot feature has been a tremendous success. It provides an efficient way to perform a consist snapshot of data that can be resumed, which is critical when the snapshot consists of large volumes of data.</p> </div> <div class="paragraph"> <p>However, incremental snapshots do have specific requirements that must be met before the feature can be used. One of those requirements is all tables being snapshot must use a primary key. You may ask, why does a table have no primary key, and we aren&#8217;t going to debate that here today; however, suffice to say this occurs more often than you may think.</p> </div> <div class="paragraph"> <p>With Debezium 2.2, incremental snapshots can be performed on key-less tables as long as there is one column that is unique and can be considered a "surrogate key" for incremental snapshot purposes.</p> </div> <div class="admonitionblock warning"> <table> <tr> <td class="icon"> <i class="fa icon-warning" title="Warning"></i> </td> <td class="content"> <div class="paragraph"> <p>The surrogate key feature is not supported by MongoDB; only relational connectors.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>To provide the surrogate key column data in an incremental snapshot signal, the signal&#8217;s payload must include the new surrogate key attribute, <code>surrogate-key</code>.</p> </div> <div class="listingblock json"> <div class="title">An example incremental snapshot signal payload specifying a surrogate key</div> <div class="content"> <pre class="CodeRay highlight"><code>{
  "data-collections": [ "public.mytab" ],
  "surrogate-key": "customer_ref"
}</code></pre> </div> </div> <div class="paragraph"> <p>In the above example, an incremental snapshot will be started for table <code>public.mytab</code> and the incremental snapshot will use the <code>customer_ref</code> column as the primary key for generating the snapshot windows.</p> </div> <div class="admonitionblock warning"> <table> <tr> <td class="icon"> <i class="fa icon-warning" title="Warning"></i> </td> <td class="content"> <div class="paragraph"> <p>A surrogate key cannot be defined using multiple columns, only a <strong>single</strong> column.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>However, the surrogate key feature isn&#8217;t just applicable for tables with no primary keys. There are a series of advantages when using this feature with tables that have primary keys:</p> </div> <div class="olist arabic"> <ol class="arabic"> <li> <p>One clear advantage is when the table&#8217;s primary key consists of multiple columns. The query generates a disjunction predicate for each column in the primary key, and it&#8217;s performance is highly dependent on the environment. Reducing the number of columns down to a single column often performs universally.</p> </li> <li> <p>Another advantage is when the surrogate key is based on a numeric data type while the primary key column is based on a character-based data type. Relational databases generally perform predicate evaluation more efficiently with numeric comparisons rather than character comparisons. By adjusting the query to use a numeric data type in this case, query performance could be better.</p> </li> </ol> </div> </div> <div class="sect2"> <h3 id="new-quarkus-3">Quarkus 3 support</h3> <div class="paragraph"> <p>Quarkus is a Kubernetes Native Java stack that combines the best Java libraries to create fast, low footprint applications. The Debezium Server runtime is based on Quarkus as well as part of Debezium UI. Additionally, the Debezium Outbox extension is also based on the Quarkus platform.</p> </div> <div class="paragraph"> <p>The upgrade to Quarkus 3 introduces a number of improvements, including using the latest stable releases of a plethora of Java libraries, including the migration from Java EE to Jakarta EE. If you are not familiar with this migration, previously most Java EE platform classes were bundled in the package <code>javax.*</code>. Over the past year or two, more applications have started the move from JavaEE or J2EE to Jakarta EE, and Quarkus 3 marks this transition era. Overall, the only real change is that classes that previously resided in <code>javax.*</code> now are placed in <code>jakarta.*</code>.</p> </div> <div class="paragraph"> <p>If your application makes use of the Debezium Quarkus Outbox extension, be aware that in order to use Debezium 2.2 with Quarkus, you will need to migrate to Quarkus 3. This also means that if you want to take advantage of the Outbox extension for Reactive data sources, you will be required to use Quarkus 3 as well.</p> </div> <div class="paragraph"> <p>Finally, if you are developing or maintaining sink adapters for Debezium Server, you will also need to make adjustments to using the new Jakarta EE annotations rather than the older Java EE annotations.</p> </div> </div> <div class="sect2"> <h3 id="new-jdbc-sink">JDBC Sink connector</h3> <div class="paragraph"> <p>The Debezium 2.2 release ushers in a new era for Debezium which has had a longstanding focus purely on providing a set of source connectors for relational and non-relational databases. This release alters that landscape, introducing a new JDBC sink connector implementation.</p> </div> <div class="paragraph"> <p>The Debezium JDBC sink connector is quite different from other vendor implementations in that it is capable of ingesting change events emitted by Debezium connectors without the need for event flattening. This has the potential to reduce the processing footprint in your pipeline, simplifies the pipeline&#8217;s configuration, and allows Debezium&#8217;s JDBC sink connector to take advantage of numerous Debezium source connector features such as column type propagation and much more.</p> </div> <div class="paragraph"> <p>Getting started with the Debezium JDBC sink connector is quite simple, lets take a look at an example.</p> </div> <div class="paragraph"> <p>Let&#8217;s say we have a Kafka topic called <code>orders</code> that contains Debezium change events that were created without using the <code>ExtractNewRecordState</code> transformation from MySQL. A simple configuration to ingest these change events into a PostgreSQL database might look this the following:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">mysql-to-postgres-pipeline</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">config</span><span class="delimiter">&quot;</span></span>: {
    <span class="key"><span class="delimiter">&quot;</span><span class="content">connector_class</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">io.debezium.connector.jdbc.JdbcSinkConnector</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">topics</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">orders</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">connection.url</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">jdbc://postgresql://&lt;host&gt;:&lt;port&gt;/&lt;database&gt;</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">connection.user</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">&lt;username&gt;</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">connection.password</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">&lt;password&gt;</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">insert.mode</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">upsert</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">delete.enabled</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">primary.key.mode</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record_key</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">schema.evolution</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">basic</span><span class="delimiter">&quot;</span></span>
  }
}</code></pre> </div> </div> <div class="paragraph"> <p>In this example, we&#8217;ve specified a series of <code>connection.*</code> properties that define the connection string and credentials for accessing the destination PostgreSQL database. Additionally, records will use <em>UPSERT</em> semantics when writing to the destination database, choosing to use an insert if the record doesn&#8217;t exist or updating the record if it does. We have also enabled schema evolution and specified that a table&#8217;s key columns should be derived from the event&#8217;s primary key.</p> </div> <div class="paragraph"> <p>The JDBC sink connector presently has support for the following relational databases:</p> </div> <div class="ulist"> <ul> <li> <p>Db2</p> </li> <li> <p>MySQL</p> </li> <li> <p>Oracle</p> </li> <li> <p>PostgreSQL</p> </li> <li> <p>SQL Server</p> </li> </ul> </div> <div class="paragraph"> <p>We do intend to add additional dialects in the future, and if there one you&#8217;d like to see, please get in touch with us either on our mailing list, in chat, or opening a Jira enhancement.</p> </div> </div> <div class="sect2"> <h3 id="new-oracle-logical-standby">Ingest changes from Oracle Logical standby instances</h3> <div class="paragraph"> <p>The Debezium for Oracle connector normally manages what is called a <em>flush table</em>, which is an internal table used to manage the flush cycles used by the Oracle Log Writer Buffer (LGWR) process. This flushing process requires that the user account the connector uses to have permission to create and write to this table. Logical stand-by databases often have more restrictive rules about data manipulation and may even be read-only, therefore, writing to the database is unfavorable or even not permissible.</p> </div> <div class="paragraph"> <p>To support an Oracle read-only logical stand-by database, we introduced a flag to disable the creation and management of this <em>flush table</em>. This feature can be used with both Oracle Standalone and Oracle RAC installations, and is currently considered incubating, meaning its subject to change in the future.</p> </div> <div class="paragraph"> <p>In order to enable Oracle read-only logical stand-by support, add the following connector option:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">internal.log.mining.read.only=true</code></pre> </div> </div> <div class="paragraph"> <p>In a future version, we plan to add support for an Oracle read-only physical stand-by database.</p> </div> </div> <div class="sect2"> <h3 id="new-spanner-postgresql-dialect">Google Spanner PostgreSQL dialect support</h3> <div class="paragraph"> <p>Google&#8217;s Cloud Spanner platform supports a PostgreSQL interface, which combines the scalability and reliability of the Google Spanner platform with the familiarity and portability of PostgreSQL. When operating Google Spanner with this PostgreSQL interface, metadata of columns and tables is different than when using the standard GoogleSQL dialect.</p> </div> <div class="paragraph"> <p>This release extends the Debezium Spanner connector support not only for the GoogleSQL dialect but also for users that use the Spanner PostgreSQL dialect feature. This means regardless of which dialect your spanner environment relies on, you will be able to capture change events from Spanner using the Debezium Spanner connector seamlessly.</p> </div> </div> <div class="sect2"> <h3 id="new-infinispan-sink">Infinispan sink adapter</h3> <div class="paragraph"> <p><a href="https://infinispan.org">Infinispan</a> is an in-memory, distributed data store that offers flexible deployment options with robust capabilities to store, manage, and process data. Infinispan is based on the notion of a key-value store that allows storing any data type. In order to integrate Debezium Server with Infinispan, the Debezium Server <code>application.properties</code> must be modified to include the following entries:</p> </div> <div class="listingblock"> <div class="title">application.properties</div> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">debezium.sink.type=infinispan
debezium.sink.infinispan.server.host=&lt;hostname&gt;
debezium.sink.infinispan.server.port=&lt;port&gt;
debezium.sink.infinispan.cache=&lt;cache-name&gt;
debezium.sink.infinispan.user=&lt;user&gt;
debezium.sink.infinispan.password=&lt;password&gt;</code></pre> </div> </div> <div class="paragraph"> <p>The above configuration specifies that the sink type to be used is <code>infinispan</code>, which enables the use of the Infinispan module. The following is a description of each of the properties shown above:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>debezium.sink.infinispan.server.host</code></dt> <dd> <p>Specifies the host name of one of the servers in the Infinispan cluster. This configuration option can also supply a comma-separated list of hostnames as well, such as <code>hostname1,hostname2</code>.</p> </dd> <dt class="hdlist1"><code>debezium.sink.infinispan.server.port</code></dt> <dd> <p>Specifies the port of the Infinispan cluster. Defaults to <code>11222</code>.</p> </dd> <dt class="hdlist1"><code>debezium.sink.infinispan.cache</code></dt> <dd> <p>Specifies the name of the Infinispan cache to write change events.</p> </dd> </dl> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>The Infinispan sink requires that the cache be created manually ahead of time. This enables the ability to create the cache with any variable configuration needed to fit your requirements.</p> </div> </td> </tr> </table> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>debezium.sink.infinispan.user</code></dt> <dd> <p>An optional configuration to specify the user to authenticate with, if authentication is required.</p> </dd> <dt class="hdlist1"><code>debezium.sink.infinispan.password</code></dt> <dd> <p>An optional configuration to specify the password for the authenticating user, if authentication is required.</p> </dd> </dl> </div> <div class="paragraph"> <p>For more information on using Debezium Server with Infinispan, see the <a href="/documentation/reference/2.2/operations/debezium-server.html#_infinispan">documentation</a>.</p> </div> </div> <div class="sect2"> <h3 id="new-rabbitmq-sink">RabbitMQ sink adapter</h3> <div class="paragraph"> <p>Debezium 2.2 introduces a new sink adapter to the Debezium Server portfolio, allowing Debezium users to send change events to RabbitMQ. The following configuration shows a simple example of how easy it is to configure:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">debezium.sink.type=rabbitmq

# Connection details
debezium.sink.rabbitmq.connection.host=&lt;hostname&gt;
debezium.sink.rabbitmq.connection.port=&lt;port&gt;

# The routing key specifies an override of where events are published
debezium.sink.rabbitmq.routingKey=&lt;routing-key&gt;

# The default is 30 seconds, specified in milliseconds
debezium.sink.rabbitmq.ackTimeout=30000</code></pre> </div> </div> <div class="paragraph"> <p>The <code>debezium.sink.rabbitmq.connection.*</code> properties are required while the latter two properties for <code>routingKey</code> and <code>ackTimeout</code> are optional or have preset defaults that should be sufficient for most use cases.</p> </div> </div> <div class="sect2"> <h3 id="new-rocketmq-sink">RocketMQ sink adapter</h3> <div class="paragraph"> <p><a href="https://rocketmq.apache.org">Apache RocketMQ</a> is a cloud-native messaging, eventing, and streaming real-time data processing platform that covers cloud-edge-device collaboration scenarios. In order to integrate Debezium Server with RocketMQ, the Debezium Server <code>application.properties</code> must be modified to include the following entries:</p> </div> <div class="listingblock"> <div class="title">application.properties</div> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">debezium.sink.type=rocketmq
debezium.sink.rocketmq.producer.name.srv.addr=&lt;hostname&gt;:&lt;port&gt;
debezium.sink.rocketmq.producer.group=debezuim-group
debezium.sink.rocketmq.producer.max.message.size=4194304
debezium.sink.rocketmq.producer.send.msg.timeout=3000
debezium.sink.rocketmq.producer.acl.enabled=false
debezium.sink.rocketmq.producer.access.key=&lt;access-key&gt;
debezium.sink.rocketmq.producer.secret.key=&lt;secret-key&gt;</code></pre> </div> </div> <div class="paragraph"> <p>The above configuration specifies that the sink type to be used is <code>rocketmq</code>, which enables the use of the RocketMQ module. The following is a description of each of the properties shown above:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.name.srv.addr</code></dt> <dd> <p>Specifies the host and port where Apache RocketMQ is available.</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.group</code></dt> <dd> <p>Specifies the name associated with the Apache RocketMQ producer group.</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.max.message.size</code></dt> <dd> <p>(Optional) Specifies the maximum number of bytes a message can be. Defaults to <code>4193404</code> (4MB).</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.send.msg.timeout</code></dt> <dd> <p>(Optional) Specifies the timeout in milliseconds when sending messages. Defaults to <code>3000</code> (3 seconds).</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.acl.enabled</code></dt> <dd> <p>(Optional) Controls whether access control lists are enabled. Defaults to <code>false</code>.</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.access.key</code></dt> <dd> <p>(Optional) The access key used for connecting to the Apache RocketMQ cluster.</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.secret.key</code></dt> <dd> <p>(Optional) The access secret used for connecting to the Apache RocketMQ cluster.</p> </dd> </dl> </div> <div class="paragraph"> <p>For more information on using Debezium Server with RocketMQ, see the <a href="/documentation/reference/2.2/operations/debezium-server.html#_apache_rocketmq">documentation</a>.</p> </div> </div> <div class="sect2"> <h3 id="new-pulsar-async-delivery">Pulsar asynchronous event delivery</h3> <div class="paragraph"> <p>In prior versions of the Debezium Server Pulsar sink, the adapter leveraged the <code>send()</code> method to deliver messages in a synchronous way. While this works for sending one-off messages, this has the potential to introduce connector latency as the method waits an acknowledgement of send operation sequentially. Since the Debezium Server sink adapters are provided a collection of events to deliver, the synchronous nature just does not perform well.</p> </div> <div class="paragraph"> <p>Starting Debezium 2.2, the Pulsar sink will now use <code>sendAsync()</code> to asynchronously deliver the batch of events to Pulsar, netting a substantial increase in overall throughput. While each event within the batch is delivered asynchronously, the adapter will only proceed to the next batch once the current batch is acknowledged in entirety.</p> </div> </div> <div class="sect2"> <h3 id="new-outbox-reactive-extension">Reactive Quarkus Outbox extension</h3> <div class="paragraph"> <p>The <a href="https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/">outbox pattern</a> is an approach that many microservices leverage to share data across microservice boundaries. We introduced the Debezium Outbox Quarkus Extension in Debezium 1.1 back in early 2020, and it has allowed Quarkus users to leverage the outbox pattern with ease using Debezium.</p> </div> <div class="paragraph"> <p>Thanks to <a href="https://github.com/ingmarfjolla">Ingmar Fjolla</a>, Debezium 2.2 includes a new reactive-based implementation of the Debezium Outbox Quarkus Extension. This new implementation is based on Vert.x and Hibernate Reactive, providing a fully asynchronous solution to the outbox pattern using Debezium.</p> </div> <div class="paragraph"> <p>This new extension is included in the Quarkus 3 platform released later this month. However if you want to get started with it today, you can easily drop it directly into your project&#8217;s configuration using the following coordinates:</p> </div> <div class="listingblock"> <div class="title">Maven coordinates</div> <div class="content"> <pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
  <span class="tag">&lt;groupId&gt;</span>io.debezium<span class="tag">&lt;/groupId&gt;</span>
  <span class="tag">&lt;artifactId&gt;</span>debezium-quarkus-outbox-reactive<span class="tag">&lt;/artifactId&gt;</span>
  <span class="tag">&lt;version&gt;</span>2.2.0.Final<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre> </div> </div> <div class="listingblock"> <div class="title">Gradle coordinates</div> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">io.debezium:debezium-quarkus-outbox-reactive:2.2.0.Final</code></pre> </div> </div> </div> <div class="sect2"> <h3 id="new-storage-amazon-s3-bucket">Amazon S3 bucket storage support</h3> <div class="paragraph"> <p>Debezium provides a Storage API framework that enables connectors to store offset and schema history state in a variety of persistence datastores. Moreover, the framework enables contributors to extend the API by adding new storage implementations with ease. Currently, the Storage API framework supports the local FileSystem, a Kafka Topic, or Redis datastores.</p> </div> <div class="paragraph"> <p>With Debezium 2.2, we&#8217;re pleased to add Amazon S3 buckets as part of that framework, allowing the schema history to be persisted to an S3 bucket. An example connector configuration using S3 might look like the following:</p> </div> <div class="listingblock properties"> <div class="content"> <pre class="CodeRay highlight"><code>...
schema.history.internal=io.debezium.storage.s3.history
schema.history.internal.s3.access.key.id=aa
schema.history.internal.s3.secret.access.key=bb
schema.history.internal.s3.region.name=aws-global
schema.history.internal.s3.bucket.name=debezium
schema.history.internal.s3.object.name=db-history.log
schema.history.internal.s3.endpoint=http://&lt;server&gt;:&lt;port&gt;</code></pre> </div> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>schema.history.internal.s3.access.key.id</code></dt> <dd> <p>Specifies the access key required to authenticate to S3.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.s3.secret.access.key</code></dt> <dd> <p>Specifies the secret access key required to authenticate to S3.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.s3.region.name</code></dt> <dd> <p>Specifies the region where the S3 bucket is available.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.s3.bucket.name</code></dt> <dd> <p>Specifies the name of the S3 bucket where the schema history is to be persisted.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.s3.object.name</code></dt> <dd> <p>Specifies the object name in the bucket where the schema history is to be persisted.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.s3.endpoint</code></dt> <dd> <p>Specifies the S3 endpoint with the format of <code><a href="http://&lt;server&gt;:&lt;port&gt" class="bare">http://&lt;server&gt;:&lt;port&gt</a>;</code>.</p> </dd> </dl> </div> </div> <div class="sect2"> <h3 id="new-storage-rocketmq">RocketMQ storage support</h3> <div class="paragraph"> <p>Debezium&#8217;s new storage API has been a huge success over this past year. We initially started with our original file and Kafka based implementations for offset and schema history storage, but that has since grown to support storing schema history on other platforms such as Amazon S3 and Redis.</p> </div> <div class="paragraph"> <p>This release continues to expand on this by adding a new schema history storage implementation for Rocket MQ. In order to get started with storing your schema history into Rocket MQ, the <code>debezium-storage-rocketmq</code> dependency must first be on the classpath and accessible by the connector runtime.</p> </div> <div class="paragraph"> <p>Once the dependency exists, the only remaining step will be configuring the schema history connector configuration. The following example shows basic usage of the Rocket MQ schema history:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">schema.history.internal.rocketmq.topic=schema-history
schema.history.internal.rocketmq.name.srv.addr=172.17.15.2
schema.history.internal.rocketmq.acl.enabled=true
schema.history.internal.rocketmq.access.key=&lt;rocketmq-access-key&gt;
schema.history.internal.rocketmq.secret.key=&lt;rocketmq-secret-key&gt;
schema.history.internal.rocketmq.recovery.attempts=5
schema.history.internal.rocketmq.recovery.poll.interval.ms=1000
schema.history.internal.rocketmq.store.record.timeout.ms=2000</code></pre> </div> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>schema.history.internal.rocketmq.topic</code></dt> <dd> <p>Specifies the topic name where the schema history will be stored.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.name.srv.addr</code></dt> <dd> <p>Specifies the service discovery service nameserver for Rocket MQ.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.acl.enabled</code></dt> <dd> <p>Specifies whether access control lists (ACLs) are enabled, defaults to <code>false</code>.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.access.key</code></dt> <dd> <p>Specifies the Rocket MQ access key, required only if ACLs are enabled.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.secret.key</code></dt> <dd> <p>Specifies the Rocket MQ secret key, required only if ACLs are enabled.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.recovery.attempts</code></dt> <dd> <p>Specifies the number of sequential attempts that no data is returned before recovery completes.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.recovery.poll.interval.ms</code></dt> <dd> <p>Specifies the number of milliseconds for each poll attempt to recover the history.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.store.record.timeout.ms</code></dt> <dd> <p>Specifies the number of milliseconds for a write to Rocket MQ to complete before timing out.</p> </dd> </dl> </div> </div> </div> </div> <div class="sect1"> <h2 id="other-fixes-improvements">Other fixes &amp; improvements</h2> <div class="sectionbody"> <div class="paragraph"> <p>There were many bugfixes, stability changes, and improvements throughout the development of Debezium 2.2. Altogether, a total of <a href="https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(2.2.0.Alpha1%2C%202.2.0.Alpha2%2C%202.2.0.Alpha3%2C%202.2.0.Beta1%2C%202.2.0.CR1%2C%202.2.0.Final)%20ORDER%20BY%20component%20ASC">228 issues</a> were fixed for this release.</p> </div> <div class="paragraph"> <p>A big thank you to all the contributors from the community who worked on this release: Akshansh Jain, Đỗ Ngọc Sơn, <a href="https://github.com/AnatolyPopov">Anatolii Popov</a>, <a href="https://github.com/ggaborg">Gabor Andras</a> <a href="https://github.com/adasari">Anil Dasari</a>, <a href="https://github.com/akanimesh7">Animesh Kumar</a>, <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/btiernay">Bobby Tiernay</a>, <a href="https://github.com/bruth">Byron Ruth</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/erdinctaskin">Erdinç Taşkın</a>, <a href="https://github.com/EugeneAbramchuk">Eugene Abramchuk</a>, <a href="https://github.com/ggaborg">Gabor Andras</a>, <a href="https://github.com/govi20">Govinda Sakhare</a>, <a href="https://github.com/gunnarmorling">Gunnar Morling</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/henkosch">Henrik Schnell</a>, <a href="https://github.com/HenryCaiHaiying">Henry Cai</a>, <a href="https://github.com/blcksrx">Hossein Torabi</a>, <a href="https://github.com/indraraj">Indra Shukla</a>, <a href="https://github.com/ingmarfjolla">Ingmar Fjolla</a>, <a href="https://github.com/ismailsimsek">Ismail Simsek</a>, <a href="https://github.com/jbarrieault">Jacob Barrieault</a>, <a href="https://github.com/sugarcrm-jgminder">Jacob Gminder</a>, <a href="https://github.com/jcechace">Jakub Cechacek</a>, <a href="https://github.com/jakzal">Jakub Zalas</a>, <a href="https://github.com/jeremy-l-ford">Jeremy Ford</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/joschi">Jochen Schalanda</a>, <a href="https://github.com/echatman-ias">Liz Chatman</a>, <a href="https://github.com/lokesh1729">Lokesh Sanapalli</a>, <a href="https://github.com/Lucascanna">Luca Scannapieco</a>, <a href="https://github.com/mfvitale">Mario Fiore Vitale</a>, <a href="https://github.com/alwaysbemark">Mark Bereznitsky</a>, <a href="https://github.com/dude0001">Mark Lambert</a>, <a href="https://github.com/MartinMedek">Martin Medek</a>, <a href="https://github.com/MehmetFiratKomurcu">Mehmet Firat Komurcu</a>, <a href="https://github.com/MyLanPangzi">My Lang Pangzi</a>, <a href="https://github.com/nirolevy">Nir Levy</a>, <a href="https://github.com/olivierboudet">Olivier Boudet</a>, <a href="https://github.com/obabec">Ondrej Babec</a>, <a href="https://github.com/smallYellowCat">Pengwei Dou</a>, <a href="https://github.com/PlugaruT">Plugaru Tudor</a>, <a href="https://github.com/rnowling-memphis">RJ Nowling</a>, <a href="https://github.com/rajdangwal">Rajendra Dangwal</a>, <a href="https://github.com/roldanbob">Robert Roldan</a>, <a href="https://github.com/ironakj">Ronak Jain</a>, <a href="https://github.com/Apteryx0">Russell Mora</a>, <a href="https://github.com/morozov">Sergei Morozov</a>, <a href="https://github.com/smiklosovic">Stefan Miklosovic</a>, <a href="https://github.com/subodh1810">Subodh Kant Chaturvedi</a>, <a href="https://github.com/sunxiaojian">Sun Xiao Jian</a>, <a href="https://github.com/twthorn">Thomas Thornton</a>, <a href="https://github.com/chtitux">Théophile Helleboid</a>, <a href="https://github.com/Tideri-Tim2">Tim Loes</a>, <a href="https://github.com/vjuranek">Vojtech Juranek</a>, <a href="https://github.com/vjuranek">Vojtěch Juránek</a>, <a href="https://github.com/xinbinhuang">Xinbin Huang</a>, <a href="https://github.com/y5w">Yang Wu</a>, <a href="https://github.com/yoheimuta">Yohei Yoshimuta</a>, <a href="https://github.com/zzzming">ming luo</a>, <a href="https://github.com/imtj1">tony joseph</a>, <a href="https://github.com/yoheimuta">yohei yoshimuta</a>, and <a href="https://github.com/caicancai">蔡灿材</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="whats-next">What&#8217;s Next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>We began pre-planning Debezium 2.3 several weeks ago and with 2.2 shipped, our focus will now be on the next minor release. With Debezium 2.2 release cycle being a tad longer than normal, the release cycle for 2.3 will be condensed as we want to return to our end-of-quarter release cadence. In order to achieve that goal, we&#8217;ve chosen to focus on the following features for the next minor release:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1">Configurable Signal Channels</dt> <dd> <p>The goal of this change is to provide a way in which signals can be sent to a connector from a variety of sources, including things like the filesystem, Kafka topic, database table, etc.</p> </dd> <dt class="hdlist1">Exactly once delivery semantics</dt> <dd> <p>Debezium currently only guarantees at-least-once delivery semantics, meaning that a change event could be written to a topic more than once in the case of unsafe shutdowns or failures of a connector. Kafka and by extension Kafka Connect, now support exactly-once delivery and we want to explore this feature as part of Debezium. The goal is to focus adding this to at least once connector as a proof of concept and based on feedback, extend this to all connectors.</p> </dd> <dt class="hdlist1">Kubernetes operator for Debezium Server</dt> <dd> <p>Debezium Server has gained quite a bit of exposure in recent months, both with new sink adapters and just general usage by the community. We want to bring the power of Kubernetes to Debezium Server, introducing an operator that you can deploy in order to manage the full lifecycle of a Debezium Server deployment.</p> </dd> <dt class="hdlist1">Ingestion from Oracle using OpenLogReplicator</dt> <dd> <p>The Debezium Oracle connector presents supports ingestion of changes using XStream or LogMiner. We want to build a proof-of-concept using OpenLogReplicator, a native application that is capable of reading the Oracle redo and archive logs directly from the file system. We do not intend to replace either of the existing adapters with this new approach, but to instead extend the connector&#8217;s functionality to offer alternatives to data ingestion that may have less overhead.</p> </dd> <dt class="hdlist1">Debezium UI Enhancements</dt> <dd> <p>We believe there is a lot of unlocked potential with Debezium UI, so this release will focus on improving that overall user experience by adding new features like starting/stopping ad-hoc snapshots, editing connector deployments, and displaying critical connector metrics.</p> </dd> </dl> </div> <div class="paragraph"> <p>While the team intends to focus on the above improvements, we would really like your feedback or suggestions. If you have anything that you&#8217;d like to share, be sure to get in touch with us on the <a href="https://groups.google.com/g/debezium">mailing list</a> or our <a href="https://debezium.zulipchat.com/login/#narrow/stream/302529-users">chat</a>.</p> </div> <div class="paragraph"> <p>Until next time&#8230;&#8203;</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="mongodb"/><category term="spanner"/><summary type="html"><![CDATA[Today, it&#8217;s with great joy that we can announce the availability of Debezium 2.2.0.Final! Many of you may have noticed, this release cadence took a bit longer than our traditional three-months. While we normally prefer to keep to our usual cadence, this shift gives us a unique opportunity to ship Debezium 2.2 with tons of new features and bug fixes, but also major upgrades to several core components.]]></summary></entry><entry><title type="html">Debezium 2.2.0.CR1 Released</title><link href="https://debezium.io/blog/2023/04/17/debezium-2-2-cr1-released/" rel="alternate" type="text/html" title="Debezium 2.2.0.CR1 Released"/><published>2023-04-17T00:00:00+00:00</published><updated>2023-04-17T00:00:00+00:00</updated><id>https://debezium.io/blog/2023/04/17/debezium-2-2-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2023/04/17/debezium-2-2-cr1-released/"><![CDATA[<div class="paragraph"> <p>The Debezium team is excited to announce the first release candidate of Deebzium 2.2, Debezium <strong>2.2.0.CR1</strong>.</p> </div> <div class="paragraph"> <p>This release primarily focuses on stability improvements and bug fixes; however, there are a number of new features and breaking changes. In this release, Debezium migrated to Quarkus 3.0.0.Final, there are performance improvements to Debezium Server Pulsar sink, Jolokia can be enabled inside Debezium&#8217;s Kafka Connect container image, incubating support for incremental snapshots on MongoDB multi-replica and sharded clusters, and the deprecation usage of Docker Hub for images.</p> </div> <div class="paragraph"> <p>Let&#8217;s take a moment and dive into several of these and what it means moving forward!</p> </div> <div class="paragraph"> <p></p> </div> <div class="sect1"> <h2 id="upgrade_to_quarkus_3">Upgrade to Quarkus 3</h2> <div class="sectionbody"> <div class="paragraph"> <p>Quarkus is a Kubernetes Native Java stack that combines the best Java libraries to create fast, low footprint applications. The Debezium Server runtime is based on Quarkus as well as part of Debezium UI. Additionally, the Debezium Outbox extension is also based on the Quarkus platform.</p> </div> <div class="paragraph"> <p>The upgrade to Quarkus 3 introduces a number of improvements, including using the latest stable releases of a plethora of Java libraries, including the migration from Java EE to Jakarta EE. If you are not familiar with this migration, previously most Java EE platform classes were bundled in the package <code>javax.*</code>. Over the past year or two, more applications have started the move from JavaEE or J2EE to Jakarta EE, and Quarkus 3 marks this transition era. Overall, the only real change is that classes that previously resided in <code>javax.*</code> now are placed in <code>jakarta.*</code>.</p> </div> <div class="paragraph"> <p>If your application makes use of the Debezium Quarkus Outbox extension, be aware that in order to use Debezium 2.2 with Quarkus, you will need to migrate to Quarkus 3. This also means that if you want to take advantage of the Outbox extension for Reactive data sources, you will be required to use Quarkus 3 as well.</p> </div> <div class="paragraph"> <p>Finally, if you are developing or maintaining sink adapters for Debezium Server, you will also need to make adjustments to using the new Jakarta EE annotations rather than the older Java EE annotations.</p> </div> </div> </div> <div class="sect1"> <h2 id="debezium_server_pulsar_changes">Debezium Server Pulsar Changes</h2> <div class="sectionbody"> <div class="paragraph"> <p>In prior versions of the Debezium Server Pulsar sink, the adapter leveraged the <code>send()</code> method to deliver messages in a synchronous way. While this works for sending one-off messages, this has the potential to introduce connector latency as the method waits an acknowledgement of send operation sequentially. Since the Debezium Server sink adapters are provided a collection of events to deliver, the synchronous nature just does not perform well.</p> </div> <div class="paragraph"> <p>Starting Debezium 2.2, the Pulsar sink will now use <code>sendAsync()</code> to asynchronously deliver the batch of events to Pulsar, netting a substantial increase in overall throughput. While each event within the batch is delivered asynchronously, the adapter will only proceed to the next batch once the current batch is acknowledged in entirety.</p> </div> </div> </div> <div class="sect1"> <h2 id="jolokia_support">Jolokia support</h2> <div class="sectionbody"> <div class="paragraph"> <p>Jolokia is a JMX-HTTP bridge that provides an alternative to using JSR-160 to gather metrics. It is an agent based approach that improves traditional JMX by introducing unique features like bulk requests and fine-grained security policies.</p> </div> <div class="paragraph"> <p>With Debezium 2.2, the <code>debezium/connect</code> image now ships with Jolokia, but this agent isn&#8217;t enabled by default. In order to enable Jolokia support, the container must be started with <code>ENABLE_JOLOKIA</code> set to <code>true</code>. By default, Jolokia will bind to port 8778 when enabled.</p> </div> <div class="paragraph"> <p>In the event that a different port is required, Jolokia will need to be enabled differently. For example, in order to enable Jolokia using port 9779, do not set the <code>ENABLE_JOLOKIA</code> but instead configure the <code>KAFKA_OPTS</code> environment variable as follows:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="propreties">-e KAFKA_OPTS=&quot;-javaagent:$(ls &quot;$KAFKA_HOME&quot;/libs/jolokia-jvm-*.jar)=port=9779,host=*&quot;</code></pre> </div> </div> <div class="paragraph"> <p>By specifying the above environment variable, Jolokia&#8217;s JMX-HTTP bridge will be available on port 9779 of the container.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>Do not forget to add the Jolokia port to the container&#8217;s list of exposed ports when starting.</p> </div> </td> </tr> </table> </div> </div> </div> <div class="sect1"> <h2 id="deprecation_of_docker_hub">Deprecation of Docker Hub</h2> <div class="sectionbody"> <div class="paragraph"> <p>Docker recently announced a reduction in their free organization account offerings, which is leveraged by a number of open-source communities, including Debezium. Unfortunately, Debezium does not qualify according to their rules.</p> </div> <div class="paragraph"> <p>Despite that Docker chose to walk back their decision, the Debezium team believes that we need a solid path forward to guarantee the availability of our images to our community without disruption. Debezium has been dual-publishing to both <code>docker.io</code> and <code>quay.io</code> for quite some time, and we will continue this for Debezium 2.2.0.Final and for all Debezium 2.3 <strong>preview</strong> releases.</p> </div> <div class="paragraph"> <p>We plan to publish a blog post going into more detail in the coming days with more details. In the meantime, all users should plan to migrate to <code>quay.io</code> as soon as possible to avoid disruption of fetching newer versions of Debezium.</p> </div> </div> </div> <div class="sect1"> <h2 id="other_fixes">Other fixes</h2> <div class="sectionbody"> <div class="paragraph"> <p>There were quite a number of other improvements, bug fixes, and stability changes in this release, some noteworthy are:</p> </div> <div class="ulist"> <ul> <li> <p>Upgrade dependencies (Quarkus, etc) of Debezium UI <a href="https://issues.redhat.com/browse/DBZ-4109">DBZ-4109</a></p> </li> <li> <p>Failed retriable operations are retried infinitely <a href="https://issues.redhat.com/browse/DBZ-4488">DBZ-4488</a></p> </li> <li> <p>UI- Add the UI to configure the additional properties for a connector <a href="https://issues.redhat.com/browse/DBZ-5365">DBZ-5365</a></p> </li> <li> <p>Capture events in order across mongodb shards <a href="https://issues.redhat.com/browse/DBZ-5590">DBZ-5590</a></p> </li> <li> <p>DDL events not stored in schema history topic for excluded tables <a href="https://issues.redhat.com/browse/DBZ-6070">DBZ-6070</a></p> </li> <li> <p>Oracle path used current batchSize to calculate end scn is wrong, need to use min batch size <a href="https://issues.redhat.com/browse/DBZ-6155">DBZ-6155</a></p> </li> <li> <p>Upgrade UI build to use Debezium 2.2 or latest <a href="https://issues.redhat.com/browse/DBZ-6173">DBZ-6173</a></p> </li> <li> <p>Oracle-Connector dbz##user needs more rights <a href="https://issues.redhat.com/browse/DBZ-6198">DBZ-6198</a></p> </li> <li> <p>Make quay.io primary image repository <a href="https://issues.redhat.com/browse/DBZ-6216">DBZ-6216</a></p> </li> <li> <p>Multiplatform build of example-postres fails <a href="https://issues.redhat.com/browse/DBZ-6258">DBZ-6258</a></p> </li> <li> <p>Add protoc version property to postgres connector pom.xml <a href="https://issues.redhat.com/browse/DBZ-6261">DBZ-6261</a></p> </li> <li> <p>Pass through configurations for kafka topics/configuration <a href="https://issues.redhat.com/browse/DBZ-6262">DBZ-6262</a></p> </li> <li> <p>Postgres connector doesn&#8217;t need logical WAL level when snapshotting only <a href="https://issues.redhat.com/browse/DBZ-6265">DBZ-6265</a></p> </li> <li> <p>Update config properties in RHEL deployment instructions <a href="https://issues.redhat.com/browse/DBZ-6266">DBZ-6266</a></p> </li> <li> <p>MySQL connector doesn&#8217;t need to query binlog when snapshotting only <a href="https://issues.redhat.com/browse/DBZ-6271">DBZ-6271</a></p> </li> <li> <p>Table names with spaces are not correctly deserialized when using an Infinispan cache as the transaction buffer <a href="https://issues.redhat.com/browse/DBZ-6273">DBZ-6273</a></p> </li> <li> <p>Infinispan cache configuration used by Oracle tests are not compatible with Infinispan 14.0.2 <a href="https://issues.redhat.com/browse/DBZ-6274">DBZ-6274</a></p> </li> <li> <p>Transaction buffer state can become corrupted when using Infinispan cache with LOBs <a href="https://issues.redhat.com/browse/DBZ-6275">DBZ-6275</a></p> </li> <li> <p>Enable the docker tag to be configurable in the Spanner connector <a href="https://issues.redhat.com/browse/DBZ-6302">DBZ-6302</a></p> </li> <li> <p>Upgrade MySQL JDBC driver to 8.0.32 <a href="https://issues.redhat.com/browse/DBZ-6304">DBZ-6304</a></p> </li> <li> <p>Allow specifying docker image reference in MongoDB testcontainers implementation <a href="https://issues.redhat.com/browse/DBZ-6305">DBZ-6305</a></p> </li> <li> <p>Use <strong>MongoDbContainer</strong> instead of <strong>MongoDBContainer</strong> test containers class in ConnectorConfiguration class <a href="https://issues.redhat.com/browse/DBZ-6306">DBZ-6306</a></p> </li> <li> <p>DDL statement couldn&#8217;t be parsed - Oracle connector 2.1.3.Final <a href="https://issues.redhat.com/browse/DBZ-6314">DBZ-6314</a></p> </li> <li> <p>Unparsable DDL statements (MySQL/MariaDB) <a href="https://issues.redhat.com/browse/DBZ-6316">DBZ-6316</a></p> </li> <li> <p>Remove outdated information about SYS user accounts with Oracle <a href="https://issues.redhat.com/browse/DBZ-6318">DBZ-6318</a></p> </li> <li> <p>Cassandra 3 cannot be built using JDK20 <a href="https://issues.redhat.com/browse/DBZ-6320">DBZ-6320</a></p> </li> <li> <p>Bundle Jolokia with Debezium connect image <a href="https://issues.redhat.com/browse/DBZ-6323">DBZ-6323</a></p> </li> </ul> </div> <div class="paragraph"> <p>Altogether, <a href="https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.2.0.CR1%20ORDER%20BY%20component%20ASC">34 issues</a> were fixed for this release. A big thank you to all the contributors from the community who worked on this release: <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/sugarcrm-jgminder">Jacob Gminder</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/joschi">Jochen Schalanda</a>, <a href="https://github.com/mfvitale">Mario Fiore Vitale</a>, <a href="https://github.com/alwaysbemark">Mark Bereznitsky</a>, <a href="https://github.com/obabec">Ondrej Babec</a>, <a href="https://github.com/smallYellowCat">Pengwei Dou</a>, <a href="https://github.com/roldanbob">Robert Roldan</a>, and <a href="https://github.com/vjuranek">Vojtech Juranek</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="outlook_whats_next">Outlook &amp; What&#8217;s Next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>We are approaching the end of the Debezium 2.2 release cycle, with a final release expected this week. If there are any outstanding bugs or issues, please get in touch with us so that can be addressed prior to the final release.</p> </div> <div class="paragraph"> <p>The Debezium team is shifting their focus on Debezium 2.3. The Debezium 2.3 release will be a much more condensed and focused release, as our goal is to release it in late June. The Debezium roadmap has been updated and the following features are planned for this quarter:</p> </div> <div class="ulist"> <ul> <li> <p>Support configurable signaling channels</p> </li> <li> <p>Support exactly once delivery semantics (phase 1)</p> </li> <li> <p>Kubernetes operator for Debezium Server</p> </li> <li> <p>Oracle OpenLogReplicator adapter proof-of-concept / incubating implementation</p> </li> <li> <p>Debezium UI improvements</p> </li> </ul> </div> <div class="paragraph"> <p>We would like to hear your feedback or suggestions, so if you have anything you&#8217;d like to share be sure to get in touch with us on the <a href="https://groups.google.com/g/debezium">mailing list</a> or our <a href="https://debezium.zulipchat.com/login/#narrow/stream/302529-users">chat</a>.</p> </div> <div class="paragraph"> <p>Until next time, let the changes continue to stream&#8230;&#8203;</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html"><![CDATA[The Debezium team is excited to announce the first release candidate of Deebzium 2.2, Debezium 2.2.0.CR1. This release primarily focuses on stability improvements and bug fixes; however, there are a number of new features and breaking changes. In this release, Debezium migrated to Quarkus 3.0.0.Final, there are performance improvements to Debezium Server Pulsar sink, Jolokia can be enabled inside Debezium&#8217;s Kafka Connect container image, incubating support for incremental snapshots on MongoDB multi-replica and sharded clusters, and the deprecation usage of Docker Hub for images. Let&#8217;s take a moment and dive into several of these and what it means moving forward!]]></summary></entry><entry><title type="html">Debezium 2.2.0.Beta1 Released</title><link href="https://debezium.io/blog/2023/04/03/debezium-2-2-beta1-released/" rel="alternate" type="text/html" title="Debezium 2.2.0.Beta1 Released"/><published>2023-04-03T00:00:00+00:00</published><updated>2023-04-03T00:00:00+00:00</updated><id>https://debezium.io/blog/2023/04/03/debezium-2-2-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2023/04/03/debezium-2-2-beta1-released/"><![CDATA[<div class="paragraph"> <p>The team is excited to announce the first beta release of the Debezium 2.2 release stream, Debezium <strong>2.2.0.Beta1</strong>.</p> </div> <div class="paragraph"> <p>This release includes a plethora of bug fixes, improvements, and a number of new features including, but not limited to, a new JDBC sink connector implementation, MongoDB sharded cluster improvements, Google Spanner PostgreSQL dialect support, and a RabbitMQ sink implementation for Debezium Server to just name a few.</p> </div> <div class="paragraph"> <p>Let&#8217;s take moment and dive into what&#8217;s new!</p> </div> <div class="paragraph"> <p></p> </div> <div class="sect1"> <h2 id="jdbc_sink_connector">JDBC Sink Connector</h2> <div class="sectionbody"> <div class="paragraph"> <p>The Debezium 2.2 release ushers in a new era for Debezium which has had a longstanding focus purely on providing a set of source connectors for relational and non-relational databases. This release alters that landscape, introducing a new JDBC sink connector implementation.</p> </div> <div class="paragraph"> <p>The Debezium JDBC sink connector is quite different from other vendor implementations in that it is capable of ingesting change events emitted by Debezium connectors without the need for event flattening. This has the potential to reduce the processing footprint in your pipeline, simplifies the pipeline&#8217;s configuration, and allows Debezium&#8217;s JDBC sink connector to take advantage of numerous Debezium source connector features such as column type propagation and much more.</p> </div> <div class="paragraph"> <p>Getting started with the Debezium JDBC sink connector is quite simple, lets take a look at an example.</p> </div> <div class="paragraph"> <p>Let&#8217;s say we have a Kafka topic called <code>orders</code> that contains Debezium change events that were created without using the <code>ExtractNewRecordState</code> transformation from MySQL. A simple configuration to ingest these change events into a PostgreSQL database might look this the following:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">mysql-to-postgres-pipeline</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">config</span><span class="delimiter">&quot;</span></span>: {
    <span class="key"><span class="delimiter">&quot;</span><span class="content">connector_class</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">io.debezium.connector.jdbc.JdbcSinkConnector</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">topics</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">orders</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">connection.url</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">jdbc://postgresql://&lt;host&gt;:&lt;port&gt;/&lt;database&gt;</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">connection.user</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">&lt;username&gt;</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">connection.password</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">&lt;password&gt;</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">insert.mode</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">upsert</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">delete.enabled</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">primary.key.mode</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record_key</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">schema.evolution</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">basic</span><span class="delimiter">&quot;</span></span>
  }
}</code></pre> </div> </div> <div class="paragraph"> <p>In this example, we&#8217;ve specified a series of <code>connection.*</code> properties that define the connection string and credentials for accessing the destination PostgreSQL database. Additionally, records will use <em>UPSERT</em> semantics when writing to the destination database, choosing to use an insert if the record doesn&#8217;t exist or updating the record if it does. We have also enabled schema evolution and specified that a table&#8217;s key columns should be derived from the event&#8217;s primary key.</p> </div> <div class="paragraph"> <p>The JDBC sink connector presently has support for the following relational databases:</p> </div> <div class="ulist"> <ul> <li> <p>Db2</p> </li> <li> <p>MySQL</p> </li> <li> <p>Oracle</p> </li> <li> <p>PostgreSQL</p> </li> <li> <p>SQL Server</p> </li> </ul> </div> <div class="paragraph"> <p>We do intend to add additional dialects in the future, and if there one you&#8217;d like to see, please get in touch with us either on our mailing list, in chat, or opening a Jira enhancement.</p> </div> </div> </div> <div class="sect1"> <h2 id="mongodb_sharded_cluster_improvements">MongoDB Sharded Cluster Improvements</h2> <div class="sectionbody"> <div class="paragraph"> <p>When using the Debezium for MongoDB connector in a sharded cluster deployment, the connector opens a connection with each of the shard&#8217;s replica sets directly. This is not a recommended approach and instead MongoDB suggests that the connector <a href="https://www.mongodb.com/docs/manual/sharding/#connecting-to-a-sharded-cluster">open a connection with the mongos instance</a> (the router) instead.</p> </div> <div class="paragraph"> <p>This release aligns with this recommended strategy and users should be prepared to adjust their configurations slightly and when using the connector in such a deployment, point the connector as the <code>mongos</code> instance instead. There should be be other changes required.</p> </div> </div> </div> <div class="sect1"> <h2 id="spanner_postgresql_dialect_support">Spanner PostgreSQL Dialect Support</h2> <div class="sectionbody"> <div class="paragraph"> <p>Google&#8217;s Cloud Spanner platform supports a PostgreSQL interface, which combines the scalability and reliability of the Google Spanner platform with the familiarity and portability of PostgreSQL. When operating Google Spanner with this PostgreSQL interface, metadata of columns and tables is different than when using the standard GoogleSQL dialect.</p> </div> <div class="paragraph"> <p>This release extends the Debezium Spanner connector support not only for the GoogleSQL dialect but also for users that use the Spanner PostgreSQL dialect feature. This means regardless of which dialect your spanner environment relies on, you will be able to capture change events from Spanner using the Debezium Spanner connector seamlessly.</p> </div> <div class="paragraph"> <p>So if you&#8217;re using Spanner&#8217;s PostgreSQL dialect, upgrade to Debezium 2.2.0.Beta1 or later and start capturing changes!</p> </div> </div> </div> <div class="sect1"> <h2 id="rabbitmq_debezium_server_sink">RabbitMQ Debezium Server Sink</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium Server is a ready-made Quarkus-based runtime for Debezium source and sink connectors. Debezium Server provides the capability to send Debezium change events from any source connector to a variety of messaging infrastructure platforms, particularly for users who would prefer something other than Apache Kafka.</p> </div> <div class="paragraph"> <p>In this release, a new sink adapter has been added to the Debezium Server portfolio, allowing Debezium users to send change events to RabbitMQ. The following configuration shows a simple example of how easy it is to configure:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">debezium.sink.type=rabbitmq

# Connection details
debezium.sink.rabbitmq.connection.host=&lt;hostname&gt;
debezium.sink.rabbitmq.connection.port=&lt;port&gt;

# The routing key specifies an override of where events are published
debezium.sink.rabbitmq.routingKey=&lt;routing-key&gt;

# The default is 30 seconds, specified in milliseconds
debezium.sink.rabbitmq.ackTimeout=30000</code></pre> </div> </div> <div class="paragraph"> <p>The <code>debezium.sink.rabbitmq.connection.*</code> properties are required while the latter two properties for <code>routingKey</code> and <code>ackTimeout</code> are optional or have preset defaults that should be sufficient for most use cases.</p> </div> </div> </div> <div class="sect1"> <h2 id="other_fixes">Other fixes</h2> <div class="sectionbody"> <div class="paragraph"> <p>There were quite a number of other improvements, bug fixes, and stability changes in this release, some noteworthy are:</p> </div> <div class="ulist"> <ul> <li> <p>Create an endpoint to update a connector <a href="https://issues.redhat.com/browse/DBZ-5314">DBZ-5314</a></p> </li> <li> <p>Refactor snapshotting to use change streams instead of oplog <a href="https://issues.redhat.com/browse/DBZ-5987">DBZ-5987</a></p> </li> <li> <p>Update the design for Debezium based connectors Filter step <a href="https://issues.redhat.com/browse/DBZ-6060">DBZ-6060</a></p> </li> <li> <p>NPE when setting schema.history.internal.store.only.captured.tables.ddl=true <a href="https://issues.redhat.com/browse/DBZ-6072">DBZ-6072</a></p> </li> <li> <p>Postgres connector stuck when replication slot does not have confirmed_flush_lsn <a href="https://issues.redhat.com/browse/DBZ-6092">DBZ-6092</a></p> </li> <li> <p>java.lang.NullPointerException in MySQL connector with max.queue.size.in.bytes <a href="https://issues.redhat.com/browse/DBZ-6104">DBZ-6104</a></p> </li> <li> <p>debezium-connector-mysql failed to parse serveral DDLs of 'CREATE TABLE' <a href="https://issues.redhat.com/browse/DBZ-6124">DBZ-6124</a></p> </li> <li> <p>Connect and stream from sharded clusters through mongos instances <a href="https://issues.redhat.com/browse/DBZ-6170">DBZ-6170</a></p> </li> <li> <p>Support Azure blob storage as Debezium history storage <a href="https://issues.redhat.com/browse/DBZ-6180">DBZ-6180</a></p> </li> <li> <p>Zerofill property failed for different int types <a href="https://issues.redhat.com/browse/DBZ-6185">DBZ-6185</a></p> </li> <li> <p>GRANT DELETE HISTORY couldn&#8217;t be parsed in mariadb <a href="https://issues.redhat.com/browse/DBZ-6186">DBZ-6186</a></p> </li> <li> <p>ddl parse failed for key partition table <a href="https://issues.redhat.com/browse/DBZ-6188">DBZ-6188</a></p> </li> <li> <p>Config options internal.schema.history.internal.ddl.filter not working <a href="https://issues.redhat.com/browse/DBZ-6190">DBZ-6190</a></p> </li> <li> <p>Support Database role in Connector Config. <a href="https://issues.redhat.com/browse/DBZ-6192">DBZ-6192</a></p> </li> <li> <p>Use CHARSET for alterByConvertCharset clause <a href="https://issues.redhat.com/browse/DBZ-6194">DBZ-6194</a></p> </li> <li> <p>Remove duplicated createDdlFilter method from historized connector config <a href="https://issues.redhat.com/browse/DBZ-6197">DBZ-6197</a></p> </li> <li> <p>Create new SMT to copy/move header to record value <a href="https://issues.redhat.com/browse/DBZ-6201">DBZ-6201</a></p> </li> <li> <p>Data loss upon connector restart <a href="https://issues.redhat.com/browse/DBZ-6204">DBZ-6204</a></p> </li> <li> <p>ParsingException: DDL statement couldn&#8217;t be parsed <a href="https://issues.redhat.com/browse/DBZ-6217">DBZ-6217</a></p> </li> <li> <p>The CHARACTER/CHARACTER(p)/CHARACTER VARYING(p) data types not recognized as JDBC type CHAR <a href="https://issues.redhat.com/browse/DBZ-6221">DBZ-6221</a></p> </li> <li> <p>MySQL treats the BOOLEAN synonym differently when processed in snapshot vs streaming phases. <a href="https://issues.redhat.com/browse/DBZ-6225">DBZ-6225</a></p> </li> <li> <p>MySQL treats REAL synonym differently when processed in snapshot vs streaming phases. <a href="https://issues.redhat.com/browse/DBZ-6226">DBZ-6226</a></p> </li> <li> <p>Spanner Connector - Deadlock in BufferedPublisher when publish gives exception <a href="https://issues.redhat.com/browse/DBZ-6227">DBZ-6227</a></p> </li> <li> <p>Publish of sync event fails when message becomes very large. <a href="https://issues.redhat.com/browse/DBZ-6228">DBZ-6228</a></p> </li> <li> <p>MySQL treats NCHAR/NVARCHAR differently when processed in snapshot vs streaming phases. <a href="https://issues.redhat.com/browse/DBZ-6231">DBZ-6231</a></p> </li> <li> <p>Add support for columns of type "bytea[]" - array of bytea (byte array) <a href="https://issues.redhat.com/browse/DBZ-6232">DBZ-6232</a></p> </li> <li> <p>MySQL singleDeleteStatement parser does not support table alias <a href="https://issues.redhat.com/browse/DBZ-6243">DBZ-6243</a></p> </li> <li> <p>Support ImageFromDockerfile with Debezium&#8217;s testcontainers suite <a href="https://issues.redhat.com/browse/DBZ-6244">DBZ-6244</a></p> </li> <li> <p>Testcontainers MongoDbReplicaSetTest failing with MongoDB 4.2 <a href="https://issues.redhat.com/browse/DBZ-6247">DBZ-6247</a></p> </li> <li> <p>Expose EmbeddedEngine configurations <a href="https://issues.redhat.com/browse/DBZ-6248">DBZ-6248</a></p> </li> <li> <p>Wrong error thrown when snapshot.custom_class=custom and no snapshot.custom.class <a href="https://issues.redhat.com/browse/DBZ-6249">DBZ-6249</a></p> </li> <li> <p>Missing GEOMETRY keyword which can be used as column name <a href="https://issues.redhat.com/browse/DBZ-6250">DBZ-6250</a></p> </li> <li> <p>Postgres connector stuck trying to fallback to restart_lsn when replication slot confirmed_flush_lsn is null. <a href="https://issues.redhat.com/browse/DBZ-6251">DBZ-6251</a></p> </li> <li> <p>MariaDB&#8217;s UUID column type cannot be parsed when scheme is loaded <a href="https://issues.redhat.com/browse/DBZ-6255">DBZ-6255</a></p> </li> </ul> </div> <div class="paragraph"> <p>Altogether, <a href="https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.2.0.Beta1%20ORDER%20BY%20component%20ASC">52 issues</a> were fixed for this release. A big thank you to all the contributors from the community who worked on this release: <a href="https://github.com/sondn">Đỗ Ngọc Sơn</a>, <a href="https://github.com/AnatolyPopov">Anatolii Popov</a>, <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/gunnarmorling">Gunnar Morling</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/blcksrx">Hossein Torabi</a>, <a href="https://github.com/jcechace">Jakub Cechacek</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/mfvitale">Mario Fiore Vitale</a>, <a href="https://github.com/nirolevy">Nir Levy</a>, <a href="https://github.com/PlugaruT">Plugaru Tudor</a>, <a href="https://github.com/roldanbob">Robert Roldan</a>, <a href="https://github.com/Apteryx0">Russell Mora</a>, <a href="https://github.com/vjuranek">Vojtech Juranek</a>, <a href="https://github.com/vjuranek">Vojtěch Juránek</a>, and <a href="https://github.com/imtj1">tony joseph</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="outlook_whats_next">Outlook &amp; What&#8217;s Next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>As we approach the end of the Debezium 2.2 development cycle, with a final release expected in the next two weeks, we&#8217;re going to begin to turn our attention toward Debezium 2.3. The Debezium 2.3 release will be a much more condensed and focused release, as our goal is to release it in late June.</p> </div> <div class="paragraph"> <p>We will be refining our <a href="https://debezium.io/roadmap">roadmap</a> in the coming days, so I would pay close attention to this to get an understanding of what lies ahead in the near future for Debezium 2.3. We would like to hear your feedback or suggestions, so if you have anything you&#8217;d like to share be sure to get in touch with us on the <a href="https://groups.google.com/g/debezium">mailing list</a> or our <a href="https://debezium.zulipchat.com/login/#narrow/stream/302529-users">chat</a>.</p> </div> <div class="paragraph"> <p>DevNexus 2023 is also underway this week, from April 4th until April 6th and I will be presenting a talk on CDC Patterns with Distributed Systems using Debezium. If you&#8217;re in the Atlanta area and plan to attend DevNexus on Thursday, April 6th, drop me a line.</p> </div> <div class="paragraph"> <p>Until next time, let the changes continue to stream&#8230;&#8203;</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html"><![CDATA[The team is excited to announce the first beta release of the Debezium 2.2 release stream, Debezium 2.2.0.Beta1. This release includes a plethora of bug fixes, improvements, and a number of new features including, but not limited to, a new JDBC sink connector implementation, MongoDB sharded cluster improvements, Google Spanner PostgreSQL dialect support, and a RabbitMQ sink implementation for Debezium Server to just name a few. Let&#8217;s take moment and dive into what&#8217;s new!]]></summary></entry><entry><title type="html">Hello Debezium Team!</title><link href="https://debezium.io/blog/2023/03/09/hello-debezium/" rel="alternate" type="text/html" title="Hello Debezium Team!"/><published>2023-03-09T10:11:11+00:00</published><updated>2023-03-09T10:11:11+00:00</updated><id>https://debezium.io/blog/2023/03/09/hello-debezium</id><content type="html" xml:base="https://debezium.io/blog/2023/03/09/hello-debezium/"><![CDATA[<div class="paragraph"> <p>Hi everyone, my name is Mario Fiore Vitale and I recently joined Red Hat and the Debezium team.</p> </div> <div class="paragraph"> <p>I am a very curious person that follows a continuous learning approach, I like to keep growing my skills. I care about code quality and readability.</p> </div> <div class="paragraph"> <p>I have about 9+ years of experience and have worked for consultancy, startup, and enterprise product companies in different sectors. In my previously experience I had the chance to work on architecture re-design project to split a monolith into a microservices application. During this experience I gained experience with different technologies such as Kafka, Elasticsearch, Redis, Kubernetes, VictoriaMetrics, Spring Framework, and a bit of Cassandra.</p> </div> <div class="paragraph"> <p>Why Am I here?</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>First of all, I have always been fascinated by OSS and the power of the "community". During my career I have used a lot of OSS and when I had the chance to give back to the community I didn&#8217;t back down.</p> </div> <div class="paragraph"> <p>In recent years data are becoming more and more important, in terms of their role for companies but also in terms of quantity. The way we manage these data is now crucial. Data comes from different source, asynchronously and must be shared with different consumers. So we need to continuously process incoming data, and this is where Event Stream Processing comes in. Debezium can act as a facilitator for Stream processing, enabling a lot of useful use cases for modern software architecture. This is why I like Debezium.</p> </div> <div class="paragraph"> <p>I&#8217;m thrilled to be here and looking forward to working with this amazing community.</p> </div> <div class="paragraph"> <p>Onwards,</p> </div> <div class="paragraph"> <p>--Mario</p> </div>]]></content><author><name>Fiore Mario Vitale</name></author><category term="community"/><category term="news"/><summary type="html"><![CDATA[Hi everyone, my name is Mario Fiore Vitale and I recently joined Red Hat and the Debezium team. I am a very curious person that follows a continuous learning approach, I like to keep growing my skills. I care about code quality and readability. I have about 9+ years of experience and have worked for consultancy, startup, and enterprise product companies in different sectors. In my previously experience I had the chance to work on architecture re-design project to split a monolith into a microservices application. During this experience I gained experience with different technologies such as Kafka, Elasticsearch, Redis, Kubernetes, VictoriaMetrics, Spring Framework, and a bit of Cassandra. Why Am I here?]]></summary></entry><entry><title type="html">Debezium 2.2.0.Alpha3 Released</title><link href="https://debezium.io/blog/2023/03/08/debezium-2-2-alpha3-released/" rel="alternate" type="text/html" title="Debezium 2.2.0.Alpha3 Released"/><published>2023-03-08T00:00:00+00:00</published><updated>2023-03-08T00:00:00+00:00</updated><id>https://debezium.io/blog/2023/03/08/debezium-2-2-alpha3-released</id><content type="html" xml:base="https://debezium.io/blog/2023/03/08/debezium-2-2-alpha3-released/"><![CDATA[<div class="paragraph"> <p>Today, I am pleased to announce the third alpha release in the 2.2 release stream, Debezium <strong>2.2.0.Alpha3</strong>.</p> </div> <div class="paragraph"> <p>This release includes a plethora of bug fixes, improvements, breaking changes, and a number of new features including, but not limited to, optional parallel snapshots, server-side MongoDB change stream filtering, surrogate keys for incremental snapshots, a new Cassandra connector for Cassandra Enterprise, much more.</p> </div> <div class="paragraph"> <p>Let&#8217;s take moment and dive into some of these new features, improvements, and breaking changes.</p> </div> <div class="paragraph"> <p></p> </div> <div class="sect1"> <h2 id="breaking_changes">Breaking Changes</h2> <div class="sectionbody"> <div class="paragraph"> <p>We typically try to avoid any breaking changes, even during minor releases such as this; however, sometimes breaking changes are inevitable given the circumstances. Debezium 2.2.0.Alpha3 includes one breaking change:</p> </div> <div class="ulist"> <ul> <li> <p><a href="#zoned-datetime-truncation">PostgreSQL zoned date-time data types truncated</a></p> </li> </ul> </div> <div class="sect2"> <h3 id="zoned-datetime-truncation">PostgreSQL zoned date-time data types truncated</h3> <div class="paragraph"> <p>It was identified (<a href="https://issues.redhat.com/browse/DBZ-6163">DBZ-6163</a>) that PostgreSQL timezone based column values that had a value of zero (<code>0</code>) for milli and micro second parts of a timezone based column were being serialized incorrectly where the string did not include neither the millisecond nor the microsecond portions of the time using zeroes.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>This <strong>does not</strong> create any data loss!</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>What&#8217;s important to note is that prior to this release, when evaluating the values of such columns, consumers must be prepared to parse these string-based time values without the presence of a milli or microsecond value. In effect, this means events have an inconsistent pattern where some will have the milli and microsecond portions and others may not if their source value had 0 milliseconds or 0 microseconds.</p> </div> <div class="paragraph"> <p>These string-based time values will be be emitted consistently, padded with zeroes (<code>0</code>) for the milli and microsecond parts of the string-based time, even when the source value has neither milli nor microseconds.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="optional_parallel_snapshots">Optional parallel snapshots</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium&#8217;s relational database initial snapshot process has always been single-threaded. This limitation primarily stems from the complexities of ensuring data consistency across multiple transactions.</p> </div> <div class="paragraph"> <p>Starting in Debezium 2.2, we&#8217;re adding a new and initially optional way to utilize multiple threads to perform consistent database snapshot for a connector. This implementation uses these multiple threads to execute table-level snapshots in parallel.</p> </div> <div class="paragraph"> <p>In order to take advantage of this new feature, specify <code>snapshot.max.threads</code> in your connector&#8217;s configuration and when this property has a value greater than <code>1</code>, parallel snapshots will be used.</p> </div> <div class="listingblock"> <div class="title">Example configuration using parallel snapshots</div> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">snapshot.max.threads=4</code></pre> </div> </div> <div class="paragraph"> <p>In the example above, if the connector needs to snapshot more than 4 tables, there will be at most 4 tables being snapshot in parallel. When one thread finishes processing a table, it will get a new table to snapshot from the queue and the process continues until all tables have been snapshot.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>This feature is considered <em>incubating</em>, but we strongly suggest that new connector deployments give this feature a try. We would welcome any and all feedback on how to improve this going forward.</p> </div> </td> </tr> </table> </div> </div> </div> <div class="sect1"> <h2 id="mongodb_server_side_change_stream_filtering">MongoDB server-side change stream filtering</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium presently subscribes to the MongoDB change stream and evaluates whether an event is of relevance or not on the connector side. On the surface, there is nothing technically wrong with this approach, it has worked well; however, a recent contributor explained how this decision impacts them.</p> </div> <div class="paragraph"> <p>Overall, the current process effectively serializes across the network all changes from MongoDB to the connector. If you have a lower volume of changes, you likely don&#8217;t see any issue with this approach; however, in a high volume scenario, especially when you&#8217;re only interested in a subset of the data generated by change streams, you quickly begin to see how this approach is inefficient. Furthermore, if you&#8217;re running the connector in a cloud environment like AWS, you&#8217;ll likely see in a high volume scenario where utilization costs could be impacted.</p> </div> <div class="paragraph"> <p>By moving where the include/exclude list filters are evaluated from the connector to the MongoDB server&#8217;s change stream subscription, this adds a number of advantages for all MongoDB connector users.</p> </div> <div class="paragraph"> <p>By reducing the number of events seen by connector, this impacts both network and CPU utilization. When events are sent that the connector simply discards due to include/exclude filters, this leads to network usage that could be avoided. When the connector is configured with full document or pre-image settings, this adds even more utilization to the network that is entirely unnecessary. Furthermore, by receiving more events than the connector configuration is interested in, this leads to the connector doing more processing, raising CPU utilization.</p> </div> <div class="paragraph"> <p>While network and CPU utilization are critical regardless of one&#8217;s environment, these are often more scrutinized when operating a cloud-based environments as these two metrics directly impact the operating budget. Users should see an overall lower network and CPU utilization with Debezium MongoDB 2.2 connectors.</p> </div> <div class="paragraph"> <p>We hope to share more details the benefits of this change in a future blog post, so stay tuned!</p> </div> </div> </div> <div class="sect1"> <h2 id="incremental_snapshot_surrogate_key_support">Incremental snapshot surrogate key support</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium&#8217;s incremental snapshot feature has been a tremendous success. It provides an efficient way to perform a consist snapshot of data that can be resumed, which is critical when the snapshot consists of large volumes of data.</p> </div> <div class="paragraph"> <p>However, incremental snapshots do have specific requirements that must be met before the feature can be used. One of those requirements is all tables being snapshot must use a primary key. You may ask, why does a table have no primary key, and we aren&#8217;t going to debate that here today; however, suffice to say this occurs more often than you may think.</p> </div> <div class="paragraph"> <p>With Debezium 2.2, incremental snapshots can be performed on key-less tables as long as there is one column that is unique and can be considered a "surrogate key" for incremental snapshot purposes.</p> </div> <div class="admonitionblock warning"> <table> <tr> <td class="icon"> <i class="fa icon-warning" title="Warning"></i> </td> <td class="content"> <div class="paragraph"> <p>The surrogate key feature is not supported by MongoDB; only relational connectors.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>To provide the surrogate key column data in an incremental snapshot signal, the signal&#8217;s payload must include the new surrogate key attribute, <code>surrogate-key</code>.</p> </div> <div class="listingblock json"> <div class="title">An example incremental snapshot signal payload specifying a surrogate key</div> <div class="content"> <pre class="CodeRay highlight"><code>{
  "data-collections": [ "public.mytab" ],
  "surrogate-key": "customer_ref"
}</code></pre> </div> </div> <div class="paragraph"> <p>In the above example, an incremental snapshot will be started for table <code>public.mytab</code> and the incremental snapshot will use the <code>customer_ref</code> column as the primary key for generating the snapshot windows.</p> </div> <div class="admonitionblock warning"> <table> <tr> <td class="icon"> <i class="fa icon-warning" title="Warning"></i> </td> <td class="content"> <div class="paragraph"> <p>A surrogate key cannot be defined using multiple columns, only a <strong>single</strong> column.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>However, the surrogate key feature isn&#8217;t just applicable for tables with no primary keys. There are a series of advantages when using this feature with tables that have primary keys:</p> </div> <div class="olist arabic"> <ol class="arabic"> <li> <p>One clear advantage is when the table&#8217;s primary key consists of multiple columns. The query generates a disjunction predicate for each column in the primary key, and it&#8217;s performance is highly dependent on the environment. Reducing the number of columns down to a single column often performs universally.</p> </li> <li> <p>Another advantage is when the surrogate key is based on a numeric data type while the primary key column is based on a character-based data type. Relational databases generally perform predicate evaluation more efficiently with numeric comparisons rather than character comparisons. By adjusting the query to use a numeric data type in this case, query performance could be better.</p> </li> </ol> </div> </div> </div> <div class="sect1"> <h2 id="other_fixes">Other fixes</h2> <div class="sectionbody"> <div class="paragraph"> <p>There were quite a number of other improvements, bug fixes, and stability changes in this release, some noteworthy are:</p> </div> <div class="ulist"> <ul> <li> <p>When using <code>snapshot.collection.include.list</code>, relational schema isn&#8217;t populated correctly <a href="https://issues.redhat.com/browse/DBZ-3594">DBZ-3594</a></p> </li> <li> <p>Debezium UI should use fast-jar again with Quarkus 2.x <a href="https://issues.redhat.com/browse/DBZ-4621">DBZ-4621</a></p> </li> <li> <p>Create a Datastax connector based on Cassandra connector <a href="https://issues.redhat.com/browse/DBZ-5951">DBZ-5951</a></p> </li> <li> <p>Add support for honouring MongoDB read preference in change stream after promotion <a href="https://issues.redhat.com/browse/DBZ-5953">DBZ-5953</a></p> </li> <li> <p>Add support for header to all Debezium Server sinks <a href="https://issues.redhat.com/browse/DBZ-6017">DBZ-6017</a></p> </li> <li> <p>GCP Spanner connector start failing when there are multiple indexes on a single column <a href="https://issues.redhat.com/browse/DBZ-6101">DBZ-6101</a></p> </li> <li> <p>Negative remaining attempts on MongoDB reconnect case <a href="https://issues.redhat.com/browse/DBZ-6113">DBZ-6113</a></p> </li> <li> <p>Support String type for key in Mongo incremental snapshot <a href="https://issues.redhat.com/browse/DBZ-6116">DBZ-6116</a></p> </li> <li> <p>Tables with spaces or non-ASCII characters in their name are not captured by Oracle because they must be quoted. <a href="https://issues.redhat.com/browse/DBZ-6120">DBZ-6120</a></p> </li> <li> <p>Offsets are not advanced in a CDB deployment with low frequency of changes to PDB <a href="https://issues.redhat.com/browse/DBZ-6125">DBZ-6125</a></p> </li> <li> <p>Allow TestContainers test framework to expose ConnectorConfiguration as JSON <a href="https://issues.redhat.com/browse/DBZ-6136">DBZ-6136</a></p> </li> <li> <p>Oracle TIMESTAMP WITH TIME ZONE is emitted as GMT during snapshot rather than the specified TZ <a href="https://issues.redhat.com/browse/DBZ-6143">DBZ-6143</a></p> </li> <li> <p>Upgrade impsort-maven-plugin from 1.7.0 to 1.8.0 <a href="https://issues.redhat.com/browse/DBZ-6144">DBZ-6144</a></p> </li> <li> <p>Debezium UI E2E Frontend build failing randomly with corrupted Node 16 tar file <a href="https://issues.redhat.com/browse/DBZ-6146">DBZ-6146</a></p> </li> <li> <p>Debezium UI SQL Server tests randomly fail due to slow agent start-up <a href="https://issues.redhat.com/browse/DBZ-6149">DBZ-6149</a></p> </li> <li> <p>Upgrade Quarkus dependencies to 2.16.3.Final <a href="https://issues.redhat.com/browse/DBZ-6150">DBZ-6150</a></p> </li> <li> <p>Remove hardcoded list of system database exclusions that are not required for change streaming <a href="https://issues.redhat.com/browse/DBZ-6152">DBZ-6152</a></p> </li> <li> <p>RelationalSnapshotChangeEventSource swallows exception generated during snapshot <a href="https://issues.redhat.com/browse/DBZ-6179">DBZ-6179</a></p> </li> <li> <p>Create SSL scenarios for integration tests for MySQL connector <a href="https://issues.redhat.com/browse/DBZ-6184">DBZ-6184</a></p> </li> </ul> </div> <div class="paragraph"> <p>Altogether, <a href="https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.2.0.Alpha3%20ORDER%20BY%20component%20ASC">33 issues</a> were fixed for this release. A big thank you to all the contributors from the community who worked on this release: <a href="https://github.com/ggaborg">Gabor Andras</a>, <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/btiernay">Bobby Tiernay</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/EugeneAbramchuk">Eugene Abramchuk</a>, <a href="https://github.com/ggaborg">Gabor Andras</a>, <a href="https://github.com/gunnarmorling">Gunnar Morling</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/jcechace">Jakub Cechacek</a>, <a href="https://github.com/jeremy-l-ford">Jeremy Ford</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/MehmetFiratKomurcu">Mehmet Firat Komurcu</a>, <a href="https://github.com/PlugaruT">Plugaru Tudor</a>, <a href="https://github.com/smiklosovic">Stefan Miklosovic</a>, <a href="https://github.com/subodh1810">Subodh Kant Chaturvedi</a>, <a href="https://github.com/vjuranek">Vojtech Juranek</a>, and <a href="https://github.com/xinbinhuang">Xinbin Huang</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="outlook_whats_next">Outlook &amp; What&#8217;s Next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>In addition, we are nearing the end of the Debezium 2.2 development cycle. Assuming no unexpected problems, we do intend to release Beta1 next week, followed by a release candidate two weeks thereafter. Our goal is to finalize the Debezium 2.2 release in late March or early April at the latest.</p> </div> <div class="paragraph"> <p>We would love to hear your feedback or suggestions about our roadmap, changes in this release, or any that are outstanding or that we may haven&#8217;t mentioned. Be sure to get in touch with us on the <a href="https://groups.google.com/g/debezium">mailing list</a> or our <a href="https://debezium.zulipchat.com/login/#narrow/stream/302529-users">chat</a> if there is.</p> </div> <div class="paragraph"> <p>Also, the DevNexus 2023 conference is coming up in early April in Atlanta, and I have the privilege to be a guest speaker discussing Debezium and CDC patterns. Be sure to check out that talk in person if you have an opportunity!</p> </div> <div class="paragraph"> <p>And finally, be on the lookout for our first installment of our 2023 Newsletter later this month. I also will be wrapping up the blog series, "Debezium for Oracle" where I cover performance, debugging, and frequently asked questions about the Oracle connector.</p> </div> <div class="paragraph"> <p>Until next time&#8230;&#8203;</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html"><![CDATA[Today, I am pleased to announce the third alpha release in the 2.2 release stream, Debezium 2.2.0.Alpha3. This release includes a plethora of bug fixes, improvements, breaking changes, and a number of new features including, but not limited to, optional parallel snapshots, server-side MongoDB change stream filtering, surrogate keys for incremental snapshots, a new Cassandra connector for Cassandra Enterprise, much more. Let&#8217;s take moment and dive into some of these new features, improvements, and breaking changes.]]></summary></entry><entry><title type="html">Debezium 2.2.0.Alpha2 Released</title><link href="https://debezium.io/blog/2023/02/16/debezium-2-2-alpha2-released/" rel="alternate" type="text/html" title="Debezium 2.2.0.Alpha2 Released"/><published>2023-02-16T00:00:00+00:00</published><updated>2023-02-16T00:00:00+00:00</updated><id>https://debezium.io/blog/2023/02/16/debezium-2-2-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2023/02/16/debezium-2-2-alpha2-released/"><![CDATA[<div class="paragraph"> <p>Today, I am pleased to announce the second alpha release in the 2.2 release stream, Debezium <strong>2.2.0.Alpha2</strong>. This release includes a plethora of bug fixes, improvements, breaking changes, and a number of new features including, but not limited to, a new <code>ExtractRecordChanges</code> single message transformation, a Reactive-based implementation of the Debezium Outbox extension for Quarkus, a Debezium Storage module for Apache RocketMQ, and much more. Let&#8217;s take moment and dive into these new features, improvements, and breaking changes.</p> </div> <div class="paragraph"> <p></p> </div> <div class="sect1"> <h2 id="breaking_changes">Breaking Changes</h2> <div class="sectionbody"> <div class="paragraph"> <p>We typically try to avoid any breaking changes, even during minor releases such as this; however, sometimes breaking changes are inevitable given the circumstances. Debezium 2.2.0.Alpha2 includes three breaking changes:</p> </div> <div class="ulist"> <ul> <li> <p><a href="#topic-schema-naming-changes">Topic and schema naming changes</a></p> </li> <li> <p><a href="#source-info-block-changes-oracle">Source info block changed for Oracle connector</a></p> </li> <li> <p><a href="#debezium-server-moved-to-new-repository">Debezium Server source code in new repository</a></p> </li> </ul> </div> <div class="sect2"> <h3 id="topic-schema-naming-changes">Topic / Schema naming changes</h3> <div class="paragraph"> <p>Debezium previously sanitized topic and schema names by using an underscore (<code>_</code>) to replace non-ASCII characters that would lead to unsupported topic or schema names when using schema registries. However, if this non-ASCII character was the only difference between two similar topics or schema names that otherwise only varied by case, this would lead to other problems.</p> </div> <div class="paragraph"> <p>In order to address this in the most compatible way, Debezium now uses a strategy-based approach to map characters uniquely. As a side effect of this change, the <code>sanitize.field.names</code> configuration property has been retired and replaced by this new strategy-based approach.</p> </div> <div class="paragraph"> <p>Each connector supports two configuration properties to control this behavior:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>schema.name.adjustment.mode</code></dt> <dd> <p>Specifies how schema names should be adjusted for compatibility with the message converter.</p> </dd> <dt class="hdlist1"><code>field.name.adjustment.mode</code></dt> <dd> <p>Specifies how field names should be adjusted for compatibility with the message converter.</p> </dd> </dl> </div> <div class="paragraph"> <p>These two connector configuration properties support three modes:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>none</code></dt> <dd> <p>No adjustment is made to the schema or field names, passed as-is.</p> </dd> <dt class="hdlist1"><code>avro</code></dt> <dd> <p>Replaces characters that cannot be used in Avro with an underscore (<code>_</code>).</p> </dd> <dt class="hdlist1"><code>avro_unicode</code></dt> <dd> <p>Replaces underscores (<code>_</code>) and characters that cannot be used in Avro with unicode-based characters.</p> </dd> </dl> </div> <div class="paragraph"> <p>This now allows you to pick the most appropriate strategy based on your table or collection naming convention.</p> </div> </div> <div class="sect2"> <h3 id="source-info-block-changes-oracle">Source info block changes with Oracle connector</h3> <div class="paragraph"> <p>All Debezium change events related to inserts, updates, and deletes contain a <code>source</code> info block in the event&#8217;s payload. For the Oracle connector, this block contains a special field called <code>ssn</code> that represents the SQL sequence number for this change.</p> </div> <div class="paragraph"> <p>It has been identified that there were corner cases where the value sourced from the database for this field could exceed the maximum value of <code>2,147,483,647</code>, or the maximum value of an <code>INT32</code> data type. To fix this corner case, we&#8217;ve changed the data type from <code>INT32</code> to <code>INT64</code>, which allows up to a maximum value of <code>9,223,372,036,854,775,807</code>.</p> </div> <div class="paragraph"> <p>This change should be entirely non-invasive, but we wanted to bring attention to this should you have pipelines that could be storing this value in a sink system or if you are using a schema registry.</p> </div> </div> <div class="sect2"> <h3 id="debezium-server-moved-to-new-repository">Debezium Server moved to new repository</h3> <div class="paragraph"> <p>Debezium Server is a standalone Quarkus-based runtime for Debezium source connectors enabling the integration with various platforms like EventHubs, PubSub, Pulsar, Redis, and Kafka, to name a few. With this release, we have moved the code related to Debezium Server to its own <a href="https://www.github.com/debezium/debezium-server">GitHub repository</a>.</p> </div> <div class="paragraph"> <p>This change was required in order to support building Debezium Server to include connectors that are not part of the main Debezium repository, connectors such as Db2, Google Spanner, Cassandra 4, and Vitess. Therefore, this means that starting with this release, Debezium Server now ships with all connectors (excluding Cassandra 3) by default.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>Cassandra 3 is excluded due to some technical limitations with class loading that creates conflicts with Cassandra 4. We are aware of this and plan to deliver a solution to include Cassandra 3 in the future.</p> </div> </td> </tr> </table> </div> </div> </div> </div> <div class="sect1"> <h2 id="new_extractchangedrecordstate_smt">New ExtractChangedRecordState SMT</h2> <div class="sectionbody"> <div class="paragraph"> <p>We have heard from the community on several occasions that it would great to have an out-of-the-box way to determine what values have changed in a Debezium change event. The new single message transform (SMT) <code>ExtractChangedRecordState</code> aims to deliver on this request by adding metadata to the event identifying which fields changed or were unchanged.</p> </div> <div class="paragraph"> <p>In order to get started with this new transformation, configure it as part of your connector configuration:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">transforms=changes
transforms.changes.type=io.debezium.transforms.ExtractChangedRecordState
transforms.changes.header.changed=ChangedFields
transforms.changes.header.unchanged=UnchangedFields</code></pre> </div> </div> <div class="paragraph"> <p>This transformation can be configured to disclose either what fields changed by setting <code>header.changed</code>, what fields are unchanged by setting <code>header.unchanged</code>, or both by setting both properties as shown above. The transformation will add a new header with the specified name and it&#8217;s value will include a collection of field names based on whether you&#8217;ve configured changes, non-changes, or both.</p> </div> </div> </div> <div class="sect1"> <h2 id="drop_fields_using_extractnewrecordstate_smt">Drop fields using ExtractNewRecordState SMT</h2> <div class="sectionbody"> <div class="paragraph"> <p>The <code>ExtractNewRecordState</code> single message transformation is extremely useful in situations where you need to consume the Debezium change event in a <em>flattened</em> format. This SMT has been changed in this release to add the ability to drop fields from the payload and the message key of the event.</p> </div> <div class="paragraph"> <p>This new feature introduces three new configuration properties for the transformation:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>drop.fields.header.name</code></dt> <dd> <p>The Kafka message header name to use for listing field names in the source message that are to be dropped.</p> </dd> <dt class="hdlist1"><code>drop.fields.from.key</code></dt> <dd> <p>Specifies whether to remove fields also from the key, defaults to <code>false</code>.</p> </dd> <dt class="hdlist1"><code>drop.fields.keep.schema.compatible</code></dt> <dd> <p>Specifies whether to remove fields that are only optional, defaults to <code>true</code>.</p> </dd> </dl> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>When using Avro, schema compatibility is extremely important. This is why we opted to enforce schema compatibility by default. If a field is configured to be dropped but it is non-optional, the field will not be removed from the key nor the payload unless schema compatibility is disabled.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>These new configuration options allow for some exciting ways to manipulate change events. For example, to emit events with only changed fields, pairing the <code>ExtractNewRecordState</code> with the new <code>ExtractChangedRecordState</code> transformation makes this extremely simple and straightforward. An example configuration to only emit changed columns would look like the following:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">transforms=changes,extract
transforms.changes.type=io.debezium.transforms.ExtractChangedRecordState
transforms.changes.header.unchanged=UnchangedFields
transforms.extract.type=io.debezium.transforms.ExtractNewRecordState
transforms.extract.drop.fields.header.name=UnchangedFields</code></pre> </div> </div> <div class="paragraph"> <p>The above configuration will explicitly not include unchanged fields from the event&#8217;s payload value. If a field in the key did not change, it will be unaffected because <code>drop.fields.from.key</code> was left as its default of <code>false</code>. And finally, if a field in the event&#8217;s payload is to be dropped because it did not change, but it&#8217;s not optional, it will continue to be included in the transformation&#8217;s output event to comply with schema compatibility.</p> </div> </div> </div> <div class="sect1"> <h2 id="reactive_debezium_outbox_quarkus_extension">Reactive Debezium Outbox Quarkus Extension</h2> <div class="sectionbody"> <div class="paragraph"> <p>The <a href="https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/">outbox pattern</a> is an approach that many microservices leverage to share data across microservice boundaries. We introduced the Debezium Outbox Quarkus Extension in Debezium 1.1 back in early 2020, and it has allowed Quarkus users to leverage the outbox pattern with ease using Debezium.</p> </div> <div class="paragraph"> <p>Thanks to <a href="https://github.com/ingmarfjolla">Ingmar Fjolla</a>, Debezium 2.2.0.Alpha2 includes a new reactive-based implementation of the Debezium Outbox Quarkus Extension. This new implementation is based on Vert.x and Hibernate Reactive, providing a fully asynchronous solution to the outbox pattern using Debezium.</p> </div> <div class="paragraph"> <p>This new extension will be included in the Quarkus Platform releases latter this quarter or early Q2, however, if you want to get started with it today, you can easily drop it directly into your project&#8217;s configuration using the following coordinates:</p> </div> <div class="listingblock"> <div class="title">Maven coordinates</div> <div class="content"> <pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
  <span class="tag">&lt;groupId&gt;</span>io.debezium<span class="tag">&lt;/groupId&gt;</span>
  <span class="tag">&lt;artifactId&gt;</span>debezium-quarkus-outbox-reactive<span class="tag">&lt;/artifactId&gt;</span>
  <span class="tag">&lt;version&gt;</span>2.2.0.Alpha2<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre> </div> </div> <div class="listingblock"> <div class="title">Gradle coordinates</div> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">io.debezium:debezium-quarkus-outbox-reactive:2.2.0.Alpha2</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="new_rocket_mq_schema_history_storage">New Rocket MQ Schema History Storage</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium&#8217;s new storage API has been a huge success over this past year. We initially started with our original file and Kafka based implementations for offset and schema history storage, but that has since grown to support storing schema history on other platforms such as Amazon S3 and Redis.</p> </div> <div class="paragraph"> <p>This release continues to expand on this by adding a new schema history storage implementation for Rocket MQ. In order to get started with storing your schema history into Rocket MQ, the <code>debezium-storage-rocketmq</code> dependency must first be on the classpath and accessible by the connector runtime.</p> </div> <div class="paragraph"> <p>Once the dependency exists, the only remaining step will be configuring the schema history connector configuration. The following example shows basic usage of the Rocket MQ schema history:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">schema.history.internal.rocketmq.topic=schema-history
schema.history.internal.rocketmq.name.srv.addr=172.17.15.2
schema.history.internal.rocketmq.acl.enabled=true
schema.history.internal.rocketmq.access.key=&lt;rocketmq-access-key&gt;
schema.history.internal.rocketmq.secret.key=&lt;rocketmq-secret-key&gt;
schema.history.internal.rocketmq.recovery.attempts=5
schema.history.internal.rocketmq.recovery.poll.interval.ms=1000
schema.history.internal.rocketmq.store.record.timeout.ms=2000</code></pre> </div> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>schema.history.internal.rocketmq.topic</code></dt> <dd> <p>Specifies the topic name where the schema history will be stored.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.name.srv.addr</code></dt> <dd> <p>Specifies the service discovery service nameserver for Rocket MQ.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.acl.enabled</code></dt> <dd> <p>Specifies whether access control lists (ACLs) are enabled, defaults to <code>false</code>.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.access.key</code></dt> <dd> <p>Specifies the Rocket MQ access key, required only if ACLs are enabled.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.secret.key</code></dt> <dd> <p>Specifies the Rocket MQ secret key, required only if ACLs are enabled.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.recovery.attempts</code></dt> <dd> <p>Specifies the number of sequential attempts that no data is returned before recovery completes.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.recovery.poll.interval.ms</code></dt> <dd> <p>Specifies the number of milliseconds for each poll attempt to recover the history.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.rocketmq.store.record.timeout.ms</code></dt> <dd> <p>Specifies the number of milliseconds for a write to Rocket MQ to complete before timing out.</p> </dd> </dl> </div> </div> </div> <div class="sect1"> <h2 id="other_fixes">Other fixes</h2> <div class="sectionbody"> <div class="paragraph"> <p>There were quite a number of other improvements, bug fixes, and stability changes in this release, some noteworthy are:</p> </div> <div class="ulist"> <ul> <li> <p>Better control on debezium GTID usage <a href="https://issues.redhat.com/browse/DBZ-2296">DBZ-2296</a></p> </li> <li> <p>Data type conversion failed for mysql bigint <a href="https://issues.redhat.com/browse/DBZ-5798">DBZ-5798</a></p> </li> <li> <p>ActivateTracingSpan wrong timestamps reported <a href="https://issues.redhat.com/browse/DBZ-5827">DBZ-5827</a></p> </li> <li> <p>Unable to specify column or table include list if name contains a backslash \ <a href="https://issues.redhat.com/browse/DBZ-5917">DBZ-5917</a></p> </li> <li> <p>debezium-connector-cassandra 2.1.0.Alpha2 plugin can no longer run "out of the box" <a href="https://issues.redhat.com/browse/DBZ-5925">DBZ-5925</a></p> </li> <li> <p>MongoDB Incremental Snapshot not Working <a href="https://issues.redhat.com/browse/DBZ-5973">DBZ-5973</a></p> </li> <li> <p>Nullable columns marked with "optional: false" in DDL events <a href="https://issues.redhat.com/browse/DBZ-6003">DBZ-6003</a></p> </li> <li> <p>Upgrade to Quarkus 2.16.0.Final <a href="https://issues.redhat.com/browse/DBZ-6005">DBZ-6005</a></p> </li> <li> <p>Vitess: Handle the shard list difference between current db shards and persisted shards <a href="https://issues.redhat.com/browse/DBZ-6011">DBZ-6011</a></p> </li> <li> <p>Offsets are not flushed on connect offsets topic when encountering an error on Postgres connector <a href="https://issues.redhat.com/browse/DBZ-6026">DBZ-6026</a></p> </li> <li> <p>Unexpected format for TIME column: 8:00 <a href="https://issues.redhat.com/browse/DBZ-6029">DBZ-6029</a></p> </li> <li> <p>Oracle does not support compression/logging clauses after an LOB storage clause <a href="https://issues.redhat.com/browse/DBZ-6031">DBZ-6031</a></p> </li> <li> <p>debezium-server Pulsar support non-default tenant and namespace <a href="https://issues.redhat.com/browse/DBZ-6033">DBZ-6033</a></p> </li> <li> <p>Debezium is logging the full message along with the error <a href="https://issues.redhat.com/browse/DBZ-6037">DBZ-6037</a></p> </li> <li> <p>Improve resilience during internal schema history recovery from Kafka <a href="https://issues.redhat.com/browse/DBZ-6039">DBZ-6039</a></p> </li> <li> <p>Vitess: Support Mapping unsigned bigint mysql column type to long <a href="https://issues.redhat.com/browse/DBZ-6043">DBZ-6043</a></p> </li> <li> <p>Incremental snapshot sends the events from signalling DB to Kafka <a href="https://issues.redhat.com/browse/DBZ-6051">DBZ-6051</a></p> </li> <li> <p>Upgrade Kafka to 3.3.2 <a href="https://issues.redhat.com/browse/DBZ-6054">DBZ-6054</a></p> </li> <li> <p>Mask password in log statement <a href="https://issues.redhat.com/browse/DBZ-6064">DBZ-6064</a></p> </li> <li> <p>Loading Custom offset storage fails with Class not found error <a href="https://issues.redhat.com/browse/DBZ-6075">DBZ-6075</a></p> </li> <li> <p>Increase query.fetch.size default to something sensible above zero <a href="https://issues.redhat.com/browse/DBZ-6079">DBZ-6079</a></p> </li> <li> <p>SQL Server tasks fail if the number of databases is smaller than maxTasks <a href="https://issues.redhat.com/browse/DBZ-6084">DBZ-6084</a></p> </li> <li> <p>When using LOB support, an UPDATE against multiple rows can lead to inconsistent event data <a href="https://issues.redhat.com/browse/DBZ-6107">DBZ-6107</a></p> </li> <li> <p>Expose sequence field in CloudEvents message id <a href="https://issues.redhat.com/browse/DBZ-6089">DBZ-6089</a></p> </li> <li> <p>Reduce verbosity of skipped transactions if transaction has no events relevant to captured tables <a href="https://issues.redhat.com/browse/DBZ-6094">DBZ-6094</a></p> </li> <li> <p>Upgrade Kafka client to 3.4.0 <a href="https://issues.redhat.com/browse/DBZ-6102">DBZ-6102</a></p> </li> </ul> </div> <div class="paragraph"> <p>Altogether, <a href="https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.2.0.Alpha2%20ORDER%20BY%20component%20ASC">53 issues</a> were fixed for this release. A big thank you to all the contributors from the community who worked on this release: <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/bruth">Byron Ruth</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/gunnarmorling">Gunnar Morling</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/HenryCaiHaiying">Henry Cai</a>, <a href="https://github.com/ingmarfjolla">Ingmar Fjolla</a>, <a href="https://github.com/ismailsimsek">Ismail Simsek</a>, <a href="https://github.com/jbarrieault">Jacob Barrieault</a>, <a href="https://github.com/sugarcrm-jgminder">Jacob Gminder</a>, <a href="https://github.com/jcechace">Jakub Cechacek</a>, <a href="https://github.com/jeremy-l-ford">Jeremy Ford</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/echatman-ias">Liz Chatman</a>, <a href="https://github.com/lokesh1729">Lokesh Sanapalli</a>, <a href="https://github.com/MartinMedek">Martin Medek</a>, <a href="https://github.com/roldanbob">Robert Roldan</a>, <a href="https://github.com/morozov">Sergei Morozov</a>, <a href="https://github.com/sunxiaojian">Sun Xiao Jian</a>, <a href="https://github.com/chtitux">Théophile Helleboid</a>, <a href="https://github.com/Tideri-Tim2">Tim Loes</a>, <a href="https://github.com/vjuranek">Vojtech Juranek</a>, <a href="https://github.com/y5w">Yang Wu</a>, and <a href="https://github.com/zzzming">ming luo</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="whats_next">What&#8217;s Next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>We&#8217;re still very early in the development cycle of Debezium 2.2 and many other features are still in development, including:</p> </div> <div class="ulist"> <ul> <li> <p>Configurable signal channels, enabling users to send signals not only from a database table or a Kafka topic, but also from other means such as an HTTP endpoint, the file system, etc.</p> </li> <li> <p>The Debezium JDBC sink connector that supports native Debezium change events out-of-the-box, without requiring the use of the Event Flattening transformation.</p> </li> <li> <p>And a plethora of Debezium UI enhancements</p> </li> </ul> </div> <div class="paragraph"> <p>We are about middle way through the quarter and Debezium 2.2 will begin to enter beta phase very soon. We would love to hear your feedback or suggestions regarding the roadmap, changes in this release, those that are outstanding, or anything we haven&#8217;t mentioned. Be sure to get in touch with us on the <a href="https://groups.google.com/g/debezium">mailing list</a> or our <a href="https://debezium.zulipchat.com/login/#narrow/stream/302529-users">chat</a> if there is.</p> </div> <div class="paragraph"> <p>Also be on the lookout for our first installment of our 2023 Newsletter as well as the upcoming and conclusion to the blog series, "Debezium for Oracle" where I cover performance, debugging, and frequently asked questions about the Oracle connector.</p> </div> <div class="paragraph"> <p>Until next time&#8230;&#8203;</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html"><![CDATA[Today, I am pleased to announce the second alpha release in the 2.2 release stream, Debezium 2.2.0.Alpha2. This release includes a plethora of bug fixes, improvements, breaking changes, and a number of new features including, but not limited to, a new ExtractRecordChanges single message transformation, a Reactive-based implementation of the Debezium Outbox extension for Quarkus, a Debezium Storage module for Apache RocketMQ, and much more. Let&#8217;s take moment and dive into these new features, improvements, and breaking changes.]]></summary></entry><entry><title type="html">DDD Aggregates via CDC-CQRS Pipeline using Kafka &amp;amp; Debezium</title><link href="https://debezium.io/blog/2023/02/04/ddd-aggregates-via-cdc-cqrs-pipeline-using-kafka-and-debezium/" rel="alternate" type="text/html" title="DDD Aggregates via CDC-CQRS Pipeline using Kafka &amp;amp; Debezium"/><published>2023-02-04T00:00:00+00:00</published><updated>2023-02-04T00:00:00+00:00</updated><id>https://debezium.io/blog/2023/02/04/ddd-aggregates-via-cdc-cqrs-pipeline-using-kafka-and-debezium</id><content type="html" xml:base="https://debezium.io/blog/2023/02/04/ddd-aggregates-via-cdc-cqrs-pipeline-using-kafka-and-debezium/"><![CDATA[<div class="paragraph"> <p>In this post, we are going to talk about a CDC-CQRS pipeline between a normalized relational database, MySQL, as the command database and a de-normalized NoSQL database, MongoDB, as the query database resulting in the creation of DDD Aggregates via Debezium &amp; Kafka-Streams.</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>You can find the complete source code of the example <a href="https://github.com/purnima-jain/cdc-cqrs-pipeline">here</a>. Refer to the <a href="https://github.com/purnima-jain/cdc-cqrs-pipeline/blob/master/README.md">README.md</a> for details on building and running the example code.</p> </div> <div class="paragraph"> <p>The example is centered around three microservices: <code>order-write-service</code>, <code>order-aggregation-service</code> and <code>order-read-service</code>. These services are implemented as Spring-Boot applications in Java.</p> </div> <div class="paragraph"> <p>The <code>order-write-service</code> exposes two REST endpoints which persist shipping-details and item-details in their respective tables on MySQL database. Debezium tails the MySQL bin logs to capture any events in both these tables and publishes messages to Kafka topics. These topics are consumed by <code>order-aggregation-service</code> which is a Kafka-Streams application that joins data from both of these topics to create an Order-Aggregate object which is then published to a third topic. This topic is consumed by MongoDB Sink Connector and the data is persisted in MongoDB which is served by <code>order-read-service</code>.</p> </div> <div class="paragraph"> <p>The overall architecture of the solution can be seen in the following diagram:</p> </div> <div class="exampleblock centered-image responsive-image"> <div class="content"> <img src="/assets/images/2023-02-04-ddd-aggregates-via-cdc-cqrs-pipeline-using-kafka-and-debezium/design_overview.png" style="max-width:90%;" class="responsive-image"> </div> </div> <div class="sect1"> <h2 id="rest_application_order_write_service">REST Application: order-write-service</h2> <div class="sectionbody"> <div class="paragraph"> <p>The first component that triggers the workflow starts is the <code>order-write-service</code>. This has been implemented as a Spring-Boot application and exposes two REST end-points:</p> </div> <div class="ulist"> <ul> <li> <p>POST: <code>api/shipping-details</code> to persist shipping details in the MySQL database</p> </li> <li> <p>POST: <code>api/item-details</code> to persist item details in the MySQL database</p> </li> </ul> </div> <div class="paragraph"> <p>Both of these endpoints persist their data in their respective tables in the MySQL database.</p> </div> </div> </div> <div class="sect1"> <h2 id="command_database_mysql">Command Database: MySQL</h2> <div class="sectionbody"> <div class="paragraph"> <p>The backend processing of the above-mentioned REST endpoints culminates in persisting the data in their respective tables in MySQL.</p> </div> <div class="paragraph"> <p>Shipping details are stored in a table called <code>SHIPPING_DETAILS</code>. And Item details are stored in a table called <code>ITEM_DETAILS</code>.</p> </div> <div class="paragraph"> <p>Here is the data-model of <code>SHIPPING_DETAILS</code> table, the column <code>ORDER_ID</code> is its primary key:</p> </div> <div class="exampleblock centered-image responsive-image"> <div class="content"> <img src="/assets/images/2023-02-04-ddd-aggregates-via-cdc-cqrs-pipeline-using-kafka-and-debezium/shipping_details_data_model.png" style="max-width:100%;" class="responsive-image"> </div> </div> <div class="paragraph"> <p>Here is the data-model of <code>ITEM_DETAILS</code> table, the column <code>ORDER_ID</code> + <code>ITEM_ID</code> is its primary key:</p> </div> <div class="exampleblock centered-image responsive-image"> <div class="content"> <img src="/assets/images/2023-02-04-ddd-aggregates-via-cdc-cqrs-pipeline-using-kafka-and-debezium/item_details_data_model.png" style="max-width:100%;" class="responsive-image"> </div> </div> </div> </div> <div class="sect1"> <h2 id="kafka_connect_source_connector_mysql_cdc_debezium">Kafka-Connect Source Connector: MySQL CDC Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Change Data Capture (CDC) is a solution that captures change events from a database transaction log (called BinLogs in the case of MySQL) and forwards those events to downstream consumers ex. Kafka topic.</p> </div> <div class="paragraph"> <p>Debezium is a platform that provides a low latency data streaming platform for change data capture (CDC) and is built on top of Apache Kafka. It allows database row-level changes to be captured as events and published to Apache Kafka topics. We setup and configure Debezium to monitor our databases, and then our applications consume events for each row-level change made to the database.</p> </div> <div class="paragraph"> <p>In our case, we will be using Debezium MySQL Source connector to capture any new events in the aforementioned tables and relay them to Apache Kafka. To achieve this, we will be registering our connecter by POST-ing the following JSON request to the REST API of Kafka Connect:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">app-mysql-db-connector</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">config</span><span class="delimiter">&quot;</span></span>: {
        <span class="key"><span class="delimiter">&quot;</span><span class="content">connector.class</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">io.debezium.connector.mysql.MySqlConnector</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">tasks.max</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">1</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.hostname</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">mysql_db_server</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.port</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">3306</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.user</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">custom_mysql_user</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.password</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">custom_mysql_user_password</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.server.id</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">184054</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.server.name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">app-mysql-server</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.whitelist</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">app-mysql-db</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">table.whitelist</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">app-mysql-db.shipping_details,app-mysql-db.item_details</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.history.kafka.bootstrap.servers</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">kafka_server:29092</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database.history.kafka.topic</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">dbhistory.app-mysql-db</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">include.schema.changes</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">transforms</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">unwrap</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">transforms.unwrap.type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">io.debezium.transforms.ExtractNewRecordState</span><span class="delimiter">&quot;</span></span>
    }
}</code></pre> </div> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>The above configuration is based on Debezium 1.9.5.Final. Be aware that if you attempt to use the demo with Debezium 2.0+, a number of the above configuration properties have new names and the configuration will require some adjustments.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>This sets up an instance of <code>io.debezium.connector.mysql.MySqlConnector</code>, capturing changes from the specified MySQL instance. Note that by means of a table include list, only changes from the <code>SHIPPING_DETAILS</code> and <code>ITEM_DETAILS</code> tables are captured. It also applies a single message transform (SMT) named <code>ExtractNewRecordState</code> which extracts the <code>after</code> field from a Debezium change event in a Kafka record. The SMT replaces the original change event with only its <code>after</code> field to create a simple Kafka record.</p> </div> <div class="paragraph"> <p>By default, the Kafka topic name is “serverName.schemaName.tableName” which as per our connector configuration translates to:</p> </div> <div class="ulist"> <ul> <li> <p><code>app-mysql-server.app-mysql-db.item_details</code></p> </li> <li> <p><code>app-mysql-server.app-mysql-db.shipping_details</code></p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="kafka_streams_application_order_aggregation_service">Kafka-Streams Application: order-aggregation-service</h2> <div class="sectionbody"> <div class="paragraph"> <p>The Kafka-Streams application, namely <code>order-aggregation-service</code>, is going to process data from the two Kafka cdc-topics. These topics receive CDC events based on the shipping-details and item-details relations found in MySQL.</p> </div> <div class="paragraph"> <p>With that in place, the KStreams topology to create and maintain DDD order-aggregates on-the-fly can be built as follows.</p> </div> <div class="paragraph"> <p>The application reads the data from the shipping-details-cdc-topic. Since the Kafka topic records are in Debezium JSON format with unwrapped envelopes we need to parse the order-id and the shipping-details from it to create a KTable with order-id as the key and shipping-details as the value.</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// Shipping Details Read</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; shippingDetailsSourceInputKStream = streamsBuilder.stream(shippingDetailsTopicName, Consumed.with(STRING_SERDE, STRING_SERDE));

<span class="comment">// Change the Json value of the message to ShippingDetailsDto</span>
KStream&lt;<span class="predefined-type">String</span>, ShippingDetailsDto&gt; shippingDetailsDtoWithKeyAsOrderIdKStream = shippingDetailsSourceInputKStream
                        .map((orderIdJson, shippingDetailsJson) -&gt; <span class="keyword">new</span> KeyValue&lt;&gt;(parseOrderId(orderIdJson), parseShippingDetails(shippingDetailsJson)));

<span class="comment">// Convert KStream to KTable</span>
KTable&lt;<span class="predefined-type">String</span>, ShippingDetailsDto&gt; shippingDetailsDtoWithKeyAsOrderIdKTable = shippingDetailsDtoWithKeyAsOrderIdKStream.toTable(
                        Materialized.&lt;<span class="predefined-type">String</span>, ShippingDetailsDto, KeyValueStore&lt;Bytes, <span class="type">byte</span><span class="type">[]</span>&gt;&gt;as(SHIPPING_DETAILS_DTO_STATE_STORE).withKeySerde(STRING_SERDE).withValueSerde(SHIPPING_DETAILS_DTO_SERDE));</code></pre> </div> </div> <div class="paragraph"> <p>Similarly, the application reads the data from the item-details-cdc-topic and parses the order-id and the item from each individual message to group-by all the items pertaining to the same order-id in one list which is then aggregated to a KTable with order-id as key and the list of items pertaining to that specific order-id as value.</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// Item Details Read</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; itemDetailsSourceInputKStream = streamsBuilder.stream(itemDetailsTopicName, Consumed.with(STRING_SERDE, STRING_SERDE));

<span class="comment">// Change the Key of the message from ItemId + OrderId to only OrderId and parse the Json value to ItemDto</span>
KStream&lt;<span class="predefined-type">String</span>, ItemDto&gt; itemDtoWithKeyAsOrderIdKStream = itemDetailsSourceInputKStream
                        .map((itemIdOrderIdJson, itemDetailsJson) -&gt; <span class="keyword">new</span> KeyValue&lt;&gt;(parseOrderId(itemIdOrderIdJson), parseItemDetails(itemDetailsJson)));

<span class="comment">// Group all the ItemDtos for each OrderId</span>
KGroupedStream&lt;<span class="predefined-type">String</span>, ItemDto&gt; itemDtoWithKeyAsOrderIdKGroupedStream = itemDtoWithKeyAsOrderIdKStream.groupByKey(Grouped.with(STRING_SERDE, ITEM_DTO_SERDE));

<span class="comment">// Aggregate all the ItemDtos pertaining to each OrderId in a list</span>
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">ArrayList</span>&lt;ItemDto&gt;&gt; itemDtoListWithKeyAsOrderIdKTable = itemDtoWithKeyAsOrderIdKGroupedStream.aggregate(
                (Initializer&lt;<span class="predefined-type">ArrayList</span>&lt;ItemDto&gt;&gt;) <span class="predefined-type">ArrayList</span>::<span class="keyword">new</span>,
                (orderId, itemDto, itemDtoList) -&gt; addItemToList(itemDtoList, itemDto),
                Materialized.&lt;<span class="predefined-type">String</span>, <span class="predefined-type">ArrayList</span>&lt;ItemDto&gt;, KeyValueStore&lt;Bytes, <span class="type">byte</span><span class="type">[]</span>&gt;&gt;as(ITEM_DTO_STATE_STORE).withKeySerde(STRING_SERDE).withValueSerde(ITEM_DTO_ARRAYLIST_SERDE));</code></pre> </div> </div> <div class="paragraph"> <p>With both the KTables having order-id as the key, it’s easy enough to join them using order-id to create an aggregate called Order-Aggregate. Order-Aggregate is a composite object created by assimilating data from both the shipping-details as well as the item-details. This Order-Aggregate is then written to an order-aggregate Kafka topic.</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// Joining the two tables: shippingDetailsDtoWithKeyAsOrderIdKTable and itemDtoListWithKeyAsOrderIdKTable</span>
ValueJoiner&lt;ShippingDetailsDto, <span class="predefined-type">ArrayList</span>&lt;ItemDto&gt;, OrderAggregate&gt; shippingDetailsAndItemListJoiner = (shippingDetailsDto, itemDtoList) -&gt; instantiateOrderAggregate(shippingDetailsDto, itemDtoList);
KTable&lt;<span class="predefined-type">String</span>, OrderAggregate&gt; orderAggregateKTable = shippingDetailsDtoWithKeyAsOrderIdKTable.join(itemDtoListWithKeyAsOrderIdKTable, shippingDetailsAndItemListJoiner);

<span class="comment">// Outputting to Kafka Topic</span>
orderAggregateKTable.toStream().to(orderAggregateTopicName, Produced.with(STRING_SERDE, ORDER_AGGREGATE_SERDE));</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="kafka_connect_sink_connector_mongodb_connector">Kafka-Connect Sink Connector: MongoDB Connector</h2> <div class="sectionbody"> <div class="paragraph"> <p>The sink connector is a Kafka Connect connector that reads data from Apache Kafka and writes data to some data-store. Using a MongoDB sink connector, it is easy to have the DDD aggregates written into MongoDB. All it needs is a configuration which can be posted to the REST API of Kafka Connect in order to run the connector.</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">app-mongo-sink-connector</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">config</span><span class="delimiter">&quot;</span></span>: {
        <span class="key"><span class="delimiter">&quot;</span><span class="content">connector.class</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">com.mongodb.kafka.connect.MongoSinkConnector</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">topics</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">order_aggregate</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">connection.uri</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">mongodb://root_mongo_user:root_mongo_user_password@mongodb_server:27017</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">key.converter</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.connect.storage.StringConverter</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">value.converter</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.connect.json.JsonConverter</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">value.converter.schemas.enable</span><span class="delimiter">&quot;</span></span>: <span class="value">false</span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">database</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">order_db</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">collection</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">order</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">document.id.strategy.overwrite.existing</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">document.id.strategy</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">com.mongodb.kafka.connect.sink.processor.id.strategy.ProvidedInKeyStrategy</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">transforms</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">hk,hv</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">transforms.hk.type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.connect.transforms.HoistField$Key</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">transforms.hk.field</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">_id</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">transforms.hv.type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.connect.transforms.HoistField$Value</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">transforms.hv.field</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">order</span><span class="delimiter">&quot;</span></span>
    }
}</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="query_database_mongodb">Query Database: MongoDB</h2> <div class="sectionbody"> <div class="paragraph"> <p>The DDD aggregate is written to the database <code>order_db</code> in the collection <code>order</code> on MongoDB. The order-id becomes the <code>_id</code> of the table and the <code>order</code> column stores the order-aggregate as JSON.</p> </div> </div> </div> <div class="sect1"> <h2 id="rest_application_order_read_service">REST Application: order-read-service</h2> <div class="sectionbody"> <div class="paragraph"> <p>The Order Aggregate persisted in MongoDB is served via a REST endpoint in <code>order-read-service</code>.</p> </div> <div class="ulist"> <ul> <li> <p>GET: <code>api/order/{order-id}</code> to retrieve the order from the MongoDB database</p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="execution_instructions">Execution Instructions</h2> <div class="sectionbody"> <div class="paragraph"> <p>The complete source code for this blog post is provided <a href="https://github.com/purnima-jain/cdc-cqrs-pipeline">here</a> in Github. Begin by cloning this repository and changing into the <code>cdc-cqrs-pipeline</code> directory. The project provides a Docker Compose file with services for all the components:</p> </div> <div class="ulist"> <ul> <li> <p>MySQL</p> </li> <li> <p>Adminer (formerly known as phpMinAdmin), to manage MySQL via browser</p> </li> <li> <p>MongoDB</p> </li> <li> <p>Mongo Express, to manage MongoDB via browser</p> </li> <li> <p>Zookeeper</p> </li> <li> <p>Confluent Kafka</p> </li> <li> <p>Kafka Connect</p> </li> </ul> </div> <div class="paragraph"> <p>Once all services have started, register an instance of the Debezium MySQL connector &amp; MongoDB Connector by executing the <code>Create-MySQL-Debezium-Connector</code> and <code>Create-MongoDB-Sink-Connector</code> request respectively from <code>cdc-cqrs-pipeline.postman_collection.json</code>. Execute the request <code>Get-All-Connectors</code> to verify that the connectors have been properly created.</p> </div> <div class="paragraph"> <p>Change into the individual directories and spin-up the three Spring-Boot applications:</p> </div> <div class="ulist"> <ul> <li> <p><code>order-write-service</code>: runs on port no <code>8070</code></p> </li> <li> <p><code>order-aggregation-service</code>: runs on port no <code>8071</code></p> </li> <li> <p><code>order-read-service</code>: runs on port no <code>8072</code></p> </li> </ul> </div> <div class="paragraph"> <p>With this, our setup is complete.</p> </div> <div class="paragraph"> <p>To test the application, execute the request <code>Post-Shipping-Details</code> from the postman collection to insert shipping-details and <code>Post-Item-Details</code> to insert item-details for a particular order id.</p> </div> <div class="paragraph"> <p>Finally, execute the <code>Get-Order-By-Order-Id</code> request in the postman collection to retrieve the complete Order Aggregate.</p> </div> </div> </div> <div class="sect1"> <h2 id="summary">Summary</h2> <div class="sectionbody"> <div class="paragraph"> <p>Apache Kafka acts as a highly scalable and reliable backbone for the messaging amongst the services. Putting Apache Kafka into the center of the overall architecture also ensures a decoupling of involved services. If for instance single components of the solution fail or are not available for some time, events will simply be processed later on: after a restart, the Debezium connector will continue to tail the relevant tables from the point where it left off before. Similarly, any consumer will continue to process topics from its previous offset. By keeping track of already successfully processed messages, duplicates can be detected and excluded from repeated handling.</p> </div> <div class="paragraph"> <p>Naturally, such event pipeline between different services is eventually consistent, i.e. consumers such as the order-read-service may lag a bit behind producers such as the order-write-service. Usually, that’s just fine, though, and can be handled in terms of the application’s business logic. Also, end-to-end delays of the overall solution are typically low (seconds or even sub-second range), thanks to log-based change data capture which allows for emission of events in near-realtime.</p> </div> </div> </div>]]></content><author><name>Purnima Jain</name></author><category term="ddd"/><category term="cdc"/><category term="cqrs"/><category term="debezium"/><category term="kafka"/><summary type="html"><![CDATA[In this post, we are going to talk about a CDC-CQRS pipeline between a normalized relational database, MySQL, as the command database and a de-normalized NoSQL database, MongoDB, as the query database resulting in the creation of DDD Aggregates via Debezium &amp; Kafka-Streams.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://debezium.io/assets/images/2023-02-04-ddd-aggregates-via-cdc-cqrs-pipeline-using-kafka-and-debezium/design_overview.png"/><media:content medium="image" url="https://debezium.io/assets/images/2023-02-04-ddd-aggregates-via-cdc-cqrs-pipeline-using-kafka-and-debezium/design_overview.png" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">Debezium 2.1.2.Final Released</title><link href="https://debezium.io/blog/2023/01/26/debezium-2-1-2-final-released/" rel="alternate" type="text/html" title="Debezium 2.1.2.Final Released"/><published>2023-01-26T00:00:00+00:00</published><updated>2023-01-26T00:00:00+00:00</updated><id>https://debezium.io/blog/2023/01/26/debezium-2-1-2-final-released</id><content type="html" xml:base="https://debezium.io/blog/2023/01/26/debezium-2-1-2-final-released/"><![CDATA[<div class="paragraph"> <p>The Debezium release cadence is in full swing as I&#8217;m excited to announce Debezium <strong>2.1.2.Final</strong>!</p> </div> <div class="paragraph"> <p>This release focuses primarily on bug fixes and stability; and it is the recommended update for all users from earlier versions. This release contains <a href="https://issues.redhat.com/issues/?jql=project+%3D+DBZ+AND+fixVersion+%3D+2.1.2.Final">28 resolved issues</a>, so let&#8217;s take a moment and discuss a critical breaking change.</p> </div> <div class="paragraph"> <p></p> </div> <div class="sect1"> <h2 id="breaking_change">Breaking Change</h2> <div class="sectionbody"> <div class="paragraph"> <p>An edge case was reported in <a href="https://issues.redhat.com/browse/issues/DBZ-5996">DBZ-5996</a> where if a temporal column used <code>ZonedTimestamp</code> and if the column&#8217;s value had <code>0</code> micro or nanoseconds, rather than emitting the value as <code>2023-01-19T12:30:00.123000Z</code>, the value would be emitted in a truncated way as <code>2023-01-19T12:30:00.123Z</code>. This could lead to other issues with converters used in the event pipeline when the output from that column could be formatted inconsistently.</p> </div> <div class="paragraph"> <p>In order to remedy the edge case, the <code>ZonedTimestamp</code> implementation will now pad the fraction-based seconds value of the column&#8217;s value to the length/scale of the source database column. Using the example above of a <code>TIMESTAMP(6)</code> MySQL column type, the emitted value will now properly reflect a value of <code>2023-01-19T12:30:00.123000Z</code>.</p> </div> <div class="paragraph"> <p>While this change in behavior is likely to have minimal impact to most users, we wanted to bring attention to it in the event that you&#8217;ve perhaps used other means to handle this edge case in your pipelines. If you have, you should be able to rely on Debezium to emit the value consistently, even when the fraction-based seconds is <code>0</code>.</p> </div> </div> </div> <div class="sect1"> <h2 id="other_changes">Other changes</h2> <div class="sectionbody"> <div class="paragraph"> <p>A few noteworthy bug fixes and stability improvements include:</p> </div> <div class="ulist"> <ul> <li> <p>Data type conversion failed for mysql bigint <a href="https://issues.redhat.com/browse/DBZ-5798">DBZ-5798</a></p> </li> <li> <p>Oracle cannot undo change <a href="https://issues.redhat.com/browse/DBZ-5907">DBZ-5907</a></p> </li> <li> <p>Truncate records incompatible with ExtractNewRecordState <a href="https://issues.redhat.com/browse/DBZ-5966">DBZ-5966</a></p> </li> <li> <p>Computed partition must not be negative <a href="https://issues.redhat.com/browse/DBZ-5967">DBZ-5967</a></p> </li> <li> <p>NPE in execute snapshot signal with exclude.tables config on giving wrong table name <a href="https://issues.redhat.com/browse/DBZ-5988">DBZ-5988</a></p> </li> <li> <p>There is a problem with postgresql connector parsing the boundary value of money type <a href="https://issues.redhat.com/browse/DBZ-5991">DBZ-5991</a></p> </li> <li> <p>Nullable columns marked with "optional: false" in DDL events <a href="https://issues.redhat.com/browse/DBZ-6003">DBZ-6003</a></p> </li> <li> <p>Vitess: Handle the shard list difference between current db shards and persisted shards <a href="https://issues.redhat.com/browse/DBZ-6011">DBZ-6011</a></p> </li> <li> <p>Postgres LSN check should honor event.processing.failure.handling.mode <a href="https://issues.redhat.com/browse/DBZ-6012">DBZ-6012</a></p> </li> <li> <p>Enhance the Spanner connector by adding features and/or solving bugs <a href="https://issues.redhat.com/browse/DBZ-6014">DBZ-6014</a></p> </li> <li> <p>DDL statement with TokuDB engine specific "CLUSTERING KEY" couldn&#8217;t be parsed <a href="https://issues.redhat.com/browse/DBZ-6016">DBZ-6016</a></p> </li> <li> <p>DDL parse fail for role revoke with "user-like" role name <a href="https://issues.redhat.com/browse/DBZ-6019">DBZ-6019</a></p> </li> <li> <p>DDL parse fail for ALTER USER x DEFAULT ROLE y; <a href="https://issues.redhat.com/browse/DBZ-6020">DBZ-6020</a></p> </li> <li> <p>Offsets are not flushed on connect offsets topic when encountering an error on Postgres connector <a href="https://issues.redhat.com/browse/DBZ-6026">DBZ-6026</a></p> </li> <li> <p>Unexpected format for TIME column: 8:00 <a href="https://issues.redhat.com/browse/DBZ-6029">DBZ-6029</a></p> </li> <li> <p>Oracle does not support compression/logging clauses after an LOB storage clause <a href="https://issues.redhat.com/browse/DBZ-6031">DBZ-6031</a></p> </li> <li> <p>Debezium is logging the full message along with the error <a href="https://issues.redhat.com/browse/DBZ-6037">DBZ-6037</a></p> </li> <li> <p>Improve resilience during internal schema history recovery from Kafka <a href="https://issues.redhat.com/browse/DBZ-6039">DBZ-6039</a></p> </li> </ul> </div> <div class="paragraph"> <p>Please refer to the <a href="/releases/2.1/release-notes#release-2.1.2-final">release notes</a> to learn more about all fixed bugs, update procedures, etc.</p> </div> <div class="paragraph"> <p>Many thanks to the following individuals from the community who contributed to Debezium 2.1.2.Final: Akshansh Jain, <a href="https://github.com/akanimesh7">Animesh Kumar</a>, <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/HenryCaiHaiying">Henry Cai</a>, <a href="https://github.com/indraraj">Indra Shukla</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/Lucascanna">Luca Scannapieco</a>, <a href="https://github.com/mfvitale">Mario Fiore Vitale</a>, <a href="https://github.com/dude0001">Mark Lambert</a>, <a href="https://github.com/morozov">Sergei Morozov</a>, <a href="https://github.com/vjuranek">Vojtech Juranek</a>, <a href="https://github.com/yoheimuta">Yohei Yoshimuta</a>, and <a href="https://github.com/yoheimuta">yohei yoshimuta</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="outlook_whats_next">Outlook, What&#8217;s next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium 2.1 will continue to receive bug fix and maintenance changes throughout this quarter. I expect there will be at least one additional release likely toward the middle or late February or March timeframe as we begin to wrap up up the work on Debezium 2.2.</p> </div> <div class="paragraph"> <p>Regarding Debezium 2.2, we intend to deliver another Alpha build in the coming weeks. We have lots of features still in the works, including the JDBC Sink Connector, configurable signal channels, new message transformations, and much more.</p> </div> <div class="paragraph"> <p>Stay tuned, and until then &#8230;&#8203;</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html"><![CDATA[The Debezium release cadence is in full swing as I&#8217;m excited to announce Debezium 2.1.2.Final! This release focuses primarily on bug fixes and stability; and it is the recommended update for all users from earlier versions. This release contains 28 resolved issues, so let&#8217;s take a moment and discuss a critical breaking change.]]></summary></entry><entry><title type="html">We Are Hiring (Saga continues)</title><link href="https://debezium.io/blog/2023/01/24/we-are-hiring-2/" rel="alternate" type="text/html" title="We Are Hiring (Saga continues)"/><published>2023-01-24T00:00:00+00:00</published><updated>2023-01-24T00:00:00+00:00</updated><id>https://debezium.io/blog/2023/01/24/we-are-hiring-2</id><content type="html" xml:base="https://debezium.io/blog/2023/01/24/we-are-hiring-2/"><![CDATA[<div class="paragraph"> <p>In November last year, we <a href="/blog/2022/11/15/filling-the-ranks/">announced</a> we were looking for reinforcements for the team. And I have two pieces of news for you today: a good one and an even better one.</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>The good news is that we will have a new pair of hands joining the team soon. It is still early to share more details, but we are happy to see the new guy with us!</p> </div> <div class="paragraph"> <p>How about the better news? Well, we can have one more person! The process has changed a bit since the last time, but everything else holds! So if you are interested then please apply via the Red Hat <a href="https://global-redhat.icims.com/jobs/97420/principal-software-engineer---openshift-connectors/job">job portal</a>.</p> </div> <div class="paragraph"> <p>Don’t be shy, and don’t underestimate yourself. We would rather speak to more people than miss you!</p> </div>]]></content><author><name>Jiri Pechanec</name></author><category term="community"/><category term="hiring"/><summary type="html"><![CDATA[In November last year, we announced we were looking for reinforcements for the team. And I have two pieces of news for you today: a good one and an even better one.]]></summary></entry><entry><title type="html">Debezium 2.2.0.Alpha1 Released</title><link href="https://debezium.io/blog/2023/01/19/debezium-2-2-alpha1-released/" rel="alternate" type="text/html" title="Debezium 2.2.0.Alpha1 Released"/><published>2023-01-19T00:00:00+00:00</published><updated>2023-01-19T00:00:00+00:00</updated><id>https://debezium.io/blog/2023/01/19/debezium-2-2-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2023/01/19/debezium-2-2-alpha1-released/"><![CDATA[<div class="paragraph"> <p>It&#8217;s my pleasure to announce not only the first release of the Debezium 2.2 series, but also the first release of Debezium in 2023, <strong>2.2.0.Alpha</strong>!</p> </div> <div class="paragraph"> <p>The Debezium 2.2.0.Alpha1 release includes some breaking changes, a number of bug fixes, and some noteworthy improvements and features, including but not limited to:</p> </div> <div class="ulist"> <ul> <li> <p>[Breaking Change] - <code>ZonedTimestamp</code> values will no longer truncate fractional seconds.</p> </li> <li> <p>[New] - Support ingesting changes from an Oracle logical stand-by database</p> </li> <li> <p>[New] - Support Amazon S3 buckets using the Debezium Storage API</p> </li> <li> <p>[New] - Support retrying database connections during connector start-up</p> </li> <li> <p>[New] - Debezium Server sink connector support for Apache RocketMQ and Infinispan</p> </li> </ul> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>Let&#8217;s take a few moments and dive into some of the features in more detail!</p> </div> <div class="sect1"> <h2 id="breaking_change">Breaking Change</h2> <div class="sectionbody"> <div class="paragraph"> <p>An edge case was reported in <a href="https://issues.redhat.com/browse/issues/DBZ-5996">DBZ-5996</a> where if a temporal column used <code>ZonedTimestamp</code> and if the column&#8217;s value had <code>0</code> micro or nanoseconds, rather than emitting the value as <code>2023-01-19T12:30:00.123000Z</code>, the value would be emitted in a truncated way as <code>2023-01-19T12:30:00.123Z</code>. This could lead to other issues with converters used in the event pipeline when the output from that column could be formatted inconsistently.</p> </div> <div class="paragraph"> <p>In order to remedy the edge case, the <code>ZonedTimestamp</code> implementation will now pad the fraction-based seconds value of the column&#8217;s value to the length/scale of the source database column. Using the example above of a <code>TIMESTAMP(6)</code> MySQL column type, the emitted value will now properly reflect a value of <code>2023-01-19T12:30:00.123000Z</code>.</p> </div> <div class="paragraph"> <p>While this change in behavior is likely to have minimal impact to most users, we wanted to bring attention to it in the event that you&#8217;ve perhaps used other means to handle this edge case in your pipelines. If you have, you should be able to rely on Debezium to emit the value consistently, even when the fraction-based seconds is <code>0</code>.</p> </div> </div> </div> <div class="sect1"> <h2 id="ingesting_changes_from_oracle_logical_stand_bys">Ingesting changes from Oracle logical stand-bys</h2> <div class="sectionbody"> <div class="paragraph"> <p>The Debezium for Oracle connector normally manages what is called a <em>flush table</em>, which is an internal table used to manage the flush cycles used by the Oracle Log Writer Buffer (LGWR) process. This flushing process requires that the user account the connector uses to have permission to create and write to this table. Logical stand-by databases often have more restrictive rules about data manipulation and may even be read-only, therefore, writing to the database is unfavorable or even not permissible.</p> </div> <div class="paragraph"> <p>To support an Oracle read-only logical stand-by database, we introduced a flag to disable the creation and management of this <em>flush table</em>. This feature can be used with both Oracle Standalone and Oracle RAC installations, and is currently considered incubating, meaning its subject to change in the future.</p> </div> <div class="paragraph"> <p>In order to enable Oracle read-only logical stand-by support, add the following connector option:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">internal.log.mining.read.only=true</code></pre> </div> </div> <div class="paragraph"> <p>In a future version, we plan to add support for an Oracle read-only physical stand-by database.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>This configuration option is prefixed with <code>internal.</code>, meaning that it&#8217;s considered an undocumented and experimental feature. The semantics and behavior of this option are subject to change in future versions that may not be guaranteed forward or backward compatible.</p> </div> </td> </tr> </table> </div> </div> </div> <div class="sect1"> <h2 id="using_amazon_s3_buckets_with_storage_api">Using Amazon S3 buckets with Storage API</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium provides a Storage API framework that enables connectors to store offset and schema history state in a variety of persistence datastores. Moreover, the framework enables contributors to extend the API by adding new storage implementations with ease. Currently, the Storage API framework supports the local FileSystem, a Kafka Topic, or Redis datastores.</p> </div> <div class="paragraph"> <p>With Debezium 2.2, we&#8217;re pleased to add Amazon S3 buckets as part of that framework, allowing the schema history to be persisted to an S3 bucket. An example connector configuration using S3 might look like the following:</p> </div> <div class="listingblock properties"> <div class="content"> <pre class="CodeRay highlight"><code>...
schema.history.internal=io.debezium.storage.s3.history
schema.history.internal.s3.access.key.id=aa
schema.history.internal.s3.secret.access.key=bb
schema.history.internal.s3.region.name=aws-global
schema.history.internal.s3.bucket.name=debezium
schema.history.internal.s3.object.name=db-history.log
schema.history.internal.s3.endpoint=http://&lt;server&gt;:&lt;port&gt;</code></pre> </div> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>schema.history.internal.s3.access.key.id</code></dt> <dd> <p>Specifies the access key required to authenticate to S3.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.s3.secret.access.key</code></dt> <dd> <p>Specifies the secret access key required to authenticate to S3.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.s3.region.name</code></dt> <dd> <p>Specifies the region where the S3 bucket is available.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.s3.bucket.name</code></dt> <dd> <p>Specifies the name of the S3 bucket where the schema history is to be persisted.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.s3.object.name</code></dt> <dd> <p>Specifies the object name in the bucket where the schema history is to be persisted.</p> </dd> <dt class="hdlist1"><code>schema.history.internal.s3.endpoint</code></dt> <dd> <p>Specifies the S3 endpoint with the format of <code><a href="http://&lt;server&gt;:&lt;port&gt" class="bare">http://&lt;server&gt;:&lt;port&gt</a>;</code>.</p> </dd> </dl> </div> </div> </div> <div class="sect1"> <h2 id="retry_database_connections_on_start_up">Retry database connections on start-up</h2> <div class="sectionbody"> <div class="paragraph"> <p>In previous releases of Debezium, the connector start-up phase used a fail-fast strategy. Simply put, this meant that if we couldn&#8217;t connect, authenticate, or performs any of the start-up phase steps required by the connector, the connector would enter a <code>FAILED</code> state.</p> </div> <div class="paragraph"> <p>One specific problem area for users is if the connector gracefully starts, runs for a period of time, and then eventually encounters some fatal error. If the error is related to a resource that wasn&#8217;t accessed during the connector&#8217;s start-up lifecycle, the connector would typically gracefully restart just fine. However, the situation is different if the problem was related to the database&#8217;s availability and the database was still unavailable during the connector&#8217;s start-up phase. In this situation, the connector would fail-fast, and would enter a <code>FAILED</code> state, requiring manual intervention.</p> </div> <div class="paragraph"> <p>The fail-fast approach served Debezium well over the years, but in a world where a resource can come and go without warning, it became clear that changes were needed to improve Debezium&#8217;s reliability and resiliency. While the Kafka Connect&#8217;s retry/back-off framework has helped in this regard, that doesn&#8217;t address the concerns with start-up resources being unavailable with how the code is currently written.</p> </div> <div class="paragraph"> <p>Debezium 2.2 changes this landscape, shifting how we integrate with Kafka Connect&#8217;s source connector API slightly. Instead of accessing potentially unavailable resources during the start-up lifecycle, we moved that access to a later phase in the connector&#8217;s lifecycle. In effect, the Debezium start-up code is executed lazily that accesses potentially unavailable resources, which allows us to take advantage of the Kafka Connect retry/back-off framework even during our start-up code. In short, if the database is still unavailable during the connector&#8217;s start-up, the connector will continue to retry/back-off if Kafka Connect retries are enabled. Only once the maximum number of retry attempts has been reached or a non-retriable error occurs will the connector task enter a <code>FAILED</code> state.</p> </div> <div class="paragraph"> <p>We hope this brings more reliability and resiliency for the Debezium experience, improving how errors are handled in an ever-changing landscape, and provides a solid foundation to manage connector lifecycles.</p> </div> </div> </div> <div class="sect1"> <h2 id="rocketmq_and_infinispan_support_in_debezium_server">RocketMQ and Infinispan support in Debezium Server</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium Server is a Quarkus-based framework that allows executing a Debezium connector from the command line, without Kafka or Kafka Connect, allowing the delivery of Debezium change events to any destination framework. With Debezium 2.2, two new sink connectors have been added to Debezium Server to support sending change events to Apache RocketMQ and to Infinispan.</p> </div> <div class="sect2"> <h3 id="rocketmq">RocketMQ</h3> <div class="paragraph"> <p><a href="https://rocketmq.apache.org">Apache RocketMQ</a> is a cloud-native messaging, eventing, and streaming real-time data processing platform that covers cloud-edge-device collaboration scenarios. In order to integrate Debezium Server with RocketMQ, the Debezium Server <code>application.properties</code> must be modified to include the following entries:</p> </div> <div class="listingblock"> <div class="title">application.properties</div> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">debezium.sink.type=rocketmq
debezium.sink.rocketmq.producer.name.srv.addr=&lt;hostname&gt;:&lt;port&gt;
debezium.sink.rocketmq.producer.group=debezuim-group
debezium.sink.rocketmq.producer.max.message.size=4194304
debezium.sink.rocketmq.producer.send.msg.timeout=3000
debezium.sink.rocketmq.producer.acl.enabled=false
debezium.sink.rocketmq.producer.access.key=&lt;access-key&gt;
debezium.sink.rocketmq.producer.secret.key=&lt;secret-key&gt;</code></pre> </div> </div> <div class="paragraph"> <p>The above configuration specifies that the sink type to be used is <code>rocketmq</code>, which enables the use of the RocketMQ module. The following is a description of each of the properties shown above:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.name.srv.addr</code></dt> <dd> <p>Specifies the host and port where Apache RocketMQ is available.</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.group</code></dt> <dd> <p>Specifies the name associated with the Apache RocketMQ producer group.</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.max.message.size</code></dt> <dd> <p>(Optional) Specifies the maximum number of bytes a message can be. Defaults to <code>4193404</code> (4MB).</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.send.msg.timeout</code></dt> <dd> <p>(Optional) Specifies the timeout in milliseconds when sending messages. Defaults to <code>3000</code> (3 seconds).</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.acl.enabled</code></dt> <dd> <p>(Optional) Controls whether access control lists are enabled. Defaults to <code>false</code>.</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.access.key</code></dt> <dd> <p>(Optional) The access key used for connecting to the Apache RocketMQ cluster.</p> </dd> <dt class="hdlist1"><code>debezium.sink.rocketmq.producer.secret.key</code></dt> <dd> <p>(Optional) The access secret used for connecting to the Apache RocketMQ cluster.</p> </dd> </dl> </div> <div class="paragraph"> <p>For more information on using Debezium Server with RocketMQ, see the <a href="/documentation/reference/2.2/operations/debezium-server.html#_apache_rocketmq">documentation</a>.</p> </div> </div> <div class="sect2"> <h3 id="infinispan">Infinispan</h3> <div class="paragraph"> <p><a href="https://infinispan.org">Infinispan</a> is an in-memory, distributed data store that offers flexible deployment options with robust capabilities to store, manage, and process data. Infinispan is based on the notion of a key-value store that allows storing any data type. In order to integrate Debezium Server with Infinispan, the Debezium Server <code>application.properties</code> must be modified to include the following entries:</p> </div> <div class="listingblock"> <div class="title">application.properties</div> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">debezium.sink.type=infinispan
debezium.sink.infinispan.server.host=&lt;hostname&gt;
debezium.sink.infinispan.server.port=&lt;port&gt;
debezium.sink.infinispan.cache=&lt;cache-name&gt;
debezium.sink.infinispan.user=&lt;user&gt;
debezium.sink.infinispan.password=&lt;password&gt;</code></pre> </div> </div> <div class="paragraph"> <p>The above configuration specifies that the sink type to be used is <code>infinispan</code>, which enables the use of the Infinispan module. The following is a description of each of the properties shown above:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>debezium.sink.infinispan.server.host</code></dt> <dd> <p>Specifies the host name of one of the servers in the Infinispan cluster. This configuration option can also supply a comma-separated list of hostnames as well, such as <code>hostname1,hostname2</code>.</p> </dd> <dt class="hdlist1"><code>debezium.sink.infinispan.server.port</code></dt> <dd> <p>Specifies the port of the Infinispan cluster. Defaults to <code>11222</code>.</p> </dd> <dt class="hdlist1"><code>debezium.sink.infinispan.cache</code></dt> <dd> <p>Specifies the name of the Infinispan cache to write change events.</p> </dd> </dl> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>The Infinispan sink requires that the cache be created manually ahead of time. This enables the ability to create the cache with any variable configuration needed to fit your requirements.</p> </div> </td> </tr> </table> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>debezium.sink.infinispan.user</code></dt> <dd> <p>An optional configuration to specify the user to authenticate with, if authentication is required.</p> </dd> <dt class="hdlist1"><code>debezium.sink.infinispan.password</code></dt> <dd> <p>An optional configuration to specify the password for the authenticating user, if authentication is required.</p> </dd> </dl> </div> <div class="paragraph"> <p>For more information on using Debezium Server with Infinispan, see the <a href="/documentation/reference/2.2/operations/debezium-server.html#_infinispan">documentation</a>.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="other_fixes">Other fixes</h2> <div class="sectionbody"> <div class="paragraph"> <p>There were quite a number of bugfixes and stability changes in this release, some noteworthy are:</p> </div> <div class="ulist"> <ul> <li> <p>Remove option for specifying driver class from MySQL Connector <a href="https://issues.redhat.com/browse/DBZ-4663">DBZ-4663</a></p> </li> <li> <p>Debezium is not working with Apicurio and custom truststores <a href="https://issues.redhat.com/browse/DBZ-5282">DBZ-5282</a></p> </li> <li> <p>Show/Hide password does not work on Connectors View details screen <a href="https://issues.redhat.com/browse/DBZ-5322">DBZ-5322</a></p> </li> <li> <p>Oracle cannot undo change <a href="https://issues.redhat.com/browse/DBZ-5907">DBZ-5907</a></p> </li> <li> <p>Postgresql Data Loss on restarts <a href="https://issues.redhat.com/browse/DBZ-5915">DBZ-5915</a></p> </li> <li> <p>Add support for Connect Headers to Debezium Server <a href="https://issues.redhat.com/browse/DBZ-5926">DBZ-5926</a></p> </li> <li> <p>Oracle Multithreading lost data <a href="https://issues.redhat.com/browse/DBZ-5945">DBZ-5945</a></p> </li> <li> <p>Spanner connector is missing JSR-310 dependency <a href="https://issues.redhat.com/browse/DBZ-5959">DBZ-5959</a></p> </li> <li> <p>Truncate records incompatible with ExtractNewRecordState <a href="https://issues.redhat.com/browse/DBZ-5966">DBZ-5966</a></p> </li> <li> <p>Computed partition must not be negative <a href="https://issues.redhat.com/browse/DBZ-5967">DBZ-5967</a></p> </li> <li> <p>Table size log message for snapshot.select.statement.overrides tables not correct <a href="https://issues.redhat.com/browse/DBZ-5985">DBZ-5985</a></p> </li> <li> <p>NPE in execute snapshot signal with exclude.tables config on giving wrong table name <a href="https://issues.redhat.com/browse/DBZ-5988">DBZ-5988</a></p> </li> <li> <p>There is a problem with postgresql connector parsing the boundary value of money type <a href="https://issues.redhat.com/browse/DBZ-5991">DBZ-5991</a></p> </li> <li> <p>Log statement for unparseable DDL statement in MySqlDatabaseSchema contains placeholder <a href="https://issues.redhat.com/browse/DBZ-5993">DBZ-5993</a></p> </li> <li> <p>Postgresql connector parses the null of the money type into 0 <a href="https://issues.redhat.com/browse/DBZ-6001">DBZ-6001</a></p> </li> <li> <p>Postgres LSN check should honor event.processing.failure.handling.mode <a href="https://issues.redhat.com/browse/DBZ-6012">DBZ-6012</a></p> </li> </ul> </div> <div class="paragraph"> <p>Altogether, <a href="https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.2.0.Alpha1%20ORDER%20BY%20component%20ASC">42 issues</a> were fixed for this release. A big thank you to all the contributors from the community who worked on this release: Akshansh Jain, Gabor, <a href="https://github.com/adasari">Anil Dasari</a>, <a href="https://github.com/akanimesh7">Animesh Kumar</a>, <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/erdinctaskin">Erdinç Taşkın</a>, <a href="https://github.com/govi20">Govinda Sakhare</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/blcksrx">Hossein Torabi</a>, <a href="https://github.com/indraraj">Indra Shukla</a>, <a href="https://github.com/jakzal">Jakub Zalas</a>, <a href="https://github.com/jeremy-l-ford">Jeremy Ford</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/joschi">Jochen Schalanda</a>, <a href="https://github.com/Lucascanna">Luca Scannapieco</a>, <a href="https://github.com/mfvitale">Mario Fiore Vitale</a>, <a href="https://github.com/dude0001">Mark Lambert</a>, <a href="https://github.com/rajdangwal">Rajendra Dangwal</a>, <a href="https://github.com/sunxiaojian">Sun Xiao Jian</a>, <a href="https://github.com/vjuranek">Vojtech Juranek</a>, <a href="https://github.com/yoheimuta">Yohei Yoshimuta</a>, and <a href="https://github.com/yoheimuta">yohei yoshimuta</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="whats_next">What&#8217;s Next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>As the road to Debezium 2.2 is just starting, this initial release covers quite a lot of the features we&#8217;ve outlined our recent 2023 <a href="#/roadmap">road map</a> update. However, there are still a number of features that are still in active development, which include:</p> </div> <div class="ulist"> <ul> <li> <p>Configurable signal channels, enabling users to send signals not only from a database table or a Kafka topic, but also from other means such as an HTTP endpoint, the file system, etc.</p> </li> <li> <p>The Debezium JDBC sink connector that supports native Debezium change events out-of-the-box, without requiring the use of the Event Flattening transformation.</p> </li> <li> <p>A new single message transformation, <code>ExtractChangedRecordState</code>, that supports adding headers to the emitted event that describes that fields were changed or unchanged by the source event.</p> </li> <li> <p>And a plethora of enhancements to Debezium&#8217;s UI</p> </li> </ul> </div> <div class="paragraph"> <p>As we continue development on Debezium 2.2 and bugfixes to Debezium 2.1, we would love to hear your feedback or suggestions, whether it&#8217;s regarding our road map, the changes in this release, or something you&#8217;d like to see that we haven&#8217;t mentioned. Be sure to get in touch with us on the <a href="https://groups.google.com/g/debezium">mailing list</a> or our <a href="https://debezium.zulipchat.com/login/#narrow/stream/302529-users">chat</a> if there is. Or if you just want to stop by and give us a "Hello", we&#8217;d welcome that too.</p> </div> <div class="paragraph"> <p>Until next time&#8230;&#8203;</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html"><![CDATA[It&#8217;s my pleasure to announce not only the first release of the Debezium 2.2 series, but also the first release of Debezium in 2023, 2.2.0.Alpha! The Debezium 2.2.0.Alpha1 release includes some breaking changes, a number of bug fixes, and some noteworthy improvements and features, including but not limited to: [Breaking Change] - ZonedTimestamp values will no longer truncate fractional seconds. [New] - Support ingesting changes from an Oracle logical stand-by database [New] - Support Amazon S3 buckets using the Debezium Storage API [New] - Support retrying database connections during connector start-up [New] - Debezium Server sink connector support for Apache RocketMQ and Infinispan]]></summary></entry><entry><title type="html">Change Data Capture with QuestDB and Debezium</title><link href="https://debezium.io/blog/2023/01/06/change-data-capture-with-questdb-and-debezium/" rel="alternate" type="text/html" title="Change Data Capture with QuestDB and Debezium"/><published>2023-01-06T00:00:00+00:00</published><updated>2023-01-06T00:00:00+00:00</updated><id>https://debezium.io/blog/2023/01/06/change-data-capture-with-questdb-and-debezium</id><content type="html" xml:base="https://debezium.io/blog/2023/01/06/change-data-capture-with-questdb-and-debezium/"><![CDATA[<div class="paragraph"> <p>This tutorial was originally published by <a href="https://questdb.io/">QuestDB</a>, where guest contributor, <a href="https://yitaek.medium.com/">Yitaek Hwang</a>, shows us how to stream data into QuestDB with change data capture via Debezium and Kafka Connect.</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>Modern data architecture has largely shifted away from the <strong>ETL</strong> (Extract-Transform-Load) paradigm to <strong>ELT</strong> (Extract-Load-Transform) where raw data is first loaded into a data lake before transformations are applied (e.g., aggregations, joins) for further analysis. Traditional ETL pipelines were hard to maintain and relatively inflexible with changing business needs. As new cloud technologies promised cheaper storage and better scalability, data pipelines could move away from pre-built extractions and batch uploads to a more streaming architecture.</p> </div> <div class="paragraph"> <p><a href="https://en.wikipedia.org/wiki/Change_data_capture">Change data capture</a>(CDC) fits nicely into this paradigm shift where changes to data from one source can be streamed to other destinations. As the name implies, CDC tracks changes in data (usually a database) and provides plugins to act on those changes. For event-driven architectures, CDC is especially useful as a consistent data delivery mechanism between service boundaries (e.g., <a href="https://microservices.io/patterns/data/transactional-outbox.html">Outbox Pattern</a>). In a complex microservice environment, CDC helps to simplify data delivery logic by offloading the burden to the CDC systems.</p> </div> <div class="paragraph"> <p>To illustrate, let&#8217;s take a reference architecture to stream stock updates from PostgreSQL into QuestDB. A simple Java Spring App polls stock prices by ticker symbol and updates the current price to a PostgreSQL database. Then the updates are detected by Debezium and fed to a Kafka topic. Finally, the Kafka Connect QuestDB connector listens to that topic and streams changes into QuestDB for analysis.</p> </div> <div class="exampleblock centered-image responsive-image"> <div class="content"> <img src="/assets/images/2023-01-06-change-data-capture-with-questdb-and-debezium/overview.png" style="max-width:90%;" class="responsive-image"> <div class="paragraph"> <p>Design overview</p> </div> </div> </div> <div class="paragraph"> <p>Structuring the data pipeline this way allows the application to be simple. The Java Spring App only needs to fetch the latest stock data and commit to PostgreSQL. Since PostgreSQL is an excellent OLTP (transactional) database, the app can rely on the ACID compliance to ensure that only the committed data will be seen by downstream services. The app developer does not need to worry about complicated retry logic or out-of-sync datasets. From the database standpoint, PostgreSQL can be optimized to do what it does best — transactional queries. Kafka can be leveraged to reliably feed data to other endpoints, and QuestDB can be used to store historical data to run analytical queries and visualization.</p> </div> <div class="paragraph"> <p>So without further ado, let&#8217;s get to the example:</p> </div> <div class="sect1"> <h2 id="prerequisites">Prerequisites</h2> <div class="sectionbody"> <div class="ulist"> <ul> <li> <p>Git</p> </li> <li> <p>Docker Engine: 20.10+</p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="setup">Setup</h2> <div class="sectionbody"> <div class="paragraph"> <p>To run the example locally, first clone the <a href="https://github.com/questdb/kafka-questdb-connector.git">QuestDG Kafka connector repo</a>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="shell">$ git clone https://github.com/questdb/kafka-questdb-connector.git</code></pre> </div> </div> <div class="paragraph"> <p>Then, navigate to the stocks sample to build and run the Docker compose files:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="shell">$ cd kafka-questdb-connector/kafka-questdb-connector-samples/stocks/
$ docker compose build
$ docker compose up</code></pre> </div> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>In Linux or older versions of Docker, the <code>compose</code> subcommand might not be available. You can try to execute <code>docker-compose</code> instead of <code>docker compose</code>. If <code>docker-compose</code> is unavailable in your distribution, you can <a href="https://docs.docker.com/compose/install/other/">install it</a> manually.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>This will build the Dockerfile for the Java Spring App/Kafka Connector for QuestDB and pull down PostgreSQL (preconfigured with Debezium), Kafka/Zookeeper, QuestDB, and Grafana containers. Kafka and Kafka Connect take a bit to initialize. Wait for the logs to stop by inspecting the connect container.</p> </div> <div class="sect2"> <h3 id="start_the_debezium_connector">Start the Debezium connector</h3> <div class="paragraph"> <p>At this point, the Java App is continuously updating the stock table in PostgreSQL, but the connections have not been setup. Create the Debezium connector (i.e., PostgreSQL → Debezium → Kafka) by executing the following:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="shell">curl -X POST -H &quot;Content-Type: application/json&quot; -d  '{&quot;name&quot;:&quot;debezium_source&quot;,&quot;config&quot;:{&quot;tasks.max&quot;:1,&quot;database.hostname&quot;:&quot;postgres&quot;,&quot;database.port&quot;:5432,&quot;database.user&quot;:&quot;postgres&quot;,&quot;database.password&quot;:&quot;postgres&quot;,&quot;connector.class&quot;:&quot;io.debezium.connector.postgresql.PostgresConnector&quot;,&quot;database.dbname&quot;:&quot;postgres&quot;,&quot;database.server.name&quot;:&quot;dbserver1&quot;}} ' localhost:8083/connectors</code></pre> </div> </div> </div> <div class="sect2"> <h3 id="start-the-questdb-kafka-connect-sink">Start the QuestDB Kafka Connect sink</h3> <div class="paragraph"> <p>Finish the plumbing by creating the Kafka Connect side (i.e., Kafka → QuestDB sink):</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="shell">curl -X POST -H &quot;Content-Type: application/json&quot; -d '{&quot;name&quot;:&quot;questdb-connect&quot;,&quot;config&quot;:{&quot;topics&quot;:&quot;dbserver1.public.stock&quot;,&quot;table&quot;:&quot;stock&quot;, &quot;connector.class&quot;:&quot;io.questdb.kafka.QuestDBSinkConnector&quot;,&quot;tasks.max&quot;:&quot;1&quot;,&quot;key.converter&quot;:&quot;org.apache.kafka.connect.storage.StringConverter&quot;,&quot;value.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,&quot;host&quot;:&quot;questdb&quot;, &quot;transforms&quot;:&quot;unwrap&quot;, &quot;transforms.unwrap.type&quot;:&quot;io.debezium.transforms.ExtractNewRecordState&quot;, &quot;include.key&quot;: &quot;false&quot;, &quot;symbols&quot;: &quot;symbol&quot;, &quot;timestamp.field.name&quot;: &quot;last_update&quot;}}' localhost:8083/connectors</code></pre> </div> </div> </div> </div> </div> <div class="sect1"> <h2 id="final_result">Final result</h2> <div class="sectionbody"> <div class="paragraph"> <p>Now all the updates written to the PostgreSQL table will also be reflected in QuestDB. To validate, navigate to <a href="http://localhost:19000">http://localhost:19000</a> and select from the stock table:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="sql"><span class="class">SELECT</span> * <span class="keyword">FROM</span> stock;</code></pre> </div> </div> <div class="paragraph"> <p>You can also run aggregations for a more complex analysis:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="sql"> <span class="class">SELECT</span>
   <span class="predefined-type">timestamp</span>,
   symbol,
   <span class="predefined">avg</span>(price),
   <span class="predefined">min</span>(price),
   <span class="predefined">max</span>(price)
 <span class="keyword">FROM</span> stock
   <span class="keyword">WHERE</span> symbol = <span class="string"><span class="delimiter">'</span><span class="content">IBM</span><span class="delimiter">'</span></span>
 SAMPLE <span class="keyword">BY</span> <span class="integer">1</span>m ALIGN <span class="keyword">TO</span> CALENDAR;</code></pre> </div> </div> <div class="paragraph"> <p>Finally, you can interact with a Grafana dashboard for visualization at <a href="http://localhost:3000/d/stocks/stocks?orgId=1&amp;refresh=5s&amp;viewPanel=2">http://localhost:3000/d/stocks/stocks?orgId=1&amp;refresh=5s&amp;viewPanel=2</a>.</p> </div> <div class="paragraph"> <p>The visualization is a candle chart composed of changes captured by Debezium; each candle shows the opening, closing, high, and low price, in a given time interval. The time interval can be changed by selecting the top-left 'Interval' option:</p> </div> <div class="exampleblock centered-image responsive-image"> <div class="content"> <img src="/assets/images/2023-01-06-change-data-capture-with-questdb-and-debezium/screenshot.png" style="max-width:90%;" class="responsive-image"> <div class="paragraph"> <p>Grafana candle chart</p> </div> </div> </div> </div> </div> <div class="sect1"> <h2 id="deep_dive">Deep dive</h2> <div class="sectionbody"> <div class="paragraph"> <p>Now that we have the sample application up and running, let&#8217;s take a deeper dive into each component in the <a href="https://github.com/questdb/kafka-questdb-connector/tree/main/kafka-questdb-connector-samples/stocks">stocks</a> example.</p> </div> <div class="paragraph"> <p>We will look at the following files:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>├── kafka-questdb-connector/kafka-questdb-connector-samples/stocks/
│   ├── Dockerfile-App
|   |    -- The Dockerfile to package our Java App
|   ├── Dockerfile-Connect
|   |    -- The Dockerfile to combine the Debezium container
|   |    -- image the with QuestDB Kafka connector
│   ├── src/main/resources/schema.sql
|   |    -- The SQL which creates the stock table in PostgreSQL
|   |    -- and populates it with initial data
│   ├── src/main/java/com/questdb/kafka/connector/samples/StocksApplication.java
|   |    -- The Java Spring App which updates the stock table in PostgreSQL
|   |    -- in regular intervals
...</code></pre> </div> </div> <div class="sect2"> <h3 id="producer_java_app">Producer (Java App)</h3> <div class="paragraph"> <p>The producer is a simple Java Spring Boot App. It has two components:</p> </div> <div class="olist arabic"> <ol class="arabic"> <li> <p>The <a href="https://github.com/questdb/kafka-questdb-connector/blob/main/kafka-questdb-connector-samples/stocks/src/main/resources/schema.sql">schema.sql</a> file. This file is used to create the stock table in PostgreSQL and populate it with initial data. It&#8217;s picked up by the Spring Boot App and executed on startup.</p> <div class="literalblock"> <div class="content"> <pre>[source,sql]
----
CREATE TABLE IF NOT EXISTS stock (
    id serial primary key,
    symbol varchar(10) unique,
    price float8,
    last_update timestamp
);
INSERT INTO stock (symbol, price, last_update) VALUES ('AAPL', 500.0, now()) ON CONFLICT DO NOTHING;
INSERT INTO stock (symbol, price, last_update) VALUES ('IBM', 50.0, now()) ON CONFLICT DO NOTHING;
INSERT INTO stock (symbol, price, last_update) VALUES ('MSFT', 100.0, now()) ON CONFLICT DO NOTHING;
INSERT INTO stock (symbol, price, last_update) VALUES ('GOOG', 1000.0, now()) ON CONFLICT DO NOTHING;
INSERT INTO stock (symbol, price, last_update) VALUES ('FB', 200.0, now()) ON CONFLICT DO NOTHING;
INSERT INTO stock (symbol, price, last_update) VALUES ('AMZN', 1000.0, now()) ON CONFLICT DO NOTHING;
INSERT INTO stock (symbol, price, last_update) VALUES ('TSLA', 500.0, now()) ON CONFLICT DO NOTHING;
INSERT INTO stock (symbol, price, last_update) VALUES ('NFLX', 500.0, now()) ON CONFLICT DO NOTHING;
INSERT INTO stock (symbol, price, last_update) VALUES ('TWTR', 50.0, now()) ON CONFLICT DO NOTHING;
INSERT INTO stock (symbol, price, last_update) VALUES ('SNAP', 10.0, now()) ON CONFLICT DO NOTHING;
----</pre> </div> </div> <div class="literalblock"> <div class="content"> <pre>The `ON CONFLICT DO NOTHING` clause is used to avoid duplicate entries in the
table when the App is restarted.</pre> </div> </div> </li> <li> <p><a href="https://github.com/questdb/kafka-questdb-connector/blob/main/kafka-questdb-connector-samples/stocks/src/main/java/io/questdb/kafka/samples/StockService.java">Java code</a> to update prices and timestamps with a random value. The updates are not perfectly random, the application uses a very simple algorithm to generate updates which very roughly resembles stock price movements. In a real-life scenario, the application would fetch the price from some external source.</p> </li> </ol> </div> <div class="paragraph"> <p>The producer is packaged into a minimal Dockerfile, <a href="https://github.com/questdb/kafka-questdb-connector/blob/main/kafka-questdb-connector-samples/stocks/Dockerfile-App">Dockerfile-App</a>, and linked to PostgreSQL:</p> </div> <div class="listingblock"> <div class="content"> <pre>FROM maven:3.8-jdk-11-slim AS builder
COPY ./pom.xml /opt/stocks/pom.xml
COPY ./src ./opt/stocks/src
WORKDIR /opt/stocks
RUN mvn clean install -DskipTest
FROM azul/zulu-openjdk:11-latest
COPY --from=builder /opt/stocks/target/kafka-samples-stocks-*.jar /stocks.jar
CMD ["java", "-jar", "/stocks.jar"]</pre> </div> </div> </div> <div class="sect2"> <h3 id="kafka_connect_debezium_and_questdb_kafka_connector">Kafka Connect, Debezium, and QuestDB Kafka Connector</h3> <div class="paragraph"> <p>Before we dive into the Kafka Connect, Debezium, and the QuestDB Kafka connector configurations, let&#8217;s take a look at their relation with each other.</p> </div> <div class="paragraph"> <p>Kafka Connect is a framework for building connectors to move data between Kafka and other systems. It supports 2 classes of connectors:</p> </div> <div class="olist arabic"> <ol class="arabic"> <li> <p>Source connectors - read data from a source system and write it to Kafka</p> </li> <li> <p>Sink connectors - read data from Kafka and write it to a sink system</p> </li> </ol> </div> <div class="paragraph"> <p>Debezium is a Source connector for Kafka Connect that can monitor and capture the row-level changes in the databases. What does it mean? Whenever a row is inserted, updated, or deleted in a database, Debezium will capture the change and write it as an event to Kafka.</p> </div> <div class="paragraph"> <p>On a technical level, Debezium is a Kafka Connect connector running inside the Kafka Connect framework. This is reflected in the <a href="https://hub.docker.com/r/debezium/connect">Debezium container image</a>, which packages the Kafka Connect with Debezium connectors pre-installed.</p> </div> <div class="paragraph"> <p>QuestDB Kafka connector is also a Kafka Connect connector. It&#8217;s a Sink connector that reads data from Kafka and writes it to QuestDB. We add the QuestDB Kafka connector to the Debezium container image, and we get a Kafka Connect image that has both Debezium and QuestDB Kafka connector installed!</p> </div> <div class="paragraph"> <p>This is the Dockerfile we use to build the image:</p> </div> <div class="paragraph"> <p>(<a href="https://github.com/questdb/kafka-questdb-connector/blob/main/kafka-questdb-connector-samples/stocks/Dockerfile-Connect">Dockerfile-Connect</a>)</p> </div> <div class="listingblock"> <div class="content"> <pre>FROM ubuntu:latest AS builder
WORKDIR /opt
RUN apt-get update &amp;&amp; apt-get install -y curl wget unzip jq
RUN curl -s https://api.github.com/repos/questdb/kafka-questdb-connector/releases/latest | jq -r '.assets[]|select(.content_type == "application/zip")|.browser_download_url'|wget -qi -
RUN unzip kafka-questdb-connector-*-bin.zip

FROM debezium/connect:1.9.6.Final
COPY --from=builder /opt/kafka-questdb-connector/*.jar /kafka/connect/questdb-connector/</pre> </div> </div> <div class="paragraph"> <p>The Dockerfile downloads the latest release of the QuestDB Kafka connector, unzip it copies it to the Debezium container image. The resulting image has both Debezium and QuestDB Kafka connector installed:</p> </div> <div class="exampleblock centered-image responsive-image"> <div class="content"> <img src="/assets/images/2023-01-06-change-data-capture-with-questdb-and-debezium/dockerfile-connect.png" style="max-width:90%;" class="responsive-image"> <div class="paragraph"> <p>Dockerfile-Coonnect adding the QuestDB Kafka Connector layer</p> </div> </div> </div> <div class="paragraph"> <p>The overall Kafka connector is completed with a Source connector and a Sink connector:</p> </div> <div class="exampleblock centered-image responsive-image"> <div class="content"> <img src="/assets/images/2023-01-06-change-data-capture-with-questdb-and-debezium/kafka-cluster.png" style="max-width:90%;" class="responsive-image"> <div class="paragraph"> <p>How the Source and Sink connector work with the Kafka cluster and the databases</p> </div> </div> </div> <div class="sect3"> <h4 id="debezium_connector">Debezium Connector</h4> <div class="paragraph"> <p>We already know that Debezium is a Kafka Connect connector that can monitor and capture the row-level changes in the databases. We also have a Docker image that has both Debezium and QuestDB Kafka connectors installed. However, at this point neither of the connectors is running. We need to configure and start them. This is done via CURL command that sends a POST request to the Kafka Connect REST API.</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="shell">curl -X POST -H &quot;Content-Type: application/json&quot; -d  '{&quot;name&quot;:&quot;debezium_source&quot;,&quot;config&quot;:{&quot;tasks.max&quot;:1,&quot;database.hostname&quot;:&quot;postgres&quot;,&quot;database.port&quot;:5432,&quot;database.user&quot;:&quot;postgres&quot;,&quot;database.password&quot;:&quot;postgres&quot;,&quot;connector.class&quot;:&quot;io.debezium.connector.postgresql.PostgresConnector&quot;,&quot;database.dbname&quot;:&quot;postgres&quot;,&quot;database.server.name&quot;:&quot;dbserver1&quot;}} ' localhost:8083/connectors</code></pre> </div> </div> <div class="paragraph"> <p>The request body contains the configuration for the Debezium connector, let&#8217;s break it down:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">debezium_source</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">config</span><span class="delimiter">&quot;</span></span>: {
    <span class="key"><span class="delimiter">&quot;</span><span class="content">tasks.max</span><span class="delimiter">&quot;</span></span>: <span class="integer">1</span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">database.hostname</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">postgres</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">database.port</span><span class="delimiter">&quot;</span></span>: <span class="integer">5432</span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">database.user</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">postgres</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">database.password</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">postgres</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">connector.class</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">io.debezium.connector.postgresql.PostgresConnector</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">database.dbname</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">postgres</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">database.server.name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">dbserver1</span><span class="delimiter">&quot;</span></span>
  }
}</code></pre> </div> </div> <div class="paragraph"> <p>It listens to changes in the PostgreSQL database and publishes to Kafka with the above configuration. The topic name defaults to <code>&lt;server-name&gt;.&lt;schema&gt;.&lt;table&gt;.</code> In our example, it is <code>dbserver1.public.stock</code>. Why? Because the database server name is <code>dbserver1</code>, the schema is <code>public</code> and the only table we have is <code>stock</code>.</p> </div> <div class="paragraph"> <p>So after we send the request, Debezium will start listening to changes in the <code>stock</code> table and publish them to the <code>dbserver1.public.stock</code> topic.</p> </div> </div> <div class="sect3"> <h4 id="questdb_kafka_connector">QuestDB Kafka Connector</h4> <div class="paragraph"> <p>At this point, we have a PostgreSQL table <code>stock</code> being populated with random stock prices and a Kafka topic <code>dbserver1.public.stock</code> that contains the changes. The next step is to configure the QuestDB Kafka connector to read from the <code>dbserver1.public.stock</code> topic and write the data to QuestDB.</p> </div> <div class="paragraph"> <p>Let&#8217;s take a deeper look at the configuration in the <a href="#start-the-questdb-kafka-connect-sink">start the QuestDB Kafka Connect sink</a>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="jason">{
  &quot;name&quot;: &quot;questdb-connect&quot;,
  &quot;config&quot;: {
    &quot;topics&quot;: &quot;dbserver1.public.stock&quot;,
    &quot;table&quot;: &quot;stock&quot;,
    &quot;connector.class&quot;: &quot;io.questdb.kafka.QuestDBSinkConnector&quot;,
    &quot;tasks.max&quot;: &quot;1&quot;,
    &quot;key.converter&quot;: &quot;org.apache.kafka.connect.storage.StringConverter&quot;,
    &quot;value.converter&quot;: &quot;org.apache.kafka.connect.json.JsonConverter&quot;,
    &quot;host&quot;: &quot;questdb&quot;,
    &quot;transforms&quot;: &quot;unwrap&quot;,
    &quot;transforms.unwrap.type&quot;: &quot;io.debezium.transforms.ExtractNewRecordState&quot;,
    &quot;include.key&quot;: &quot;false&quot;,
    &quot;symbols&quot;: &quot;symbol&quot;,
    &quot;timestamp.field.name&quot;: &quot;last_update&quot;
  }
}</code></pre> </div> </div> <div class="paragraph"> <p>The important things to note here are:</p> </div> <div class="ulist"> <ul> <li> <p><code>table</code> and <code>topics</code>: The QuestDB Kafka connector will create a QuestDB table with the name <code>stock</code> and write the data from the <code>dbserver1.public.stock</code> topic to it.</p> </li> <li> <p><code>host</code>: The QuestDB Kafka connector will connect to QuestDB running on the <code>questdb</code> host. This is the name of the QuestDB container.</p> </li> <li> <p><code>connector.class</code>: The QuestDB Kafka connector class name. This tells Kafka Connect to use the QuestDB Kafka connector.</p> </li> <li> <p><code>value.converter</code>: The Debezium connector produces the data in JSON format. This is why we need to configure the QuestDB connector to use the JSON converter to read the data: <code>org.apache.kafka.connect.json.JsonConverter</code>.</p> </li> <li> <p><code>symbols</code>: Stock symbols are translated to <a href="https://questdb.io/docs/concept/symbol/">QuestDB symbol type</a>, used for string values with low cardinality (e.g., enums).</p> </li> <li> <p><code>timestamp.field.name</code>: Since QuestDB has great support for timestamp and partitioning based on that, we can specify the designated timestamp column.</p> </li> <li> <p><code>transforms</code>: unwrap field uses <code>io.debezium.transforms.ExtractNewRecordState</code> type to extract just the new data and not the metadata that Debezium emits. In other words, this is a filter to basically take the <code>payload.after</code> portion of the Debezium data on the Kafka topics. See its <a href="https://debezium.io/documentation/reference/1.9/transformations/event-flattening.html">documentation</a> for more details.</p> </li> </ul> </div> <div class="paragraph"> <p>The <code>ExtractNewRecordState</code> transform is probably the least intuitive part of the configuration. Let&#8217;s have a closer look at it: In short, for every change in the PostgreSQL table, the Debezium emits a JSON message to a Kafka topic such as the following:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">schema</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">This JSON key contains Debezium message schema. It's not very relevant for this sample. Omitted for brevity.</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">payload</span><span class="delimiter">&quot;</span></span>: {
    <span class="key"><span class="delimiter">&quot;</span><span class="content">before</span><span class="delimiter">&quot;</span></span>: <span class="value">null</span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">after</span><span class="delimiter">&quot;</span></span>: {
      <span class="key"><span class="delimiter">&quot;</span><span class="content">id</span><span class="delimiter">&quot;</span></span>: <span class="integer">8</span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">symbol</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">NFLX</span><span class="delimiter">&quot;</span></span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">price</span><span class="delimiter">&quot;</span></span>: <span class="float">1544.3357414199545</span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">last_update</span><span class="delimiter">&quot;</span></span>: <span class="integer">1666172978269856</span>
    }
  },
  <span class="key"><span class="delimiter">&quot;</span><span class="content">source</span><span class="delimiter">&quot;</span></span>: {
    <span class="key"><span class="delimiter">&quot;</span><span class="content">version</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">1.9.6.Final</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">connector</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">postgresql</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">dbserver1</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">ts_ms</span><span class="delimiter">&quot;</span></span>: <span class="integer">1666172978272</span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">snapshot</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">false</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">db</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">postgres</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">sequence</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">[</span><span class="char">\&quot;</span><span class="content">87397208</span><span class="char">\&quot;</span><span class="content">,</span><span class="char">\&quot;</span><span class="content">87397208</span><span class="char">\&quot;</span><span class="content">]</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">schema</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">public</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">table</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">stock</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">txId</span><span class="delimiter">&quot;</span></span>: <span class="integer">402087</span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">lsn</span><span class="delimiter">&quot;</span></span>: <span class="integer">87397208</span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">xmin</span><span class="delimiter">&quot;</span></span>: <span class="value">null</span>
  },
  <span class="key"><span class="delimiter">&quot;</span><span class="content">op</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">u</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">ts_ms</span><span class="delimiter">&quot;</span></span>: <span class="integer">1666172978637</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">transaction</span><span class="delimiter">&quot;</span></span>: <span class="value">null</span>
}</code></pre> </div> </div> <div class="paragraph"> <p>Don&#8217;t get scared if you feel overwhelmed by the sheer size of this message. Most of the fields are metadata, and they are not relevant to this sample. See <a href="https://debezium.io/documentation/reference/1.9/connectors/postgresql.html#postgresql-events">Debezium documentation</a>, for more details. The important point is that we cannot push the whole JSON message to QuestDB and we do not want all the metadata in QuestDB. We need to extract the <code>payload.after</code> portion of the message and only then push it to QuestDB. This is exactly what the <code>ExtractNewRecordState</code> transform does: It transforms the big message into a smaller one that contains only the <code>payload.after</code> portion of the message. Hence, it is as if the message looked like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">id</span><span class="delimiter">&quot;</span></span>: <span class="integer">8</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">symbol</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">NFLX</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">price</span><span class="delimiter">&quot;</span></span>: <span class="float">1544.3357414199545</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">last_update</span><span class="delimiter">&quot;</span></span>: <span class="integer">1666172978269856</span>
}</code></pre> </div> </div> <div class="paragraph"> <p>This is the message that we can push to QuestDB. The QuestDB Kafka connector will read this message and write it to the QuestDB table. The QuestDB Kafka connector will also create the QuestDB table if it does not exist. The QuestDB table will have the same schema as the JSON message - where each JSON field will be a column in the QuestDB table.</p> </div> </div> </div> <div class="sect2"> <h3 id="questdb_and_grafana">QuestDB and Grafana</h3> <div class="paragraph"> <p>Once the data is written to QuestDB tables, we can work with the time-series data easier. Since QuestDB is compatible with the PostgreSQL wire protocol, we can use the PostgreSQL data source on Grafana to visualize the data. The preconfigured dashboard is using the following query:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="sql"><span class="class">SELECT</span>
  <span class="error">$</span>__time(<span class="predefined-type">timestamp</span>),
  <span class="predefined">min</span>(price) <span class="keyword">as</span> low,
  <span class="predefined">max</span>(price) <span class="keyword">as</span> high,
  first(price) <span class="keyword">as</span> open,
  last(price) <span class="keyword">as</span> close
<span class="keyword">FROM</span>
  stock
<span class="keyword">WHERE</span>
  <span class="error">$</span>__timeFilter(<span class="predefined-type">timestamp</span>)
  <span class="keyword">and</span> symbol = <span class="string"><span class="delimiter">'</span><span class="content">$Symbol</span><span class="delimiter">'</span></span>
SAMPLE <span class="keyword">BY</span> <span class="error">$</span>Interval ALIGN <span class="keyword">TO</span> CALENDAR;</code></pre> </div> </div> <div class="paragraph"> <p>We have created a system that continuously tracks and stores the latest prices for multiple stocks in a PostgreSQL table. These prices are then fed as events to Kafka through Debezium, which captures every price change. The QuestDB Kafka connector reads these events from Kafka and stores each change as a new row in QuestDB, allowing us to retain a comprehensive history of stock prices. This history can then be analyzed and visualized using tools such as Grafana, as demonstrated by the candle chart.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="next_steps">Next steps</h2> <div class="sectionbody"> <div class="paragraph"> <p>This sample project is a foundational reference architecture to stream data from a relational database into an optimized time series database. For existing projects that are using PostgreSQL, Debezium can be configured to start streaming data to QuestDB and take advantage of time series queries and partitioning. For databases that are also storing raw historical data, adopting Debezium may need some architectural changes. However, this is beneficial as it is an opportunity to improve performance and establish service boundaries between a transactional database and an analytical, time-series database.</p> </div> <div class="paragraph"> <p>This reference architecture can also be extended to configure Kafka Connect to also stream to other data warehouses for long-term storage. After inspecting the data, QuestDB can also be configured to downsample the data for longer term storage or even <a href="https://questdb.io/blog/2022/11/02/data-lifecycle-questdb/">detach partitions to save space</a>.</p> </div> <div class="paragraph"> <p>Give this <a href="https://github.com/questdb/kafka-questdb-connector/issues/new">sample application</a> a try and join the <a href="https://slack.questdb.io/">QuestDB Slack community</a> if you have any questions.</p> </div> </div> </div>]]></content><author><name>Yitaek Hwang</name></author><category term="questdb"/><category term="kafka"/><category term="debezium"/><category term="time series"/><summary type="html"><![CDATA[This tutorial was originally published by QuestDB, where guest contributor, Yitaek Hwang, shows us how to stream data into QuestDB with change data capture via Debezium and Kafka Connect.]]></summary></entry><entry><title type="html">Debezium 2.1.0.Final/Debezium 2.1.1.Final Released</title><link href="https://debezium.io/blog/2022/12/22/debezium-2-1-final-released/" rel="alternate" type="text/html" title="Debezium 2.1.0.Final/Debezium 2.1.1.Final Released"/><published>2022-12-22T00:00:00+00:00</published><updated>2022-12-22T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/12/22/debezium-2-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/12/22/debezium-2-1-final-released/"><![CDATA[<div class="paragraph"> <p>Today it&#8217;s my great pleasure to announce the availability of Debezium <strong>2.1.0.Final</strong>!</p> </div> <div class="paragraph"> <p>You might recently noticed that Debezium went a bit silent for the last few weeks. No, we are not going away. In fact the elves in Google worked furiously to bring you a present under a Christmas tree - Debezium Spanner connector.</p> </div> <div class="paragraph"> <p></p> </div> <div class="admonitionblock warning"> <table> <tr> <td class="icon"> <i class="fa icon-warning" title="Warning"></i> </td> <td class="content"> <div class="paragraph"> <p>Release 2.1.0.Final did not contain a mandatory dependency. This is fixed in 2.1.1.Final hot update.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>After a plenty of intensive effort we woud like to present <a href="https://github.com/nancyxu123">Nancy Xu</a> as the leading engineer behind the implementation of the <a href="https://github.com/debezium/debezium-connector-spanner">Debezium Spanner connector</a> for Google&#8217;s <a href="https://cloud.google.com/spanner">Cloud Spanner</a> distributed database. The connector itself is now in incubating state and still not fully feature complete (for example initial snapshots are not supported yet). Yet it is ready for a general use in scenarios where a robust Spanner-to-Kafka streaming implementation is required.</p> </div> <div class="paragraph"> <p>The initial release provides</p> </div> <div class="ulist"> <ul> <li> <p><a href="https://repo1.maven.org/maven2/io/debezium/debezium-connector-spanner/2.1.1.Final/">Installation packages</a></p> </li> <li> <p><a href="https://hub.docker.com/r/debezium/connect">Container image</a></p> </li> <li> <p><a href="/documentation/reference/2.1/connectors/spanner.html">Documentation</a></p> </li> </ul> </div> <div class="paragraph"> <p>As exciting these news are, this is not the only new feature available for Debezium. The release brings a nice pack of additional improvements.</p> </div> <div class="ulist"> <ul> <li> <p>Vitess connector supports initial snapshotting. This is a completely new feature and means that now the default behaviour for a new Vitess connector instance is to snapshot the current table content and then switch to streaming.</p> </li> <li> <p>Starting Debezium 2.0 we extracted a set of interfaces to provide additional pluggable persistent stores. Redis offset and internal schema history store was converted into module and is now available for generic use.</p> </li> <li> <p>MySQL connector processes <code>TRUNCATE TABLE</code> commands. When detected a <code>t</code> message is emitted into the table topic. This feature is optional and is diabled by default.</p> </li> <li> <p>Kafka Connect provides so-called <code>predicates</code> that enable user to apply transfromations conditionally. Debezium Engine and Debezium Server supports the same functionality too and is configured in the same way as kafka Connect.</p> </li> <li> <p>PostgreSQL connector is compatible with PostgreSQL 15.</p> </li> <li> <p>Cassandra connector is from the very start a bit odd duckling in the way how the codebase is written and connector deployed. This meant that only Kafka was suported as a destination. The connector was rewritten so it now can run inside Debezium Server and so any supported sink can be used as the destination.</p> </li> <li> <p>Nats JetStream is the new sink provided by Debezium Server.</p> </li> <li> <p>Kafka Connect by default calculates the topic partition number based on the message primary key. With the new <code>ComputePartition</code> it is possible to define a list of per-table columns to explicitly calculate and set the partition number.</p> </li> <li> <p>PostgreSQL flushes LSN (and thus truncates the WAL) when the message is recorded in Kafka. For scenarios that prefer manual WAL management it is possible to disable this behaviour.</p> </li> <li> <p>MongoDB connector always connected and streamed from primary node in the cluster. This is no longer necessary and non-primary nodes are preferred.</p> </li> </ul> </div> <div class="sect1"> <h2 id="other_fixes_improvements">Other fixes &amp; improvements</h2> <div class="sectionbody"> <div class="paragraph"> <p>There were many bugfixes, stability changes, and improvements throughout the development of Debezium 2.1. Altogether, a total of <a href="https://issues.redhat.com/browse/DBZ-5824?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(2.1.0.Alpha1%2C%202.1.0.Alpha2%2C%202.1.0.Beta1%2C%202.1.0.Final)%20ORDER%20BY%20component%20ASC">149 issues</a> were fixed for this release.</p> </div> <div class="paragraph"> <p>A big thank you to all the contributors from the community who worked on this major release: Masazumi Kobayashi, <a href="https://github.com/jchipmunk">Andrey Pustovetov</a>, <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/Skezzowski">Balázs Sipos</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/btiernay">Bobby Tiernay</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/egyedt">Egyed Tamas</a>, <a href="https://github.com/enzo-cappa">Enzo Cappa</a>, <a href="https://github.com/erdinctaskin">Erdinç Taşkın</a>, <a href="https://github.com/ggaborg">Gabor Andras</a>, <a href="https://github.com/gunnarmorling">Gunnar Morling</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/jcechace">Jakub Cechacek</a>, <a href="https://github.com/jeremy-l-ford">Jeremy Ford</a>, <a href="https://github.com/novotnyJiri">Jiri Novotny</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/keriharris">Keri Harris</a>, <a href="https://github.com/marceloavan">Marcelo Avancini</a>, <a href="https://github.com/mfvitale">Mario Fiore Vitale</a>, <a href="https://github.com/dude0001">Mark Lambert</a>, <a href="https://github.com/MartinMedek">Martin Medek</a>, <a href="https://github.com/mikekamornikov">Mike Kamornikov</a>, <a href="https://github.com/nancyxu123">Nancy Xu</a>, <a href="https://github.com/nirolevy">Nir Levy</a>, <a href="https://github.com/obabec">Ondrej Babec</a>, <a href="https://github.com/poonam-meghnani">Poonam Meghnani</a>, <a href="https://github.com/prburgu">Praveen Burgu</a>, <a href="https://github.com/uurl">Raúl Estrada</a>, <a href="https://github.com/roldanbob">Robert Roldan</a>, <a href="https://github.com/sahapasci">Sahap Asci</a>, <a href="https://github.com/smiklosovic">Stefan Miklosovic</a>, <a href="https://github.com/subodh1810">Subodh Kant Chaturvedi</a>, <a href="https://github.com/vjuranek">Vojtech Juranek</a>, <a href="https://github.com/wuzhenhua01">Wu Zhenhua</a>, Xuan Shen, <a href="https://github.com/yoheimuta">Yohei Yoshimuta</a>, <a href="https://github.com/tooptoop4">tooptoop4</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="whats_next">What&#8217;s next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>So what are our current plans for the first quarter of the next year? Some potential features you can expect include:</p> </div> <div class="ulist"> <ul> <li> <p>Initial work on JDBC sink connector</p> </li> <li> <p>Configurable signalling channels</p> </li> <li> <p>JDBC and S3 history and offset storage support</p> </li> </ul> </div> <div class="paragraph"> <p>As always, this roadmap is heavily influenced by the community, i.e. you. So if you would like to see any particular items here, please let us know.</p> </div> <div class="paragraph"> <p>Merry Christmas and Happy New Year 2023!</p> </div> <div class="paragraph"> <p>Onwards and Upwards!</p> </div> </div> </div>]]></content><author><name>Jiri Pechanec</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="mongodb"/><category term="spanner"/><summary type="html"><![CDATA[Today it&#8217;s my great pleasure to announce the availability of Debezium 2.1.0.Final! You might recently noticed that Debezium went a bit silent for the last few weeks. No, we are not going away. In fact the elves in Google worked furiously to bring you a present under a Christmas tree - Debezium Spanner connector.]]></summary></entry><entry><title type="html">Filling the Ranks</title><link href="https://debezium.io/blog/2022/11/15/filling-the-ranks/" rel="alternate" type="text/html" title="Filling the Ranks"/><published>2022-11-15T00:00:00+00:00</published><updated>2022-11-15T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/11/15/filling-the-ranks</id><content type="html" xml:base="https://debezium.io/blog/2022/11/15/filling-the-ranks/"><![CDATA[<div class="paragraph"> <p>As you are probably well aware, Gunnar Morling has stepped down from his position as Debezium project lead and is now pursuing new exciting adventures. It is sad, but every cloud has a silver lining!</p> </div> <div class="paragraph"> <p>What can it be? We (the Debezium team and Red Hat) are hiring! Are you a community contributor? Do you have any pull requests under your belt? Are you a happy Debezium user and eager to do more, or are you a seasoned Java developer looking for work in an exciting and inclusive open-source environment?</p> </div> <div class="paragraph"> <p> If any of that describes you, don’t hesitate to contact me (Jiri Pechanec &lt;<a href="mailto:jpechane@redhat.com">jpechane@redhat.com</a>&gt;) via email or our Zulip chat. I cannot promise you will be selected, but I can promise an open and fair process.</p> </div> <div class="paragraph"> <p>The following are a guideline, things we’d love to see but aren’t all required. If there are specific expectations, those are indicated inline.</p> </div> <div class="ulist"> <ul> <li> <p>Multiple years of Java development experience</p> <div class="ulist"> <ul> <li> <p>JDBC knowledge expected</p> </li> </ul> </div> </li> <li> <p>Enterprise Java is not required but the knowledge of integration patterns like message bus (JMS), routing, etc. is welcome</p> </li> <li> <p>Kafka or Kafka Connect experience is welcome</p> </li> <li> <p>At least user knowledge of some of the databases supported by Debezium is preferred</p> <div class="ulist"> <ul> <li> <p>Basic database concepts like transactions (ACID), and transaction logs are expected</p> </li> </ul> </div> </li> <li> <p>Open-source contributions are a plus</p> </li> <li> <p>Debezium contributions are a huge plus</p> </li> </ul> </div> <div class="paragraph"> <p>We can promise engaging and interesting work, an excellent and inclusive team that treats everyone with respect, and a wonderful community that is vibrant and growing daily.</p> </div> <div class="paragraph"> <p>Don’t be shy, and don’t underestimate yourself. We would rather speak to more people than miss you!</p> </div>]]></content><author><name>Jiri Pechanec</name></author><category term="community"/><category term="hiring"/><summary type="html"><![CDATA[As you are probably well aware, Gunnar Morling has stepped down from his position as Debezium project lead and is now pursuing new exciting adventures. It is sad, but every cloud has a silver lining! What can it be? We (the Debezium team and Red Hat) are hiring! Are you a community contributor? Do you have any pull requests under your belt? Are you a happy Debezium user and eager to do more, or are you a seasoned Java developer looking for work in an exciting and inclusive open-source environment?]]></summary></entry><entry><title type="html">Debezium 2.1.0.Alpha1 Released</title><link href="https://debezium.io/blog/2022/11/10/debezium-2-1-alpha1-released/" rel="alternate" type="text/html" title="Debezium 2.1.0.Alpha1 Released"/><published>2022-11-10T00:00:00+00:00</published><updated>2022-11-10T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/11/10/debezium-2-1-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/11/10/debezium-2-1-alpha1-released/"><![CDATA[<div class="paragraph"> <p>It&#8217;s my pleasure to announce the first release of the Debezium 2.1 series, <strong>2.1.0.Alpha1</strong>!</p> </div> <div class="paragraph"> <p>The Debezium 2.1.0.Alpha1 release includes quite a number of bug fixes but also some noteworthy improvements and new features including but not limited to:</p> </div> <div class="ulist"> <ul> <li> <p>Support for PostgreSQL 15</p> </li> <li> <p>Single Message Transformation (SMT) predicate support in Debezium engine</p> </li> <li> <p>Capturing TRUNCATE as change event in MySQL table topics</p> </li> <li> <p>Oracle LogMiner performance improvements</p> </li> <li> <p>New Redis-based storage module</p> </li> </ul> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>Let&#8217;s take a few moments and dive into some of these in more detail!</p> </div> <div class="sect1"> <h2 id="smt_predicate_support_in_debezium_engine">SMT predicate support in Debezium engine</h2> <div class="sectionbody"> <div class="paragraph"> <p>Single Message Transformations (SMTs) are a critical part of a change event&#8217;s lifecycle and they can apply any number of messaging patterns to the emitted change event. For example, a database table may have a specific column that gets emitted as a part of Debezium&#8217;s change events, but you want this field to be excluded so that the field isn&#8217;t present in the persisted event inside Kafka. This can be done using a single message transformation (SMT).</p> </div> <div class="paragraph"> <p>However, Debezium emits a number of different event types such as heartbeat, schema change, and data change events. Each of these events have their own event structure and there may come a point where a specific SMT should only be applied to a specific event type or if a specific event has a certain criteria. One way to evaluate whether the SMT should be applied was to do this evaluation inside the SMT itself, checking its event type or all the criteria to see whether the SMT should be applied or if the SMT should return the event unchanged.</p> </div> <div class="paragraph"> <p>Kafka Connect later introduced a concept called <em>predicates</em>, which is where a set of external rules can be specified in the connector configuration and must be evaluated to determine whether the SMT should be fired for an event or whether the SMT is skipped. This has enormous benefits because it allows developers to write very specific transformations that focus on a singular mutation and its entirely up to the user to determine whether that SMT should be applied or not using <em>predicates</em>.</p> </div> <div class="paragraph"> <p>Starting in Debezium 2.1, the power of Single Message Transformation (SMT) predicates can be harnessed when using the Debezium Engine or Debezium Server. An example configuration might like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties"># Define the filter transformation, linking it to the IsFoo predicate/rule
debezium.transforms=Filter
debezium.transforms.Filter.type=org.apache.kafka.connect.transforms.Filter
debezium.transforms.Filter.predicate=IsFoo

# Define the IsFoo predicate/rule
debezium.predicates=IsFoo
debezium.predicates.IsFoo.type=org.apache.kafka.connect.transforms.predicates.TopicNameMatches
debezium.predicates.IsFoo.pattern=foo</code></pre> </div> </div> <div class="paragraph"> <p>With these additional <code>debezium.predicates.*</code> configuration properties, it is possible to define a set of rules that must be evaluated to determine whether the <code>Filter</code> SMT will be fired or skipped in the transformation chain. In the example above, the predicate checks to see whether the event&#8217;s topic name matches <code>foo</code> and if it does, the <code>Filter</code> transformation will be fired. If the topic name does not match <code>foo</code>, the <code>Filter</code> transformation is skipped.</p> </div> <div class="paragraph"> <p>To read more about applying Single Message Transformations (SMTs) selectively using predicates, see:</p> </div> <div class="ulist"> <ul> <li> <p><a href="https://debezium.io/documentation/reference/2.1/transformations/applying-transformations-selectively.html">Using SMT predicates to selectively apply transformations</a></p> </li> <li> <p><a href="https://debezium.io/documentation/reference/2.1/operations/debezium-server.html#debezium-predicates-configuration-options">Debezium Server predicates configuration and set up</a></p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="capture_mysql_truncate_as_change_event">Capture MySQL TRUNCATE as change event</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium has supported the concept of emitting a change event to signal a <code>TRUNCATE TABLE</code> scenario for PostgreSQL and Oracle for quite a while. Starting with Debezium 2.1, this behavior has been extended to the MySQL connector.</p> </div> <div class="paragraph"> <p>By default, the connector configuration option, <code>skipped.operations</code>, automatically skips <code>TRUNCATE</code> events if they&#8217;re detected. This means that by default, there will not be anything emitted when the connector detects this pattern. In order to support emission of such events, the <code>skipped.operations</code> configuration property must be specified with a value of <code>none</code> or other operation types that do not include the <code>t</code> (truncate) type.</p> </div> <div class="paragraph"> <p>Once the connector is configured to emit events for <code>TRUNCATE</code> operations, a new data change event type will be emitted to the table topics. These event types signal that the table or collection has been truncated. The event&#8217;s payload will looking like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json"><span class="key"><span class="delimiter">&quot;</span><span class="content">payload</span><span class="delimiter">&quot;</span></span>: {
  <span class="key"><span class="delimiter">&quot;</span><span class="content">source</span><span class="delimiter">&quot;</span></span>: {
    <span class="error">.</span><span class="error">.</span><span class="error">.</span>
  },
  <span class="key"><span class="delimiter">&quot;</span><span class="content">op</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">t</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">ts_ms</span><span class="delimiter">&quot;</span></span>: <span class="integer">1465581029523</span>
}</code></pre> </div> </div> <div class="paragraph"> <p>The most notable point here is that truncate events do not contain a <code>before</code> or <code>after</code> state.</p> </div> </div> </div> <div class="sect1"> <h2 id="new_redis_based_storage_module">New Redis-based storage module</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium recently modularized parts of its codebase around persisting offsets and schema history into a set of modules supporting File and Kafka -based implementation. In Debezium 2.1, a new module was introduced to support persisting to Redis data stores.</p> </div> <div class="paragraph"> <p>The following fully-qualified class names can be used to persist offsets or schema history to Redis data stores:</p> </div> <div class="ulist"> <ul> <li> <p><code>io.debezium.storage.redis.offset.RedisOffsetBackingStore</code></p> </li> <li> <p><code>io.debezium.storage.redis.history.RedisSchemaHistory</code></p> </li> </ul> </div> <div class="paragraph"> <p>If you have manually installed Debezium, be sure to include the <code>debezium-storage-redis</code> artifact on your classpath if it does not exist in order to gain access to these new implementations.</p> </div> <div class="paragraph"> <p>For information about what options can be configured with this new implementation, please see the <a href="https://debezium.io/documentation/reference/2.1/operations/debezium-server.html#debezium-source-configuration-properties">source configuration</a> section of the Debezium Server documentation and look for configuration options prefixed with:</p> </div> <div class="ulist"> <ul> <li> <p><code>debezium.source.offset.storage.redis.*</code></p> </li> <li> <p><code>debezium.source.schema.history.internal.redis.*</code></p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="other_fixes">Other fixes</h2> <div class="sectionbody"> <div class="paragraph"> <p>There were quite a number of bugfixes and stability changes in this release, some noteworthy are:</p> </div> <div class="ulist"> <ul> <li> <p>Missing snapshot pending transactions <a href="https://issues.redhat.com/browse/DBZ-5482">DBZ-5482</a></p> </li> <li> <p>Using snapshot.mode ALWAYS uses SCN from offsets <a href="https://issues.redhat.com/browse/DBZ-5626">DBZ-5626</a></p> </li> <li> <p>MongoDB multiple tasks monitor misalignment <a href="https://issues.redhat.com/browse/DBZ-5629">DBZ-5629</a></p> </li> <li> <p>UNIQUE INDEX with NULL value throws exception when lob.enabled is true <a href="https://issues.redhat.com/browse/DBZ-5682">DBZ-5682</a></p> </li> <li> <p>Columns are not excluded when doing incremental snapshots <a href="https://issues.redhat.com/browse/DBZ-5727">DBZ-5727</a></p> </li> <li> <p>NullPointerException thrown during snapshot of tables in Oracle source connector <a href="https://issues.redhat.com/browse/DBZ-5738">DBZ-5738</a></p> </li> <li> <p>Hostname not available for load balanced ocp services in ARO <a href="https://issues.redhat.com/browse/DBZ-5753">DBZ-5753</a></p> </li> <li> <p>Exclude Oracle Compression Advisor tables from capture to avoid infinite loop <a href="https://issues.redhat.com/browse/DBZ-5756">DBZ-5756</a></p> </li> <li> <p>Message with LSN 'LSN{XYZ}' not present among LSNs seen in the location phase <a href="https://issues.redhat.com/browse/DBZ-5792">DBZ-5792</a></p> </li> </ul> </div> <div class="paragraph"> <p>Altogether, <a href="https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.1.0.Alpha1%20ORDER%20BY%20component%20ASC">55 issues</a> were fixed for this release. A big thank you to all the contributors from the community who worked on this release: <a href="https://github.com/adasari">Anil Dasari</a>, <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/enzo-cappa">Enzo Cappa</a>, <a href="https://github.com/ggaborg">Gabor Andras</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/BetaCat0">Helong Zhang</a>, <a href="https://github.com/hdulay">Hubert Dulay</a>, <a href="https://github.com/jcechace">Jakub Cechacek</a>, <a href="https://github.com/janjwerner-confluent">Jan Werner</a>, <a href="https://github.com/jeremy-l-ford">Jeremy Ford</a>, <a href="https://github.com/novotnyJiri">Jiri Novotny</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/dude0001">Mark Lambert</a>, <a href="https://github.com/MartinMedek">Martin Medek</a>, <a href="https://github.com/obabec">Ondrej Babec</a>, <a href="https://github.com/rajdangwal">Rajendra Dangwal</a>, <a href="https://github.com/chtitux">Théophile Helleboid</a>, <a href="https://github.com/vjuranek">Vojtech Juranek</a>, and <a href="https://github.com/ywu-stripe">Yang Wu</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="whats_next">What&#8217;s Next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>So as we continue to work on Debezium 2.1, we&#8217;ve been able to include a number of the expected changes in today&#8217;s release, but we still do intend to deliver on a new Single Message Transformation (SMT) for generating change event deltas before the end of the year. There is also some much anticipated changes for Debezium UI, such as supporting editing of connector configurations and much more.</p> </div> <div class="paragraph"> <p>You can find this information and what else to expect as a part of Debezium in 2023 in our recently updated <a href="/roadmap/">road map</a>. We have quite a lot of new features planned for next year, and we would love to hear your feedback or suggestions on things that may not be on the roadmap you&#8217;d like to see. Be sure to get in touch with us on the mailing list if there is.</p> </div> <div class="paragraph"> <p>Until next time&#8230;&#8203;</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html"><![CDATA[It&#8217;s my pleasure to announce the first release of the Debezium 2.1 series, 2.1.0.Alpha1! The Debezium 2.1.0.Alpha1 release includes quite a number of bug fixes but also some noteworthy improvements and new features including but not limited to: Support for PostgreSQL 15 Single Message Transformation (SMT) predicate support in Debezium engine Capturing TRUNCATE as change event in MySQL table topics Oracle LogMiner performance improvements New Redis-based storage module]]></summary></entry><entry><title type="html">Debezium Evolving</title><link href="https://debezium.io/blog/2022/10/26/debezium-evolving/" rel="alternate" type="text/html" title="Debezium Evolving"/><published>2022-10-26T00:00:00+00:00</published><updated>2022-10-26T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/10/26/debezium-evolving</id><content type="html" xml:base="https://debezium.io/blog/2022/10/26/debezium-evolving/"><![CDATA[<div class="paragraph"> <p>Some time in early 2017, I got a meeting invite from Debezium&#8217;s founder, <a href="https://twitter.com/rhauch">Randall Hauch</a>. He was about to begin a new chapter in his professional career and was looking for someone to take over as the project lead for Debezium. So we hopped on a call to talk things through, and I was immediately sold on the concept of change data capture, its large number of potential use cases and applications, and the idea of making this available to the community as open-source. After some short consideration I decided to take up this opportunity, and without a doubt this has been one of the best decisions I&#8217;ve ever made in my job.</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>Today, five years and two major releases (<a href="/blog/2019/12/18/debezium-1-0-0-final-released/">1.0</a>, <a href="/blog/2022/10/17/debezium-2-0-final-released/">2.0</a>) later, I am feeling really proud of what the Debezium community has accomplished, having established itself as <em>the</em> leading open-source platform for change data capture. The number of officially supported databases has grown from three to eight. Further Debezium-based CDC connectors are developed externally by database vendors like <a href="https://docs.scylladb.com/stable/using-scylla/integrations/scylla-cdc-source-connector.html">ScyllaDB</a> and <a href="https://docs.yugabyte.com/preview/explore/change-data-capture/debezium-connector-yugabytedb/">Yugabyte</a>, making Debezium&#8217;s change event format kind of a de-facto standard for CDC. The project is used in production by companies such as Reddit, Shopify, Ubisoft, and Zalando. Debezium became part of Red Hat&#8217;s commercially supported product offerings (<a href="https://access.redhat.com/documentation/en-us/red_hat_integration/2022.q3/html/getting_started_with_debezium/index">on-prem</a>, as well as <a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/connectors">fully managed</a> in the cloud), with multiple other vendors providing Debezium-backed offers as well. During the keynote of this year&#8217;s Current conference, Debezium was <a href="https://twitter.com/gunnarmorling/status/1577318988836642816">recognized</a> as one of the most impactful open-source projects in the Apache Kafka space.</p> </div> <div class="paragraph"> <p>The most important part to me though is the tremendous growth of the Debezium community itself. To this day, more than <a href="https://github.com/debezium/debezium/blob/main/COPYRIGHT.txt">450 individuals</a> have contributed to the code base. A big thank you to all the people and organizations who&#8217;ve worked tirelessly to make the vision of open-source change data capture a reality and continue to improve it every day: Red Hat&#8201;&#8212;&#8201;as the project&#8217;s main sponsor&#8201;&#8212;&#8201;Stripe, Instaclustr, SugarCRM, Redis, and many other companies and individual contributors!</p> </div> <div class="paragraph"> <p>After ten amazing years at Red Hat, I felt that it was about time for a change for me and start some new adventure, and I am going to join a start-up in the data streaming space next month. As part of this transition, I am also stepping down from the role as the project lead for Debezium. While I&#8217;ll be less active in the project on a daily basis, I definitely plan to stay involved and hopefully still send the one or other pull request.</p> </div> <div class="paragraph"> <p>My partner in crime <a href="https://github.com/jpechane">Jiri Pechanec</a> will take over as the acting engineering lead. Or, I should say, has taken over, since in fact he has had that role since earlier this year already. Jiri has been a member of the project for many years, working on several key features such as <a href="/blog/2021/10/07/incremental-snapshots/">incremental snapshots</a> and MongoDB change streams support. He&#8217;s an outstanding software engineer, with a unique insight into the problem space of CDC and decades of experience working in open source, and he will be an amazing lead for the Debezium project and community.</p> </div> <div class="paragraph"> <p>With the Debezium 2.0 release just through the door, addressing several consistency issues and getting rid of a fair chunk of technical debt, the project is in an excellent position for its future evolution. There are plans for another community-led connector which should be announced very soon, there&#8217;ll be support for exactly-once semantics as recently introduced in Kafka Connect (<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-618%3A+Exactly-Once+Support+for+Source+Connectors">KIP -618</a>), a Kubernetes operator for Debezium Server, a JDBC sink connector, and much more.</p> </div> <div class="paragraph"> <p>The best is yet to come, and I can&#8217;t wait to see what this amazing community will build next!</p> </div>]]></content><author><name>Gunnar Morling</name></author><category term="community"/><category term="news"/><summary type="html"><![CDATA[Some time in early 2017, I got a meeting invite from Debezium&#8217;s founder, Randall Hauch. He was about to begin a new chapter in his professional career and was looking for someone to take over as the project lead for Debezium. So we hopped on a call to talk things through, and I was immediately sold on the concept of change data capture, its large number of potential use cases and applications, and the idea of making this available to the community as open-source. After some short consideration I decided to take up this opportunity, and without a doubt this has been one of the best decisions I&#8217;ve ever made in my job.]]></summary></entry><entry><title type="html">Debezium 1.9.7.Final Released</title><link href="https://debezium.io/blog/2022/10/26/debezium-1-9-7-final-released/" rel="alternate" type="text/html" title="Debezium 1.9.7.Final Released"/><published>2022-10-26T00:00:00+00:00</published><updated>2022-10-26T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/10/26/debezium-1-9-7-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/10/26/debezium-1-9-7-final-released/"><![CDATA[<div class="paragraph"> <p>I&#8217;m excited to announce the release of Debezium <strong>1.9.7.Final</strong>!</p> </div> <div class="paragraph"> <p>This release focuses on bug fixes and stability; and is the recommended update for all users from earlier versions. This release contains <a href="https://issues.redhat.com/issues/?jql=project+%3D+DBZ+AND+fixVersion+%3D+1.9.7.Final">22 resolved issues</a> overall.</p> </div> <div class="paragraph"> <p></p> </div> <div class="sect1"> <h2 id="changes">Changes</h2> <div class="sectionbody"> <div class="paragraph"> <p>A few noteworthy bug fixes and stability improvements include:</p> </div> <div class="ulist"> <ul> <li> <p>Debezium connectors ship with an old version of google-protobuf vulnerable to CVE-2022-3171 <a href="https://issues.redhat.com/browse/DBZ-5747">DBZ-5747</a></p> </li> <li> <p>ORA-01289: cannot add duplicate logfile <a href="https://issues.redhat.com/browse/DBZ-5276">DBZ-5276</a></p> </li> <li> <p>Using snapshot boundary mode "all" causes DebeziumException on Oracle RAC <a href="https://issues.redhat.com/browse/DBZ-5302">DBZ-5302</a></p> </li> <li> <p>Missing snapshot pending transactions <a href="https://issues.redhat.com/browse/DBZ-5482">DBZ-5482</a></p> </li> <li> <p>Outbox pattern nested payload leads to connector crash <a href="https://issues.redhat.com/browse/DBZ-5654">DBZ-5654</a></p> </li> <li> <p>Keyword virtual can be used as an identifier <a href="https://issues.redhat.com/browse/DBZ-5674">DBZ-5674</a></p> </li> <li> <p>MongoDB Connector with DocumentDB errors with "{$natural: -1} is not supported" <a href="https://issues.redhat.com/browse/DBZ-5677">DBZ-5677</a></p> </li> <li> <p>Function DATE_ADD can be used as an identifier <a href="https://issues.redhat.com/browse/DBZ-5679">DBZ-5679</a></p> </li> <li> <p>UNIQUE INDEX with NULL value throws exception when lob.enabled is true <a href="https://issues.redhat.com/browse/DBZ-5682">DBZ-5682</a></p> </li> <li> <p>MySqlConnector parse create view statement failed <a href="https://issues.redhat.com/browse/DBZ-5708">DBZ-5708</a></p> </li> <li> <p>Debezium Server 1.9.6 is using MSSQL JDBC 7.2.2 instead of 9.4.1 <a href="https://issues.redhat.com/browse/DBZ-5711">DBZ-5711</a></p> </li> <li> <p>Vitess: Handle Vstream error: unexpected server EOF <a href="https://issues.redhat.com/browse/DBZ-5722">DBZ-5722</a></p> </li> <li> <p>ParsingException: DDL statement couldn&#8217;t be parsed (index hints) <a href="https://issues.redhat.com/browse/DBZ-5724">DBZ-5724</a></p> </li> <li> <p>Oracle SQL parsing error when collation used <a href="https://issues.redhat.com/browse/DBZ-5726">DBZ-5726</a></p> </li> <li> <p>Unparseable DDL statement <a href="https://issues.redhat.com/browse/DBZ-5734">DBZ-5734</a></p> </li> </ul> </div> <div class="paragraph"> <p>Please refer to the <a href="/releases/1.9/release-notes#release-1.9.7-final">release notes</a> to learn more about all fixed bugs, update procedures, etc.</p> </div> <div class="paragraph"> <p>Many thanks to the following individuals from the community who contributed to Debezium 1.9.7.Final: <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/xinbinhuang">Bin Huang</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/HenryCaiHaiying">Henry Cai</a>, <a href="https://github.com/jcechace">Jakub Cechacek</a>, <a href="https://github.com/janjwerner-confluent">Jan Werner</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/joschi">Jochen Schalanda</a>, <a href="https://github.com/nilshartmann">Nils Hartmann</a>, <a href="https://github.com/thangdc94">Phạm Ngọc Thắng</a>, <a href="https://github.com/Sage-Pierce">Sage Pierce</a>, <a href="https://github.com/smiklosovic">Stefan Miklosovic</a>, and <a href="https://github.com/vjuranek">Vojtech Juranek</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="outlook_whats_next">Outlook, What&#8217;s next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>This past year has been packed full of tons of changes. This makes the eighth and likely final stable release for Debezium 1.9 as we begin to turn our attention fully to Debezium 2.0 moving forward.</p> </div> <div class="paragraph"> <p>With Debezium 2.0 released on October 17th, just last week, the team is now hard at work addressing your feedback, so keep that coming. We&#8217;re also actively working on the next installment of Debezium, 2.1, which will be released later this year. Be sure to keep an eye on our <a href="/roadmap">road map</a> in the coming week as we intend to debut what is planned for Debezium 2.1 and what&#8217;s to come in 2023!</p> </div> <div class="paragraph"> <p>Until then, stay safe!</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html"><![CDATA[I&#8217;m excited to announce the release of Debezium 1.9.7.Final! This release focuses on bug fixes and stability; and is the recommended update for all users from earlier versions. This release contains 22 resolved issues overall.]]></summary></entry><entry><title type="html">Debugging flaky tests</title><link href="https://debezium.io/blog/2022/10/20/flaky-tests/" rel="alternate" type="text/html" title="Debugging flaky tests"/><published>2022-10-20T00:00:00+00:00</published><updated>2022-10-20T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/10/20/flaky-tests</id><content type="html" xml:base="https://debezium.io/blog/2022/10/20/flaky-tests/"><![CDATA[<div class="paragraph"> <p>When developing the tests for your project, sooner or later you will probably get into the situation when some of the tests fail randomly. These tests, also known as flaky tests, are very unpleasant as you never know if the failure was random or there is a regression in your code. In the worst case you just ignore these tests because you know they are flaky. Most of the testing frameworks even have a dedicated annotation or other means to express that the test is flaky and if it fails, the failure should be ignored. The value of such a test is very questionable. The best thing you can do with such a test is of course to fix it so that it doesn&#8217;t fail randomly. That&#8217;s easy to say, but harder to do. The hardest part is usually to make the test fail in your development environment so that you can debug it and understand why it fails and what is the root cause of the failure. In this blog post I&#8217;ll try to show a few techniques which may help you to simulate random test failures on you local machine.</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>From my experience the most common reason for randomly failing tests is either not properly cleaned environment or slow environment. Both such situations are quite common in CI environments. Failures due to interference with other tests were more common in the past. Nowadays, when usage of virtual machines and containers is quite common, this is usually not an issue. Also, tests isolation implemented by various CI as a services offerings is done well. The downside of using a CI as a service is that you usually cannot log into the machine and debug the tests there. Therefore, you have to either enable debug logs and wait for the next failure or guess what the reason was and try to simulate it on your local machine.</p> </div> <div class="paragraph"> <p>The most common root cause of random failures in CI environments is slowness of various kinds. This is the result of overcommitting the resources in virtual environments or resource limits put on the VMs/containers. Therefore one of the most powerful ways to simulate random test failure locally is to restrict test resources on your local environment. Let&#8217;s see what the common options are and how to do it.</p> </div> <div class="sect1"> <h2 id="running_tests_in_one_thread">Running tests in one thread</h2> <div class="sectionbody"> <div class="paragraph"> <p>One possible way to slow down your tests, especially when you have a multi-threaded application, is to execute the tests on a single thread or limited number of threads. On the Linux operating system, it’s pretty easy with the <code>taskset</code> command. <a href="https://man7.org/linux/man-pages/man1/taskset.1.html">taskset</a> tell the Linux scheduler to attach given process to specified CPU core. To run e.g. Debezium MySQL <a href="https://github.com/debezium/debezium/blob/main/debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/TransactionMetadataIT.java">TransactionMetadataIT</a> on a single CPU core, you just need to run</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>taskset -c 0 mvn verify -DskipTests -Dit.test=DebeziumEngineIT</code></pre> </div> </div> <div class="paragraph"> <p>which would execute the tests on CPU #0.</p> </div> </div> </div> <div class="sect1"> <h2 id="limiting_container_resources">Limiting container resources</h2> <div class="sectionbody"> <div class="paragraph"> <p>On the Debezium project we use containers for tests heavily. We run the databases against the tests run in the containers. What we often need is not to slow down the tests itself, but the database. Docker provides quite a lot of <a href="https://docs.docker.com/config/containers/resource_constraints/">options</a> how to limit container resources. The most useful is usually limiting the CPU using <code>--cpus</code> parameter. This allows us to limit the amount of CPU Docker can use for running the container. The nice thing here is that it can be a float number, so you can e.g. limit containers to use only half of CPU time by setting <code>--cpus=0.5</code>. In a similar way you can also limit other resource, like e.g. RAM.</p> </div> <div class="paragraph"> <p>The common Debezium workflow is to run the containers from Maven, using <a href="https://dmp.fabric8.io/">Docker Maven plugin</a>. The plugin provides <a href="https://dmp.fabric8.io/#property-configuration">long list of properties</a> which you can configure, including properties for limiting container resources. However, there is one caveat with this option. With current release, <code>docker.cpus</code> expect <a href="https://github.com/fabric8io/docker-maven-plugin/issues/1608">long number</a> instead of float and have a meaning, roughly saying, how many CPU nano seconds from one second cycle the container can take. E.g. equivalent of <code>--cpus=0.5</code> would be:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>mvn docker:start -Ddocker.cpus=500000000</code></pre> </div> </div> <div class="paragraph"> <p>This issue was <a href="https://github.com/fabric8io/docker-maven-plugin/pull/1609">fixed</a> recently and should be in the next Docker Maven plugin release, so once Debezium upgrade to the next version, you should be able use <code>docker.cpus</code> in the same way as you would use when running the container from the command line. Other Docker Maven plugin properties, e.g. <code>docker.memory</code> should work as expected.</p> </div> </div> </div> <div class="sect1"> <h2 id="imposing_network_latency">Imposing network latency</h2> <div class="sectionbody"> <div class="paragraph"> <p>Another common source of random test failures is network latency. There&#8217;s probably not any easy way to simulate it on a local machine and one has to use some kind of proxy. Fortunately, there is a proxy exactly for this purpose - <a href="https://github.com/Shopify/toxiproxy">Toxiproxy</a>. It&#8217;s a dedicated proxy to simulate various network failures and latencies. It has a rich feature set and moreover it&#8217;s pretty easy to set it up, so it&#8217;s a pleasure to work with it. Let&#8217;s see how to set it up with Debezium tests on a local machine.</p> </div> <div class="paragraph"> <p>You can install Toxiproxy locally (on Fedora by running <code>sudo dnf install toxiproxy</code>) or download it in a container:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>docker pull ghcr.io/shopify/toxiproxy</code></pre> </div> </div> <div class="paragraph"> <p>We are going to run Toxiproxy in a container, but it&#8217;s also convenient to install it locally as it contains a CLI utility to send commands to the Toxyproxy. Otherwise we would have to run the commands from the container. For simplicity, we will use a CLI tool installed locally. Toxyproxi allows us to send commands over HTTP and listens on port 8474. Therefore, when we start Toxyproxy, we need to expose this port. Another port we need to expose is the one for the database for which the Toxiproxy will serve as a proxy. In our example we will use MySQL, therefore we need to expose port 3306. We can of course use any other port, but in such a case we would need to pass additional parameter to the Debezium test, namely <code>database.port</code> pointing to the port exposed by Toxiproxy. Again, for simplicity, let&#8217;s stick with the default port 3306. Also, as we are going to run the Debezium tests from the local machine (not from a container), we need to attach Toxiproxy to the localhost network, which is by default named <code>host</code>. Putting everything together, we can run Toxiproxy container as follows:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>docker run --rm -p 8474:8474 -p 3306:3306 --net=host -it ghcr.io/shopify/toxiproxy</code></pre> </div> </div> <div class="paragraph"> <p>Now we also have to start our database. As the port 3306 is already occupied by Toxiproxy, we have to choose another one, let&#8217;s say 3307:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>mvn docker:start -Dmysql.port=3307</code></pre> </div> </div> <div class="paragraph"> <p>The last missing piece is to tell Toxiproxy for which ports it should create the proxy. In our case it&#8217;s from port 3306 (listen port <code>-l</code>) to 3307 (upstream port <code>-u</code>):</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>toxiproxy-cli create mysql -l 0.0.0.0:3306 -u 0.0.0.0:3307</code></pre> </div> </div> <div class="paragraph"> <p>This command creates a new proxy within Toxiproxy, called <code>mysql</code>. There can be multiple proxies. We can list all the proxies by running</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>toxiproxy-cli list</code></pre> </div> </div> <div class="paragraph"> <p>which gives you output like this:</p> </div> <div class="listingblock"> <div class="content"> <pre>$ toxiproxy-cli list
Name                    Listen          Upstream                Enabled         Toxics
======================================================================================
mysql                   [::]:3306       0.0.0.0:3307            enabled         None</pre> </div> </div> <div class="paragraph"> <p>Now let&#8217;s try if everything works and run some test:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>mvn verify -DskipTests -Ddatabase.hostname=localhost -Pskip-integration-tests -Dit.test=TransactionMetadataIT</code></pre> </div> </div> <div class="paragraph"> <p>Everything should run as normal as we haven&#8217;t created any toxics (latencies or failure) yet. It&#8217;s just a check that the proxy works correctly. If everything works, let&#8217;s create a toxic now:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>toxiproxy-cli toxic add mysql --type latency --attribute latency=500 -n mysql_latency</code></pre> </div> </div> <div class="paragraph"> <p>This will add a network latency of 500 ms on the mysql proxy. The toxic is named "mysql_latency".</p> </div> <div class="paragraph"> <p>You can get more details about specified proxy by running <code>inspect</code> command:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>toxiproxy-cli inspect mysql</code></pre> </div> </div> <div class="paragraph"> <p>with output like this:</p> </div> <div class="listingblock"> <div class="content"> <pre>$ toxiproxy-cli inspect mysql
Name: mysql     Listen: [::]:3306       Upstream: 0.0.0.0:3307
======================================================================
Upstream toxics:
Proxy has no Upstream toxics enabled.

Downstream toxics:
mysql_latency:  type=latency    stream=downstream       toxicity=1.00   attributes=[    jitter=0        latency=500     ]</pre> </div> </div> <div class="paragraph"> <p>Now, run the test again. Did you observe that the test ran substantially longer? If yes, everything works as expected, as we added latency to every call to the database.</p> </div> <div class="paragraph"> <p>This is a simple example of adding toxic to the Toxiproxy. Toxiproxy provides many more options and ways to configure the toxics. See <a href="https://github.com/Shopify/toxiproxy">Toxiproxy</a> for more details.</p> </div> <div class="paragraph"> <p>Once we are done, we can remove toxic</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>toxiproxy-cli toxic remove mysql -n mysql_latency</code></pre> </div> </div> <div class="paragraph"> <p>as well as proxy itself:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code>toxiproxy-cli delete mysql</code></pre> </div> </div> <div class="paragraph"> <p>or simply stop and delete the container.</p> </div> </div> </div> <div class="sect1"> <h2 id="summary">Summary</h2> <div class="sectionbody"> <div class="paragraph"> <p>In this blog post I tried to show a couple of techniques which may help you to simulate flaky test failures locally. All of them try to make the test environment less responsive, namely by limiting CPU or imposing network latencies using Toxiproxy. There are many other reasons why the tests can be flaky, in many parts of your application stack, and also there are many other tools which can inject various kinds of failures (e.g. disk failures). So this post is not by far exhaustive. But I hope it will help you to debug at least some of the flaky tests, if not in the Debezium project, then at least in your own project.</p> </div> <div class="paragraph"> <p>All these things, especially Toxiproxy, can be also used on a regular basis, even in the CI, to spot various hidden issues in the project which appears only when the environment where it runs doesn&#8217;t behave nicely.</p> </div> <div class="paragraph"> <p>Feel free to share in the discussion any other tips on how to debug flaky tests and what kind of tools you find handy.</p> </div> </div> </div>]]></content><author><name>Vojtěch Juránek</name></author><category term="community"/><category term="tests"/><summary type="html"><![CDATA[When developing the tests for your project, sooner or later you will probably get into the situation when some of the tests fail randomly. These tests, also known as flaky tests, are very unpleasant as you never know if the failure was random or there is a regression in your code. In the worst case you just ignore these tests because you know they are flaky. Most of the testing frameworks even have a dedicated annotation or other means to express that the test is flaky and if it fails, the failure should be ignored. The value of such a test is very questionable. The best thing you can do with such a test is of course to fix it so that it doesn&#8217;t fail randomly. That&#8217;s easy to say, but harder to do. The hardest part is usually to make the test fail in your development environment so that you can debug it and understand why it fails and what is the root cause of the failure. In this blog post I&#8217;ll try to show a few techniques which may help you to simulate random test failures on you local machine.]]></summary></entry><entry><title type="html">Debezium 2.0.0.Final Released</title><link href="https://debezium.io/blog/2022/10/17/debezium-2-0-final-released/" rel="alternate" type="text/html" title="Debezium 2.0.0.Final Released"/><published>2022-10-17T00:00:00+00:00</published><updated>2022-10-17T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/10/17/debezium-2-0-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/10/17/debezium-2-0-final-released/"><![CDATA[<div class="paragraph"> <p>Today it&#8217;s my great pleasure to announce the availability of Debezium <strong>2.0.0.Final</strong>!</p> </div> <div class="paragraph"> <p>Since our 1.0 release in December 2019, the community has worked vigorously to build a comprehensive open-source low-latency platform for change data capture (CDC). Over the past three years, we have extended Debezium&#8217;s portfolio to include a stable connector for Oracle, a community led connector for Vitess, the introduction of incremental snapshots, multi-partition support, and so much more. With the help of our active community of contributors and committers, Debezium is the de facto leader in the CDC space, deployed to production within lots of organizations from across multiple industries, using hundreds of connectors to stream data changes out of thousands of database platforms.</p> </div> <div class="paragraph"> <p>The 2.0 release marks a new milestone for Debezium, one that we are proud to share with each of you.</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>In this post, we&#8217;re going to take a deep dive into all changes in Debezium 2.0, discussing the new features and explaining all the possible breaking changes that could have an impact during the upgrade process. As always we highly recommend that you take a look at the <a href="/releases/2.0/release-notes#release-2.0.0-final">release notes</a> to learn more about all fixed bugs, update procedures, etc. [release notes], especially when upgrading from an older release.</p> </div> <div class="ulist"> <ul> <li> <p><a href="#core-changes">Changes to core Debezium</a></p> </li> <li> <p><a href="#cassandra-changes">Changes to Cassandra connector</a></p> </li> <li> <p><a href="#mongodb-changes">Changes to MongoDB connector</a></p> </li> <li> <p><a href="#mysql-changes">Changes to MySQL connector</a></p> </li> <li> <p><a href="#oracle-changes">Changes to Oracle connector</a></p> </li> <li> <p><a href="#postgres-changes">Changes to PostgreSQL connector</a></p> </li> <li> <p><a href="#vitess-changes">Changes to Vitess connector</a></p> </li> <li> <p><a href="#container-changes">Changes for Debezium container images</a></p> </li> <li> <p><a href="#community-spaces">Community spaces</a></p> </li> </ul> </div> <div class="sect1"> <h2 id="core-changes">Changes to core Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>The fundamental core of Debezium has changed quite a bit in Debezium 2.0. In this section, we&#8217;re going to dive into the changes with Debezium&#8217;s core, and discuss how those changes impact all users of Debezium.</p> </div> <div class="sect2"> <h3 id="java_11_is_required">Java 11 is required</h3> <div class="paragraph"> <p>We have wanted to make the leap to Java 11 for quite some time, and we felt that with Debezium 2.0 this was the right moment. With Java 11, this enables us to take advantage of new language features, such as the new <code>String</code> API and <code>Predicate</code> support changes within the code base, while also benefiting from many of the Java peformance improvements.</p> </div> <div class="paragraph"> <p>Our very own Vojtech Juranek published <a href="/blog/2022/05/04/switch-to-java-11/">this blog</a> where he discusses the switch to Java 11 in detail. The Java 11 runtime will be required moving forward to use Debezium, so be sure that Java 11 is available prior to upgrading.</p> </div> </div> <div class="sect2"> <h3 id="improved_incremental_snapshots">Improved Incremental Snapshots</h3> <div class="sect3"> <h4 id="stopping">Stopping</h4> <div class="paragraph"> <p>Since we first introduced incremental snapshots, users have asked for a way to stop an in-progress snapshot. To accomplish this, we have added a new signal, <code>stop-snapshot</code>, which allows stopping an in-progress incremental snapshot. This signal is to be sent just like any other, by inserting a row into the signal table/collection, as shown below:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="sql"><span class="class">INSERT</span> <span class="class">INTO</span> schema.signal_table (id, type,data)
<span class="keyword">VALUES</span> (<span class="string"><span class="delimiter">'</span><span class="content">unique-id</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">stop-snapshot</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">_&lt;signal payload&gt;_`);</span></span></code></pre> </div> </div> <div class="paragraph"> <p>The <code>stop-snapshot</code> payload looks very similar to its <code>execute-snapshot</code> counterpart. An example:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">data-collections</span><span class="delimiter">&quot;</span></span>: [<span class="string"><span class="delimiter">&quot;</span><span class="content">schema1.table1</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">schema2.table2</span><span class="delimiter">&quot;</span></span>],
  <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">incremental</span><span class="delimiter">&quot;</span></span>
}</code></pre> </div> </div> <div class="paragraph"> <p>This example removes both <code>schema1.table1</code> and <code>schema2.table2</code> from the incremental snapshot, so long as the table or collection had not already finished its incremental snapshot. If other tables or collections remain outstanding after the removal of those specified by <code>data-collections</code>, the incremental snapshot will continue to process those that are outstanding. If no other table or collection remains, the incremental snapshot will stop.</p> </div> <div class="paragraph"> <p>Another example of a <code>stop-snapshot</code> payload is quite simply:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">incremental</span><span class="delimiter">&quot;</span></span>
}</code></pre> </div> </div> <div class="paragraph"> <p>This example does not specify the <code>data-collections</code> property, it is optional for the <code>stop-snapshot</code> signal. When this property isn&#8217;t specified, the signal implies the current in-progress incremental snapshot should be stopped entirely. This gives the ability to stop an incremental snapshot without knowledge of the current or outstanding tables or collections yet to be captured.</p> </div> </div> <div class="sect3"> <h4 id="pausing_and_resuming">Pausing and Resuming</h4> <div class="paragraph"> <p>Incremental snapshots have become an integral feature in Debezium. The incremental snapshot feature allows users to re-run a snapshot on one or more collections/tables for a variety of reasons. Incremental snapshots were originally introduced with just a <em>start</em> signal. We eventually added the ability to <em>stop</em> an ongoing incremental snapshot or to be able to remove a subset of collections/tables from an in-progress incremental snapshot.</p> </div> <div class="paragraph"> <p>In this release, we&#8217;ve built on top of the existing signal foundation and we&#8217;ve introduced two new signals, one to <em>pause</em> an in-progress incremental snapshot and then another to <em>resume</em> the incremental snapshot if it has previously been paused. To pause an incremental snapshot, a <code>pause-snapshot</code> signal must be sent, and to resume, a <code>resume-snapshot</code> signal can be used.</p> </div> <div class="paragraph"> <p>These two new signals can be sent using the signal table strategy or the Kafka signal topic strategy for MySQL. Please refer to the <a href="https://debezium.io/documentation/reference/2.0/configuration/signalling.html#_signal_actions">signal support documentation</a> for more details on signals and how they work.</p> </div> </div> <div class="sect3"> <h4 id="using_regular_expressions">Using Regular Expressions</h4> <div class="paragraph"> <p>Incremental snapshot signals have required the use of explicit table/collection names in the <code>data-collections</code> payload attribute. While this worked well, there may be situations where broad capture configurations could take advantage of regular expression usage. We already support regular expressions in connector configuration options, such as include/exclude lists, so it made sense to extend that to incremental snapshots as well.</p> </div> <div class="paragraph"> <p>Starting in Debezium 2.0, all incremental snapshot signals can use regular expressions in the <code>data-collections</code> payload property. Using one of the stop signal examples from above, the payload can be rewritten using regular expressions:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">data-collections</span><span class="delimiter">&quot;</span></span>: [<span class="string"><span class="delimiter">&quot;</span><span class="content">schema[1|2].table[1|2]</span><span class="delimiter">&quot;</span></span>],
  <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">incremental</span><span class="delimiter">&quot;</span></span>
}</code></pre> </div> </div> <div class="paragraph"> <p>Just like the explicit usage, this signal with regular expressions would also stop both <code>schema1.table1</code> and <code>schema2.table2</code>.</p> </div> </div> <div class="sect3"> <h4 id="applying_filters_with_sql_conditions">Applying filters with SQL conditions</h4> <div class="paragraph"> <p>Although uncommon, there may be scenarios such as a connector misconfiguration, where a specific record or subset of records needs to be re-emitted to the topic. Unfortunately, incremental snapshots have traditionally been an all-or-nothing type of process, where we would re-emit all records from a collection or table as a part of the snapshot.</p> </div> <div class="paragraph"> <p>In this release, a new <code>additional-condition</code> property can be specified in the signal payload, allowing the signal to dictate a SQL-based predicate to control what subset of records should be included in the incremental snapshot instead of the default behavior of <em>all rows</em>.</p> </div> <div class="paragraph"> <p>The following example illustrates sending an incremental snapshot signal for the <code>products</code> table, but instead of sending all rows from the table to the topic, the <code>additional-condition</code> property has been specified to restrict the snapshot to only send events that relate to product id equal to <code>12</code>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">execute-snapshot</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">data</span><span class="delimiter">&quot;</span></span>: {
    <span class="key"><span class="delimiter">&quot;</span><span class="content">data-collections</span><span class="delimiter">&quot;</span></span>: [<span class="string"><span class="delimiter">&quot;</span><span class="content">inventory.products</span><span class="delimiter">&quot;</span></span>],
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">INCREMENTAL</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">additional-condition</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">product_id=12</span><span class="delimiter">&quot;</span></span>
  }
}</code></pre> </div> </div> <div class="paragraph"> <p>We believe this new incremental snapshot feature will be tremendously helpful for a variety of reasons, without always having to re-snapshot all rows when only a subset of data is required.</p> </div> </div> <div class="sect3"> <h4 id="signal_database_collection_added_to_inclusion_filter_automatically">Signal database collection added to inclusion filter automatically</h4> <div class="paragraph"> <p>In prior releases of Debezium, the signal collection/table used for incremental snapshots had to be manually added to your <code>table.include.list</code> connector property. A big theme in this release was improvements on incremental snapshots, so we&#8217;ve taken this opportunity to streamline this as well. Starting in this release, Debezium will automatically add the signal collection/table to the table inclusion filters, avoiding the need for users to manually add it.</p> </div> <div class="paragraph"> <p>This change does not impose any compatibility issues. Connector configurations that already include the signal collection/table in the <code>table.include.list</code> property will continue to work without requiring any changes. However, if you wish to align your configuration with current behavior, you can also safely remove the signal collection/table from the <code>table.include.list</code>, and Debezium will begin to handle this for you automatically.</p> </div> </div> </div> <div class="sect2"> <h3 id="transaction_metadata_changes">Transaction Metadata changes</h3> <div class="paragraph"> <p>A transaction metadata event describes the <em>beginning</em> and the <em>end</em> (commit) of a database transaction. These events are useful for a variety of reasons, including auditing. By default, transaction metadata events are not generated by a connector and to enable this feature, the <code>provide.transaction.metadata</code> option must be enabled.</p> </div> <div class="paragraph"> <p>In Debezium 2.0, both <code>BEGIN</code> and <code>END</code> events include a new field, <code>ts_ms</code>, which is the database timestamp of when the transaction either began or committed depending on the event type. An example of such an event now looks like:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">status</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">END</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">id</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">12345</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">event_count</span><span class="delimiter">&quot;</span></span>: <span class="integer">2</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">ts_ms</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">1657033173441</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">data_collections</span><span class="delimiter">&quot;</span></span>: [
    {
      <span class="key"><span class="delimiter">&quot;</span><span class="content">data_collection</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">s1.a</span><span class="delimiter">&quot;</span></span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">event_count</span><span class="delimiter">&quot;</span></span>: <span class="integer">1</span>
    },
    {
      <span class="key"><span class="delimiter">&quot;</span><span class="content">data_collection</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">s2.a</span><span class="delimiter">&quot;</span></span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">event_count</span><span class="delimiter">&quot;</span></span>: <span class="integer">1</span>
    }
  ]
}</code></pre> </div> </div> <div class="paragraph"> <p>If you are already using the transaction metadata feature, new events will contain this field after upgrading.</p> </div> <div class="paragraph"> <p>If you are not using the transaction metadata feature but find this useful, simply add the <code>provide.transaction.metadata</code> option set to <em>true</em> to your connector configuration. By default, metadata events are emitted to a topic named after your <code>topic.prefix</code> option. This can be overridden by specifying the <code>transaction.topic</code> option, as shown below:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">topic.prefix=server1
provide.transaction.metadata=true
transaction.topic=my-transaction-events</code></pre> </div> </div> <div class="paragraph"> <p>In this example, all transaction metadata events will be emitted to <code>my-transaction-events</code>. Please see your connector specific configuration for more details.</p> </div> </div> <div class="sect2"> <h3 id="multi_partition_mode_now_the_default">Multi-partition mode now the default</h3> <div class="paragraph"> <p>Many database platforms support multi-tenancy out of the box, meaning you can have one installation of the database engine and have many unique databases. In cases like SQL Server, this traditionally required a separate connector deployment for each unique database. Over the last year, a large effort has been made to break down that barrier and to introduce a common way that any single connector deployment could connect and stream changes from multiple databases.</p> </div> <div class="paragraph"> <p>The first notable change is with the SQL Server connector&#8217;s configuration option, <code>database.dbname</code>. This option has been replaced with a new option called <code>database.names</code>. As multi-partition mode is now default, this new <code>database.names</code> option can be specified using a comma-separated list of database names, as shown below:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">database.names=TEST1,TEST2</code></pre> </div> </div> <div class="paragraph"> <p>In this example, the connector is being configured to capture changes from two unique databases on the same host installation. The connector will start two unique tasks in Kafka Connect and each task will be responsible for streaming changes from its respective database concurrently.</p> </div> <div class="paragraph"> <p>The second notable change is with connector metrics naming. A connector exposes JMX metrics via beans that are identified with a unique name. With multi-partition mode the default with multiple tasks, each task requires its own metrics bean and so a change in the naming strategy was necessary.</p> </div> <div class="paragraph"> <p>In older versions of Debezium using SQL Server as an example, metrics were available using the following naming strategy:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">debezium.sql_server:type=connector-metrics,server=&lt;sqlserver.server.name&gt;,context=&lt;context&gt;</code></pre> </div> </div> <div class="paragraph"> <p>In this release, the naming strategy now includes a new <code>task</code> component in the JMX MBean name:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">debezium.sql_server:type=connector-metrics,server=&lt;sqlserver.server.name&gt;,task=&lt;task.id&gt;,context=&lt;context&gt;</code></pre> </div> </div> <div class="paragraph"> <p>Please review your metrics configurations as the naming changes could have an impact when collecting Debezium metrics.</p> </div> </div> <div class="sect2"> <h3 id="new_storage_module">New storage module</h3> <div class="paragraph"> <p>In this release, we have introduced a new <code>debezium-storage</code> set of artifacts for file- and kafka- based database history and offset storage. This change is the first of several future implementations set to support platforms such as Amazon S3, Redis, and possibly JDBC.</p> </div> <div class="paragraph"> <p>For users who install connectors via plugin artifacts, this should be a seamless change as all dependencies are bundled in those plugin downloadable archives. For users who may embed Debezium in their applications or who may be building their own connector, be aware you may need to add a new storage dependency depending on which storage implementations used.</p> </div> </div> <div class="sect2"> <h3 id="pluggable_topic_selector">Pluggable topic selector</h3> <div class="paragraph"> <p>Debezium&#8217;s default topic naming strategy emits change events to topics named <code>database.schema.table</code>. If you require that topics be named differently, an SMT would normally be added to the connector configuration to adjust this behavior. But, this presents a challenge in situations where one of the components of this topic name, perhaps the database or table name, contains a dot (<code>.</code>) and perhaps an SMT doesn&#8217;t have adequate context.</p> </div> <div class="paragraph"> <p>In this release, a new <code>TopicNamingStrategy</code> was introduced to allow fully customizing this behavior directly inside Debezium. The default naming strategy implementation should suffice in most cases, but if you find that it doesn&#8217;t you can provide a custom implementation of the <code>TopicNamingStrategy</code> contract to fully control various namings used by the connector. To provide your own custom strategy, you would specify the <code>topic.naming.strategy</code> connector option with the fully-qualified class name of the strategy, as shown below:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="properties">topic.naming.strategy=org.myorganization.MyCustomTopicNamingStrategy</code></pre> </div> </div> <div class="paragraph"> <p>This custom strategy is not just limited to controlling the names of topics for table mappings, but also for schema changes, transaction metadata, and heartbeats. You can refer to the <code>DefaultTopicNamingStrategy</code> found <a href="https://github.com/debezium/debezium/blob/main/debezium-core/src/main/java/io/debezium/schema/DefaultTopicNamingStrategy.java">here</a> as an example. This feature is still incubating, and we&#8217;ll continue to improve and develop it as feedback is received.</p> </div> </div> <div class="sect2"> <h3 id="improved_unique_index_handling">Improved unique index handling</h3> <div class="paragraph"> <p>A table does not have to have a primary key to be captured by a Debezium connector. In cases where a primary key is not defined, Debezium will inspect a table&#8217;s unique indices to see whether a reasonable key substitution can be made. In some situations, the index may refer to columns such as <code>CTID</code> for PostgreSQL or <code>ROWID</code> in Oracle. These columns are not visible nor user-defined, but instead are hidden synthetic columns generated automatically by the database. In addition, the index may also use database functions to transform the column value that is stored, such as <code>UPPER</code> or <code>LOWER</code> for example.</p> </div> <div class="paragraph"> <p>In this release, indices that rely on hidden, auto-generated columns, or columns wrapped in database functions are no longer eligible as primary key alternatives. This guarantees that when relying on an index as a primary key rather than a defined primary key itself, the generated message&#8217;s primary key value tuple directly maps to the same values used by the database to represent uniqueness.</p> </div> </div> <div class="sect2"> <h3 id="new_configuration_namespaces">New configuration namespaces</h3> <div class="paragraph"> <p>One of the largest overhauls going into Debezium 2.0 is the introduction of new connector property namespaces. Starting in Debezium 2.0 Beta2 and onward, many connector properties have been relocated with new names. This is a breaking change and affects most, if not all, connector deployments during the upgrade process.</p> </div> <div class="paragraph"> <p>Debezium previously used the prefix "database." with a plethora of varied connector properties. Some of these properties were meant to be passed directly to the JDBC driver and in other cases to the database history implementations, and so on. Unfortunately, we identified situations where some properties were being passed to underlying implementations that weren&#8217;t intended. While this wasn&#8217;t creating any type of regression or problem, it could potentially introduce a future issue if there were property name collisions, for example, a JDBC driver property that matched with a "database." prefixed Debezium connector property.</p> </div> <div class="paragraph"> <p>The following describes the changes to the connector properties</p> </div> <div class="ulist"> <ul> <li> <p>All configurations previously prefixed as <code>database.history.</code> are now to be prefixed using <code>schema.history.internal.</code> instead.</p> </li> <li> <p>All JDBC pass-thru options previously specified using <code>database.</code> prefix should now be prefixed using <code>driver.</code> instead.</p> </li> <li> <p>The <code>database.server.name</code> connector property renamed to <code>topic.prefix</code>.</p> </li> <li> <p>The MongoDB <code>mongodb.name</code> connector property aligned to use <code>topic.prefix</code> instead.</p> </li> </ul> </div> <div class="paragraph"> <p>Again, please review your connector configurations prior to deployment and adjust accordingly.</p> </div> </div> <div class="sect2"> <h3 id="all_schemas_named_and_versioned">All schemas named and versioned</h3> <div class="paragraph"> <p>Debezium change events are emitted with a schema definition, which contains metadata about the fields such as the type, whether it&#8217;s required, and so on. In previous iterations of Debezium, some schema definitions did not have explicit names nor were they being explicitly versioned. In this release, we&#8217;ve moved to making sure that all schema definitions have an explicit name and version associated with them. The goal of this change is to help with future event structure compatibility, particularly for those who are using schema registries. However, if you are currently using a schema registry, be aware that this change may lead to schema compatibility issues during the upgrade process.</p> </div> </div> <div class="sect2"> <h3 id="truncate_events_are_skipped_by_default">Truncate events are skipped by default</h3> <div class="paragraph"> <p>Debezium supports skipping specific event types by including the <code>skipped.operations</code> connector property in the connector&#8217;s configuration. This feature can be useful if you&#8217;re only interested in a subset of operations, such as only inserts and updates but not deletions.</p> </div> <div class="paragraph"> <p>One specific event type, truncates (<code>t</code>), is only supported by a subset of relational connectors and whether these events were to be skipped wasn&#8217;t consistent. In this release, we have aligned the <code>skipped.operations</code> behavior so that if the connector supports truncate events, these events are skipped by default.</p> </div> <div class="paragraph"> <p>Please review the following rule-set:</p> </div> <div class="ulist"> <ul> <li> <p>Connector supports truncate events and isn&#8217;t the Oracle connector</p> </li> <li> <p>Connector configuration does not specify the <code>skipped.operations</code> in the configuration</p> </li> </ul> </div> <div class="paragraph"> <p>If all the above are true, then the connector&#8217;s behavior will change after the upgrade. If you wish to continue to emit truncate events, the <code>skipped.operations=none</code> configuration will be required.</p> </div> </div> <div class="sect2"> <h3 id="change_in_schema_name_adjustment_behavior">Change in <code>schema.name.adjustment</code> behavior</h3> <div class="paragraph"> <p>The <code>schema.name.adjustment.mode</code> configuration property controls how schema names should be adjusted for compatibility with the message converter used by the connector. This configuration option can be one of two values:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>avro</code></dt> <dd> <p>Replicates the characters that cannot be used in the Avro type name with an underscore.</p> </dd> <dt class="hdlist1"><code>none</code></dt> <dd> <p>Does not adjust the names, even when non-Avro compliant characters are detected.</p> </dd> </dl> </div> <div class="paragraph"> <p>In prior releases, Debezium always defaulted to the safe value of <code>avro</code>; however, starting with Debezium 2.0.0.CR1 the default value will now be <code>none</code>. We believe that given that the use of Avro serialization is something opted in by users based on their needs, this option should align with the same opt-in behavior.</p> </div> <div class="paragraph"> <p>The safe upgrade path would be to adjust your configuration and explicitly use <code>schema.name.adjustment.mode</code> as <code>avro</code> and use the default for new connector deployments. But you can also review your topic names and configurations, checking that no underscore substitutions are happening and ergo this change will have no impact.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="cassandra-changes">Changes to Cassandra connector</h2> <div class="sectionbody"> <div class="sect2"> <h3 id="cassandra_4_incremental_commit_log_support">Cassandra 4 incremental commit log support</h3> <div class="paragraph"> <p><a href="https://cassandra.apache.org/doc/latest/cassandra/operating/cdc.html">Cassandra 4</a> has improved the integration with CDC by adding a feature that when the fsync operation occurs, Cassandra will update a CDC-based index file to contain the latest offset values. This index file allows CDC implementations to read up to the offset that is considered durable in Cassandra.</p> </div> <div class="paragraph"> <p>In this release, Debezium now uses this CDC-based index file to eliminate the inherent delay in processing CDC events from Cassandra that previously existed. This should provide Cassandra users a substantial improvement in CDC with Debezium, and gives an incentive to consider Cassandra 4 over Cassandra 3.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="mongodb-changes">Changes to MongoDB connector</h2> <div class="sectionbody"> <div class="sect2"> <h3 id="removal_of_the_oplog_implementation">Removal of the oplog implementation</h3> <div class="paragraph"> <p>In Debezium 1.8, we introduced the new MongoDB change stream feature while also deprecating the oplog implementation. The transition to change streams offers a variety of benefits, such as being able to stream changes from non-primary nodes, the ability to emit update events with a full document representation for downstream consumers, and so much more. In short, change streams is just a much more superior way to perform change data capture with MongoDB.</p> </div> <div class="paragraph"> <p>The removal of the oplog implementation also means that MongoDB 3.x is no longer supported. If you are using MongoDB 3.x, you will need to upgrade to at least MongoDB 4.0 or later with Debezium 2.0.</p> </div> </div> <div class="sect2"> <h3 id="before_state_support_mongodb_6_0">Before state support (MongoDB 6.0)</h3> <div class="paragraph"> <p>MongoDB 6 supports capturing the state of the document before the change is applied. This has long since been a feature that has been available only to the relational-based connectors, but this now enables Debezium to also include the <code>before</code> field as part of the event&#8217;s payload for MongoDB.</p> </div> <div class="paragraph"> <p>To enable this new MongoDB 6+ behavior, the <code>capture.mode</code> setting has been adjusted to include two new values:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>change_streams_with_pre_image</code></dt> <dd> <p>The change event will also contain the full document from <em>before</em> the change as well as the final state of the document fields that were changed as a part of the change event.</p> </dd> <dt class="hdlist1"><code>change_streams_update_full_with_pre_image</code></dt> <dd> <p>When an update occurs, not only will the full document be present to represent the current state after the update, but the event will also contain the full document from <em>before</em> the change as well.</p> </dd> </dl> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>The MongoDB <code>before</code> field behavior is only available on MongoDB 6 or later. If you are using a version of MongoDB before 6.0, the <code>before</code> field is omitted from the event output, even if configured.</p> </div> </td> </tr> </table> </div> </div> </div> </div> <div class="sect1"> <h2 id="mysql-changes">Changes to MySQL connector</h2> <div class="sectionbody"> <div class="sect2"> <h3 id="legacy_mysql_implementation_removed">Legacy MySQL implementation removed</h3> <div class="paragraph"> <p>As some of you may or may not know, we implemented the MySQL connector based on the common-connector framework back in Debezium 1.5 (Feb 2021). As a part of that re-write, we introduced the ability for MySQL users to enable the legacy connector behavior using the configuration option <code>internal.implementation</code> set as <code>legacy</code>. This legacy implementation was deprecated in favor of the new common-connector framework behavior. With Debezium 2.0, this <code>internal.implementation</code> configuration option and the legacy connector implementation have been removed.</p> </div> <div class="paragraph"> <p>If your current connector deployment relies on this legacy implementation, you should be aware that by upgrading to Debezium 2.0, the connector will no longer use that older implementation and will use the common-connector implementation only. Feature-wise, both implementations are on-par with one another with one exception: the legacy implementation had experimental support for changing filter configurations. If you have relied on this legacy behavior, be aware that feature is no longer available.</p> </div> </div> <div class="sect2"> <h3 id="binlog_compression_support">Binlog Compression Support</h3> <div class="paragraph"> <p>In this release, Debezium now supports reading of binlog entries that have been written with compression enabled. In version 8.0.20, MySQL adds the ability to compress binlog events using the ZSTD algorithm. To enable compression, you must toggle the <code>binlog.transaction_compression</code> variable on the MySQL server to <code>ON</code>. When compression is enabled, the binlog behaves as usual, except that the contents of the binlog entries are compressed to save space, and are replicated to in compressed format to replicas, significantly reducing network overhead for larger transactions.</p> </div> <div class="paragraph"> <p>If you&#8217;re interested in reading more about MySQL binlog compression, you can refer to the <a href="https://dev.mysql.com/doc/refman/8.0/en/binary-log-transaction-compression.html">Binary Log Transaction Compression</a> section of the MySQL documentation for more details.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="oracle-changes">Changes to Oracle connector</h2> <div class="sectionbody"> <div class="sect2"> <h3 id="oracle_source_info_changes">Oracle source info changes</h3> <div class="paragraph"> <p>The <code>source</code> information block is a section in the change event&#8217;s payload that describes the database attributes of what generated the change event. For example, this section includes the system change number, the database timestamp of the change, and the transaction the change was part of.</p> </div> <div class="paragraph"> <p>In this release, we identified a regression where the <code>scn</code> field did not correctly reflect the right <code>source</code> of where the change event occurred. While it isn&#8217;t abnormal for Oracle to generate multiple changes with the same system change number, we did find a regression that caused the wrong system change number to get assigned to each individual event within a scoped transaction, which made it difficult for some to use this information for auditing purposes. The <code>source.scn</code> field should now correctly reflect the system change number from Oracle LogMiner or Oracle Xstream.</p> </div> <div class="paragraph"> <p>Additionally, several new fields were added to the <code>source</code> information block to improve integration with the LogMiner implementation and Oracle RAC. An example of the new source information block:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">source</span><span class="delimiter">&quot;</span></span>: {
        <span class="key"><span class="delimiter">&quot;</span><span class="content">version</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">2.0.0.Alpha3</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">server1</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">ts_ms</span><span class="delimiter">&quot;</span></span>: <span class="integer">1520085154000</span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">txId</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">6.28.807</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">scn</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">2122184</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">commit_scn</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">2122185</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">rs_id</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">001234.00012345.0124</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">ssn</span><span class="delimiter">&quot;</span></span>: <span class="integer">0</span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">redo_thread</span><span class="delimiter">&quot;</span></span>: <span class="integer">1</span>
    }
}</code></pre> </div> </div> <div class="paragraph"> <p>The newly added fields are:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>rs_id</code></dt> <dd> <p>Specifies the rollback segment identifier associated with the change.</p> </dd> <dt class="hdlist1"><code>ssn</code></dt> <dd> <p>Specifies the SQL sequence number, this combined with the <code>rs_id</code> represent a unique tuple for a change.</p> </dd> <dt class="hdlist1"><code>redo_thread</code></dt> <dd> <p>Specifies the actual database redo thread that managed the change&#8217;s lifecycle.</p> </dd> </dl> </div> <div class="paragraph"> <p>Whether using Oracle Standalone or RAC, these values will always be provided when using Oracle LogMiner. These values have more importance on an Oracle RAC installation because you have multiple database servers manipulating the shared database concurrently. These fields specifically annotate which node and at what position on that node that the change originated.</p> </div> </div> <div class="sect2"> <h3 id="oracle_connector_offset_changes">Oracle connector offset changes</h3> <div class="paragraph"> <p>In an Oracle Real Application Clusters (RAC) environment, multiple nodes access and manipulate the Oracle database concurrently. Each node maintains its own redo log buffers and executes its own redo writer thread. This means that at any given moment, each node has its own unique "position" and these will differ entirely on the activity that takes place on each respective node.</p> </div> <div class="paragraph"> <p>In this release, a small change was necessary in <a href="https://issues.redhat.com/browse/DBZ-5245">DBZ-5245</a> to support Oracle RAC. Previously, the connector offsets maintained a field called <code>scn</code> which represented this "position" of where the connector should stream changes from. But since each node could be at different positions in the redo, a single <code>scn</code> value was inadequate for Oracle RAC.</p> </div> <div class="paragraph"> <p>The old Oracle connector offsets looked like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">scn</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">1234567890</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">commit_scn</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">2345678901</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">lcr_position</span><span class="delimiter">&quot;</span></span>: <span class="value">null</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">txId</span><span class="delimiter">&quot;</span></span>: <span class="value">null</span>
}</code></pre> </div> </div> <div class="paragraph"> <p>Starting in Debezium 2.0, the new offset structure now has this form:</p> </div> <div class="listingblock"> <div class="content"> <pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">scn</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">1234567890:00124.234567890.1234:0:1,1234567891:42100.0987656432.4321:0:2</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">commit_scn</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">2345678901</span><span class="delimiter">&quot;</span></span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">lcr_position</span><span class="delimiter">&quot;</span></span>: <span class="value">null</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">txId</span><span class="delimiter">&quot;</span></span>: <span class="value">null</span>
}</code></pre> </div> </div> <div class="paragraph"> <p>You will notice that the <code>scn</code> field now consists of a comma-separated list of values, where each entry represents a tuple of values. This new tuple has the format of <code>scn:rollback-segment-id:ssn:redo-thread</code>.</p> </div> <div class="paragraph"> <p>This change is forward compatible, meaning that once you have upgraded to Debezium 2.0, an older version of the connector will be unable to read the offsets. If you do upgrade and decide to rollback, be aware the offsets will require manually adjusting the offset&#8217;s <code>scn</code> field to simply contain a string of the most recent <code>scn</code> value across all redo threads.</p> </div> </div> <div class="sect2"> <h3 id="oracle_commit_user_in_change_events">Oracle commit user in change events</h3> <div class="paragraph"> <p>The source information block of change events carry a variety of context about where the change event originated. In this release, the Oracle connector now includes the user who made the database change in the captured change event. A new field, <code>user_name</code>, can now be found in the source info block with this new information. This field is optional, and is only available when changes are emitted using the LogMiner-based implementation. This field may also contain the value of <code>UNKNOWN</code> if the user associated with a change is dropped prior to the change being captured by the connector.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="postgres-changes">Changes to PostgreSQL connector</h2> <div class="sectionbody"> <div class="sect2"> <h3 id="support_for_wal2json_removed">Support for wal2json removed</h3> <div class="paragraph"> <p>Throughout Debezium&#8217;s lifecycle, the PostgreSQL connector has supported multiple decoder implementations, including <code>decoderbufs</code>, <code>wal2json</code>, and <code>pgoutput</code>. Both the <code>decoderbufs</code> and <code>wal2json</code> plugins have required special libraries to be installed on the database server to capture changes from PostgreSQL.</p> </div> <div class="paragraph"> <p>With PostgreSQL 9.6 marked as <a href="https://www.postgresql.org/support/versioning/">end of life</a> in November 2021, we felt now was a great opportunity to streamline the number of supported decoders. With PostgreSQL 10 and later supporting the <code>pgoutput</code> decoder natively, we concluded that it made sense to remove support for the <code>wal2json</code> plugin in Debezium 2.0.</p> </div> <div class="paragraph"> <p>If you are still using PostgreSQL 9.6 or the <code>wal2json</code> decoder, you will be required to upgrade to PostgreSQL 10+ or to either to the <code>decoderbufs</code> or the native <code>pgoutput</code> plugin to use Debezium going forward.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="vitess-changes">Changes to Vitess connector</h2> <div class="sectionbody"> <div class="sect2"> <h3 id="multitasking_support_for_vitess">Multitasking support for Vitess</h3> <div class="paragraph"> <p>The Vitess connector previously allowed operation in two different modes that depended entirely on whether the connector configuration specified any shard details. Unfortunately in both cases, each resulted in a single task responsible for performing the VStream processing. For larger Vitess installations with many shards, this architecture could begin to show latency issues as it may not be able to keep up with all the changes across all shards. And even more complex, when specifying the shard details, this required manually resolving the shards across the cluster and starting a single Debezium connector per shard, which is both error-prone and more importantly could result in deploying many Debezium connectors.</p> </div> <div class="paragraph"> <p>The Vitess community recognized this and sought to find a solution that addresses all these problems, both from a maintenance and error perspective. In Debezium 2.0 Beta2, the Vitess connector now automatically resolves the shards via a discovery mechanism, quite similar to that of MongoDB. This discovery mechanism will then split the load across multiple tasks, allowing for a single deployment of Debezium running a task per shard or shard lists, depending on the maximum number of allowed tasks for the connector.</p> </div> <div class="paragraph"> <p>During the upgrade, the Vitess connector will automatically migrate the offset storage to the new format used with the multitasking behavior. But be aware that once you&#8217;ve upgraded, you won&#8217;t be able to downgrade to an earlier version as the offset storage format will have changed.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="container-changes">Changes for Debezium container images</h2> <div class="sectionbody"> <div class="sect2"> <h3 id="support_for_arm64">Support for ARM64</h3> <div class="paragraph"> <p>There has been a shift in recent years with the performance of ARM64, even at AWS where their 64-bit ARM processors have projected performance over the latest x86-64 processors. This has helped put an emphasis across the industry at looking at the cost benefits of supporting both architectures with containers.</p> </div> <div class="paragraph"> <p>Since Debezium has traditionally released <code>linux/amd64</code> -based container images, this required that you either run the images using emulation of inside a Virtual Machine. This leads to unnecessary overhead and potential performance concerns and the goal of Debezium is low-latency and hyper speed! Starting with Debezium 2.0, Debezium is now also released using <code>ARM64</code> -based container images, reducing the overhead needed.</p> </div> <div class="paragraph"> <p>We hope the new ARM64 container images improve the adoption of Debezium, and show that we&#8217;re committed to delivering the best change data capture experience across the industry universally.</p> </div> </div> </div> </div> <div class="sect1"> <h2 id="community-spaces">Community spaces</h2> <div class="sectionbody"> <div class="paragraph"> <p>Later this week, there will be several new <em>community-driven</em> discussion spaces available on our Zulip chat platform. We will be publishing a blog post that discusses the purpose of these new channels and their goals, but we wanted to also include a note here about this new feature.</p> </div> <div class="paragraph"> <p>Unlike the <code>#users</code> channel that is meant to provide community-driven support, these spaces are meant to provide a place for the community to discuss experiences with specific database technologies, Debezium services, and topics that are substantially broader than just support. These spaces will be divided by technology, allowing the user community to target specific areas of interest easily, and engage in discussions that pertain to specific databases and services.</p> </div> <div class="paragraph"> <p>These spaces are not meant to be support venues, we will still expect those to continue to foster in the <code>#users</code> channel going forward, so keep an eye out for these new community spaces later this week and the blog to follow.</p> </div> </div> </div> <div class="sect1"> <h2 id="other_fixes_improvements">Other fixes &amp; improvements</h2> <div class="sectionbody"> <div class="paragraph"> <p>There were many bugfixes, stability changes, and improvements throughout the development of Debezium 2.0. Altogether, a total of <a href="https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(2.0.0.Alpha1%2C%202.0.0.Alpha2%2C%202.0.0.Alpha3%2C%202.0.0.Beta1%2C%202.0.0.Beta2%2C%202.0.0.CR1%2C%202.0.0.Final)%20ORDER%20BY%20component%20ASC">463 issues</a> were fixed for this release.</p> </div> <div class="paragraph"> <p>A big thank you to all the contributors from the community who worked on this major release: Wang Min Chao, Rotem[Adhoh], <a href="https://github.com/ahmedjami">Ahmed ELJAMI</a>, <a href="https://github.com/almartino">Alberto Martino</a>, <a href="https://github.com/ahus1">Alexander Schwartz</a>, <a href="https://github.com/aloubyansky">Alexey Loubyansky</a>, <a href="https://github.com/AlexMiroshnikov">Alexey Miroshnikov</a>, Gabor[Andras], <a href="https://github.com/ajunwalker">Andrew Walker</a>, <a href="https://github.com/jchipmunk">Andrey Pustovetov</a>, <a href="https://github.com/ani-sha">Anisha Mohanty</a>, <a href="https://github.com/avis408">Avinash Vishwakarma</a>, <a href="https://github.com/xinbinhuang">Bin Huang</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/bmorganpa">Brad Morgan</a>, <a href="https://github.com/calinilie">Calin Laurentiu Ilie</a>, <a href="https://github.com/chadthman">Chad Marmon</a>, <a href="https://github.com/ProofOfPizza">Chai Stofkoper</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/Chrisss93">Chris Lee</a>, <a href="https://github.com/davsclaus">Claus Ibsen</a>, <a href="https://github.com/connorszczepaniak-wk">Connor Szczepaniak</a>, <a href="https://github.com/cmartinez-enve">César Martínez</a>, <a href="https://github.com/debjeetsarkar">Debjeet Sarkar</a>, Mikhail[Dubrovin], <a href="https://github.com/elirag">Eliran Agranovich</a>, <a href="https://github.com/EthanZ328">Ethan Zou</a>, <a href="https://github.com/ezerk">Ezer Karavani</a>, <a href="https://github.com/ggaborg">Gabor Andras</a>, <a href="https://github.com/giljae">Giljae Joo</a>, <a href="https://github.com/gunnarmorling">Gunnar Morling</a>, <a href="https://github.com/ruanhang1993">Hang Ruan</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/HenryCaiHaiying">Henry Cai</a>, <a href="https://github.com/Himanshu-LT">Himanshu Mishra</a>, <a href="https://github.com/blcksrx">Hossein Torabi</a>, <a href="https://github.com/nicholas-fwang">Inki Hwang</a>, <a href="https://github.com/ismailsimsek">Ismail Simsek</a>, <a href="https://github.com/jcechace">Jakub Cechacek</a>, <a href="https://github.com/domsj">Jan Doms</a>, <a href="https://github.com/DerGut">Jannik Steinmann</a>, <a href="https://github.com/jerrinot">Jaromir Hamala</a>, <a href="https://github.com/jeremy-l-ford">Jeremy Ford</a>, <a href="https://github.com/Jiabao-Sun">Jiabao Sun</a>, <a href="https://github.com/novotnyJiri">Jiri Novotny</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/joschi">Jochen Schalanda</a>, <a href="https://github.com/yannickzj">Jun Zhao</a>, <a href="https://github.com/kanha-gupta">Kanha Gupta</a>, <a href="https://github.com/kgalieva">Katerina Galieva</a>, <a href="https://github.com/LarsWerkman">Lars Werkman</a>, <a href="https://github.com/winklerm">Marek Winkler</a>, <a href="https://github.com/markallanson">Mark Allanson</a>, <a href="https://github.com/alwaysbemark">Mark Bereznitsky</a>, <a href="https://github.com/MartinMedek">Martin Medek</a>, <a href="https://github.com/mimaison">Mickael Maison</a>, <a href="https://github.com/mikekamornikov">Mike Kamornikov</a>, <a href="https://github.com/yzia2000">Mohammad Yousuf Minhaj Zia</a>, <a href="https://github.com/nathan-bradshaw-at">Nathan Bradshaw</a>, <a href="https://github.com/nathan-smit-1">Nathan Smit</a>, <a href="https://github.com/krnaveen14">Naveen Kumar KR</a>, <a href="https://github.com/nilshartmann">Nils Hartmann</a>, <a href="https://github.com/nirolevy">Nir Levy</a>, <a href="https://github.com/nitinitt">Nitin Chhabra</a>, <a href="https://github.com/zalmane">Oren Elias</a>, <a href="https://github.com/ypt">Paul Tzen</a>, <a href="https://github.com/pmalon">Paweł Malon</a>, <a href="https://github.com/smallYellowCat">Pengwei Dou</a>, <a href="https://github.com/thangdc94">Phạm Ngọc Thắng</a>, <a href="https://github.com/PlugaruT">Plugaru Tudor</a>, Oskar[Polak], <a href="https://github.com/rahulkhanna2">Rahul Khanna</a>, <a href="https://github.com/rajdangwal">Rajendra Dangwal</a>, <a href="https://github.com/rk3rn3r">René Kerner</a>, <a href="https://github.com/roldanbob">Robert Roldan</a>, <a href="https://github.com/druud">Ruud H.G. van Tol</a>, <a href="https://github.com/sagarrao12">Sagar Rao</a>, <a href="https://github.com/Sage-Pierce">Sage Pierce</a>, <a href="https://github.com/jaegwonseo">Seo Jae-kwon</a>, <a href="https://github.com/morozov">Sergei Morozov</a>, <a href="https://github.com/shichao-an">Shichao An</a>, <a href="https://github.com/smiklosovic">Stefan Miklosovic</a>, <a href="https://github.com/tim-patterson">Tim Patterson</a>, <a href="https://github.com/troeselereos">Timo Roeseler</a>, <a href="https://github.com/ramanenka">Vadzim Ramanenka</a>, <a href="https://github.com/vivekwassan">Vivek Wassan</a>, <a href="https://github.com/vjuranek">Vojtech Juranek</a>, <a href="https://github.com/xinbinhuang">Xinbin Huang</a>, <a href="https://github.com/y5w">Yang</a>, <a href="https://github.com/spicy-sauce">Yossi Shirizli</a>, <a href="https://github.com/GOODBOY008">Zhongqiang Gong</a>, <a href="https://github.com/gmouss">moustapha mahfoud</a>, <a href="https://github.com/yangrong688">yangrong688</a>, <a href="https://github.com/BetaCat0">合龙 张</a>, <a href="https://github.com/comil4444">崔世杰</a>, and <a href="https://github.com/pkgonan">민규 김</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="whats_next">What&#8217;s next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>While we are heading into the holiday season, we have started the work on Debezium 2.1, which will be out later this year. Some potential features you can expect include:</p> </div> <div class="ulist"> <ul> <li> <p>Truncate support for MySQL</p> </li> <li> <p>PostgreSQL 15 support</p> </li> <li> <p>JDBC history and offset storage support</p> </li> </ul> </div> <div class="paragraph"> <p>As always, this roadmap is heavily influenced by the community, i.e. you. So if you would like to see any particular items here, please let us know. For now, lets celebrate the hard work in the release of Debezium 2.0 and look forward to what&#8217;s coming later this year and in 2023!</p> </div> <div class="paragraph"> <p>Onwards and Upwards!</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><category term="mongodb"/><summary type="html"><![CDATA[Today it&#8217;s my great pleasure to announce the availability of Debezium 2.0.0.Final! Since our 1.0 release in December 2019, the community has worked vigorously to build a comprehensive open-source low-latency platform for change data capture (CDC). Over the past three years, we have extended Debezium&#8217;s portfolio to include a stable connector for Oracle, a community led connector for Vitess, the introduction of incremental snapshots, multi-partition support, and so much more. With the help of our active community of contributors and committers, Debezium is the de facto leader in the CDC space, deployed to production within lots of organizations from across multiple industries, using hundreds of connectors to stream data changes out of thousands of database platforms. The 2.0 release marks a new milestone for Debezium, one that we are proud to share with each of you.]]></summary></entry><entry><title type="html">Debezium 2.0.0.CR1 Released</title><link href="https://debezium.io/blog/2022/10/10/debezium-2.0-cr1-released/" rel="alternate" type="text/html" title="Debezium 2.0.0.CR1 Released"/><published>2022-10-10T00:00:00+00:00</published><updated>2022-10-10T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/10/10/debezium-2.0-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/10/10/debezium-2.0-cr1-released/"><![CDATA[<div class="paragraph"> <p>I am excited to announce the release of Debezium <strong>2.0.0.CR1</strong>!</p> </div> <div class="paragraph"> <p>This release contains breaking changes, stability fixes, and bug fixes, all to inch us closer to 2.0.0.Final. Overall, this release contains a total of <a href="https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.CR1%20ORDER%20BY%20component%20ASC">53 issues</a> that were fixed.</p> </div> <div class="paragraph"> <p></p> </div> <div class="paragraph"> <p>If you intend to upgrade to 2.0.0.CR1, we strongly recommend that you read the release notes before the upgrade to understand all breaking changes. There was one noteworthy breaking changes with the 2.0.0.CR1 release:</p> </div> <div class="ulist"> <ul> <li> <p>[breaking] <a href="#schema-name-adjustment-mode">Behavior of <code>schema.name.adjustment.mode</code> has changed</a></p> </li> </ul> </div> <div class="sect1"> <h2 id="schema-name-adjustment-mode">Behavior of schema.name.adjustment.mode has changed</h2> <div class="sectionbody"> <div class="paragraph"> <p>The <code>schema.name.adjustment.mode</code> configuration property controls how schema names should be adjusted for compatibility with the message converter used by the connector. This configuration option can be one of two values:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>avro</code></dt> <dd> <p>Repliaces the characters that cannot be used in the Avro type name with an underscore.</p> </dd> <dt class="hdlist1"><code>none</code></dt> <dd> <p>Does not adjust the names, even when non-Avro compliant characters are detected.</p> </dd> </dl> </div> <div class="paragraph"> <p>In prior releases, Debezium always defaulted to the safe value of <code>avro</code>; however, starting with Debezium 2.0.0.CR1 the default value will now be <code>none</code>. We believe that given that the use of Avro serialization is something opted in by users based on their needs, this option should align with the same opt-in behavior.</p> </div> <div class="paragraph"> <p>The safe upgrade path would be to adjust your configuration and explicitly use <code>schema.name.adjustment.mode</code> as <code>avro</code> and use the default for new connector deployments. But you can also review your topic names and configurations, checking that no underscore substitutions are happening and ergo this change will have no impact.</p> </div> </div> </div> <div class="sect1"> <h2 id="mongodb_6_0_before_state_support">MongoDB 6.0 - before state support</h2> <div class="sectionbody"> <div class="paragraph"> <p>MongoDB 6 supports capturing the state of the document before the change is applied. This has long since been a feature that has been available only to the relational-based connectors, but this now enables Debezium to also include the <code>before</code> field as part of the event&#8217;s payload for MongoDB.</p> </div> <div class="paragraph"> <p>To enable this new MongoDB 6+ behavior, the <code>capture.mode</code> setting has been adjusted to include two new values:</p> </div> <div class="dlist"> <dl> <dt class="hdlist1"><code>change_streams_with_pre_image</code></dt> <dd> <p>The change event will also contain the full document from <em>before</em> the change as well as the final state of the document fields that were changed as a part of the change event.</p> </dd> <dt class="hdlist1"><code>change_streams_update_full_with_pre_image</code></dt> <dd> <p>When an update occurs, not only will the full document be present to represent the current state after the update, but the event will also contain the full document from <em>before</em> the change as well.</p> </dd> </dl> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>The MongoDB <code>before</code> field behavior is only available on MongoDB 6 or later. If you are using a version of MongoDB before 6.0, the <code>before</code> field is omitted from the event output, even if configured.</p> </div> </td> </tr> </table> </div> </div> </div> <div class="sect1"> <h2 id="other_fixes_improvements">Other fixes &amp; improvements</h2> <div class="sectionbody"> <div class="paragraph"> <p>There are many bugfixes and stability changes in this release, some noteworthy are:</p> </div> <div class="ulist"> <ul> <li> <p>Implement retries for Debezium embedded engine <a href="https://issues.redhat.com/browse/DBZ-4629">DBZ-4629</a></p> </li> <li> <p>Traditional snapshot process setting source.ts_ms <a href="https://issues.redhat.com/browse/DBZ-5591">DBZ-5591</a></p> </li> <li> <p>Upgrade Kafka client to 3.3.1 <a href="https://issues.redhat.com/browse/DBZ-5600">DBZ-5600</a></p> </li> <li> <p>Support READ ONLY/ENCRYPTION options for alter database statment <a href="https://issues.redhat.com/browse/DBZ-5622">DBZ-5622</a></p> </li> <li> <p>Clarify semantics of include/exclude options <a href="https://issues.redhat.com/browse/DBZ-5625">DBZ-5625</a></p> </li> <li> <p>Added support for Mongo pre-image in change stream <a href="https://issues.redhat.com/browse/DBZ-5628">DBZ-5628</a></p> </li> <li> <p>Support for using any expression in kill statements <a href="https://issues.redhat.com/browse/DBZ-5636">DBZ-5636</a></p> </li> <li> <p>Debezium Db2 Connector fails to handle default values in schema when is making the snapshot <a href="https://issues.redhat.com/browse/DBZ-4990">DBZ-4990</a></p> </li> <li> <p>Oracle connector parsing SELECT_LOB_LOCATOR event missing constant <code>unavailable.value.placeholder</code> <a href="https://issues.redhat.com/browse/DBZ-5581">DBZ-5581</a></p> </li> <li> <p>Starting Embedded Engine swallows ClassNotFoundException so user cannot see why engine does not work <a href="https://issues.redhat.com/browse/DBZ-5583" class="bare">https://issues.redhat.com/browse/DBZ-5583</a>[DBZ-558</p> </li> <li> <p>Hardcoded driver task properties are not being passed to underlying connections <a href="https://issues.redhat.com/browse/DBZ-5670">DBZ-5670</a></p> </li> <li> <p>MongoDB Connector with DocumentDB errors with "{$natural: -1} is not supported" <a href="https://issues.redhat.com/browse/DBZ-5677">DBZ-5677</a></p> </li> <li> <p>Upgrade apicurio to 2.2.5.Final <a href="https://issues.redhat.com/browse/DBZ-5549">DBZ-5549</a></p> </li> <li> <p>Upgrade binary log client to 0.27.2 <a href="https://issues.redhat.com/browse/DBZ-5620">DBZ-5620</a></p> </li> </ul> </div> <div class="paragraph"> <p>Altogether, a total of <a href="https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.Beta2%20ORDER%20BY%20component%20ASC">53 issues</a> were fixed for this release.</p> </div> <div class="paragraph"> <p>A big thank you to all the contributors from the community who worked on this release: <a href="https://github.com/ahus1">Alexander Schwartz</a>, Gabor Andras, <a href="https://github.com/avis408">Avinash Vishwakarma</a>, <a href="https://github.com/xinbinhuang">Bin Huang</a>, <a href="https://github.com/roldanbob">Bob Roldan</a>, <a href="https://github.com/Naros">Chris Cranford</a>, <a href="https://github.com/ezerk">Ezer Karavani</a>, <a href="https://github.com/ggaborg">Gabor Andras</a>, <a href="https://github.com/harveyyue">Harvey Yue</a>, <a href="https://github.com/ismailsimsek">Ismail Simsek</a>, <a href="https://github.com/jerrinot">Jaromir Hamala</a>, <a href="https://github.com/jeremy-l-ford">Jeremy Ford</a>, <a href="https://github.com/jpechane">Jiri Pechanec</a>, <a href="https://github.com/nirolevy">Nir Levy</a>, <a href="https://github.com/rajdangwal">Rajendra Dangwal</a>, <a href="https://github.com/Sage-Pierce">Sage Pierce</a>, <a href="https://github.com/morozov">Sergei Morozov</a>, <a href="https://github.com/vjuranek">Vojtech Juranek</a>, <a href="https://github.com/xinbinhuang">Xinbin Huang</a>, and <a href="https://github.com/gmouss">moustapha mahfoud</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="whats_next">What&#8217;s next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>With the release of Debezium 2.0 CR1, the release of 2.0.0.Final is just around the corner. The community should expect the Final release soon, barring any bug reports. In addition, we are also working on wrapping up the last installation of the 1.9 release stream, 1.9.7.Final which should will be released toward the end of this month.</p> </div> <div class="paragraph"> <p>With the holiday season fast approaching, we will soon begin work on Debezium 2.1. We do intend to have a normal release cycle this quarter despite being behind on Debezium 2.0, so expect that sometime just before the end of the year.</p> </div> <div class="paragraph"> <p>In the meantime, happy capturing!</p> </div> </div> </div>]]></content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><category term="mongodb"/><summary type="html"><![CDATA[I am excited to announce the release of Debezium 2.0.0.CR1! This release contains breaking changes, stability fixes, and bug fixes, all to inch us closer to 2.0.0.Final. Overall, this release contains a total of 53 issues that were fixed.]]></summary></entry></feed>